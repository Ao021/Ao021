<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="DANTE的游戏博客">
    <meta name="keyword" content="GAMES# seo key words">
    <meta name="theme-color" content="#600090">
    <meta name="msapplication-navbutton-color" content="#600090">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="#600090">
    <link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/964987e788bb8e7784f2f3b0c6b20f30.png# your favicon png">
    <link rel="alternate" type="application/atom+xml" title="Dante-Game" href="/atom.xml">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/animate.css/3.5.2/animate.min.css">
    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.css">
    <title>
        
        Pytorch学习笔记--张量｜Dante-Game
        
    </title>

    <link rel="canonical" href="https://www.dante-game.com.cn/2021/01/27/Pytorch学习笔记1-张量/">

    <!-- Bootstrap Core CSS -->
    
<link rel="stylesheet" href="/css/bootstrap.min.css">


    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/blog-style.css">


    <!-- Pygments Github CSS -->
    
<link rel="stylesheet" href="/css/syntax.css">

<meta name="generator" content="Hexo 6.3.0"></head>

<style>

    header.intro-header {
        background-image: url('//o7bkkhiex.bkt.clouddn.com/lion-blur-bg.jpg')
    }
</style>
<!-- hack iOS CSS :active style -->
<body ontouchstart="" class="animated fadeIn">
<!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top " id="nav-top" data-ispost = "true" data-istags="false
" data-ishome = "false" >
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand animated pulse" href="/">
                <span class="brand-logo">
                    Dante-Game
                </span>
                's Blog
            </a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <!-- /.navbar-collapse -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>
					
                    
                        
							
                        <li>
                            <a href="/tags/">tags</a>
                        </li>
							
						
                    
                        
							
                        <li>
                            <a href="/categories/">categories</a>
                        </li>
							
						
                    
					
					
                </ul>
            </div>
        </div>
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
//    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>

<!-- Main Content -->

<!--only post-->


<img class="wechat-title-img"
     src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/84137197_p0.png">


<style>
    
    header.intro-header {
        background-image: url('https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/84137197_p0.png')
    }

    
</style>

<header class="intro-header">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 text-center">
                <div class="post-heading">
                    <h1>Pytorch学习笔记--张量</h1>
                    
                    <span class="meta">
                         作者 Dante
                        <span>
                          日期 2021-01-27
                         </span>
                    </span>
                    <div class="tags text-center">
                        
                        <a class="tag" href="/tags/#学习"
                           title="学习">学习</a>
                        
                        <a class="tag" href="/tags/#记录"
                           title="记录">记录</a>
                        
                        <a class="tag" href="/tags/#经验"
                           title="经验">经验</a>
                        
                        <a class="tag" href="/tags/#Pytorch"
                           title="Pytorch">Pytorch</a>
                        
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="post-title-haojen">
        <span>
            Pytorch学习笔记--张量
        </span>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">
            <!-- Post Container -->
            <div class="col-lg-8 col-lg-offset-1 col-sm-9 post-container">
                <h2 id="PyTorch是什么"><a href="#PyTorch是什么" class="headerlink" title="PyTorch是什么"></a>PyTorch是什么</h2><p>基于Python的科学计算包，服务于以下两种场景:</p>
<ul>
<li>作为NumPy的替代品，可以使用GPU的强大计算能力</li>
<li>提供最大的灵活性和高速的深度学习研究平台</li>
</ul>
<span id="more"></span>
<h2 id="Tensors-张量"><a href="#Tensors-张量" class="headerlink" title="Tensors 张量"></a>Tensors 张量</h2><h3 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h3><p>Tensors与Numpy中的 ndarrays类似，但是在PyTorch中 Tensors 可以使用GPU进行计算.<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from __future__ import print_function</span><br><span class="line">import torch</span><br></pre></td></tr></table></figure></p>
<h4 id="创建一个-5x3-矩阵-但是未初始化"><a href="#创建一个-5x3-矩阵-但是未初始化" class="headerlink" title="创建一个 5x3 矩阵, 但是未初始化:"></a>创建一个 5x3 矩阵, 但是未初始化:</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.empty(5, 3)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.0000, 0.0000, 0.0000],  </span><br><span class="line">        [0.0000, 0.0000, 0.0000],  </span><br><span class="line">        [0.0000, 0.0000, 0.0000],  </span><br><span class="line">        [0.0000, 0.0000, 0.0000],  </span><br><span class="line">        [0.0000, 0.0000, 0.0000]])</span><br></pre></td></tr></table></figure>
<h4 id="创建一个随机初始化的矩阵"><a href="#创建一个随机初始化的矩阵" class="headerlink" title="创建一个随机初始化的矩阵:"></a>创建一个随机初始化的矩阵:</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(5, 3)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.6972, 0.0231, 0.3087],</span><br><span class="line">        [0.2083, 0.6141, 0.6896],</span><br><span class="line">        [0.7228, 0.9715, 0.5304],</span><br><span class="line">        [0.7727, 0.1621, 0.9777],</span><br><span class="line">        [0.6526, 0.6170, 0.2605]])</span><br></pre></td></tr></table></figure>
<h4 id="创建一个0填充的矩阵，数据类型为long"><a href="#创建一个0填充的矩阵，数据类型为long" class="headerlink" title="创建一个0填充的矩阵，数据类型为long:"></a>创建一个0填充的矩阵，数据类型为long:</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.zeros(5, 3, dtype=torch.long)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0]])</span><br></pre></td></tr></table></figure>
<h4 id="创建tensor并使用现有数据初始化"><a href="#创建tensor并使用现有数据初始化" class="headerlink" title="创建tensor并使用现有数据初始化:"></a>创建tensor并使用现有数据初始化:</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([5.5, 3])</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([5.5000, 3.0000])</span><br></pre></td></tr></table></figure>
<h4 id="根据现有的张量创建张量。-这些方法将重用输入张量的属性，例如，-dtype，除非设置新的值进行覆盖"><a href="#根据现有的张量创建张量。-这些方法将重用输入张量的属性，例如，-dtype，除非设置新的值进行覆盖" class="headerlink" title="根据现有的张量创建张量。 这些方法将重用输入张量的属性，例如， dtype，除非设置新的值进行覆盖"></a>根据现有的张量创建张量。 这些方法将重用输入张量的属性，例如， dtype，除非设置新的值进行覆盖</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = x.new_ones(5, 3, dtype=torch.double)      # new_* 方法来创建对象</span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line">x = torch.randn_like(x, dtype=torch.float)    # 覆盖 dtype!</span><br><span class="line">print(x)                                      #  对象的size 是相同的，只是值和类型发生了变化</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1., 1., 1.],</span><br><span class="line">        [1., 1., 1.],</span><br><span class="line">        [1., 1., 1.],</span><br><span class="line">        [1., 1., 1.],</span><br><span class="line">        [1., 1., 1.]], dtype=torch.float64)</span><br><span class="line">tensor([[ 0.5691, -2.0126, -0.4064],</span><br><span class="line">        [-0.0863,  0.4692, -1.1209],</span><br><span class="line">        [-1.1177, -0.5764, -0.5363],</span><br><span class="line">        [-0.4390,  0.6688,  0.0889],</span><br><span class="line">        [ 1.3334, -1.1600,  1.8457]])</span><br></pre></td></tr></table></figure>
<h4 id="获取-size"><a href="#获取-size" class="headerlink" title="获取 size"></a>获取 size</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x.size())</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([5, 3])</span><br></pre></td></tr></table></figure>
<h2 id="张量的操作"><a href="#张量的操作" class="headerlink" title="张量的操作"></a>张量的操作</h2><h3 id="加法"><a href="#加法" class="headerlink" title="加法"></a>加法</h3><h4 id="加法1"><a href="#加法1" class="headerlink" title="加法1"></a>加法1</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = torch.rand(5, 3)</span><br><span class="line">print(x + y)</span><br></pre></td></tr></table></figure>
<h4 id="加法2"><a href="#加法2" class="headerlink" title="加法2"></a>加法2</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(torch.add(x, y))</span><br></pre></td></tr></table></figure>
<h4 id="提供输出tensor作为参数"><a href="#提供输出tensor作为参数" class="headerlink" title="提供输出tensor作为参数"></a>提供输出tensor作为参数</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">result = torch.empty(5, 3)</span><br><span class="line">torch.add(x, y, out=result)</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>
<h4 id="替换"><a href="#替换" class="headerlink" title="替换"></a>替换</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.add_(x)</span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>任何 以<code>_</code> 结尾的操作都会用结果替换原变量. 例如: <code>x.copy_(y)</code>, <code>x.t_()</code>, 都会改变 <code>x</code>.这里便是 y+=x</p>
</blockquote>
<h4 id="torch-view-可以改变张量的维度和大小"><a href="#torch-view-可以改变张量的维度和大小" class="headerlink" title="torch.view: 可以改变张量的维度和大小"></a>torch.view: 可以改变张量的维度和大小</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(4, 4)</span><br><span class="line">y = x.view(16)</span><br><span class="line">z = x.view(-1, 8)  #  size -1 从其他维度推断</span><br><span class="line">print(x.size(), y.size(), z.size())</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])</span><br></pre></td></tr></table></figure>
<h4 id="只有一个元素的张量，使用-item-来得到Python数据类型的数值"><a href="#只有一个元素的张量，使用-item-来得到Python数据类型的数值" class="headerlink" title="只有一个元素的张量，使用.item()来得到Python数据类型的数值"></a>只有一个元素的张量，使用.item()来得到Python数据类型的数值</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(1)</span><br><span class="line">print(x)</span><br><span class="line">print(x.item())</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([-0.2368])</span><br><span class="line">-0.23680149018764496</span><br></pre></td></tr></table></figure>
<h2 id="NumPy-转换"><a href="#NumPy-转换" class="headerlink" title="NumPy 转换"></a>NumPy 转换</h2><p>将一个Torch Tensor转换为NumPy数组是一件轻松的事，反之亦然。<br>Torch Tensor与NumPy数组共享底层内存地址，修改一个会导致另一个的变化。<br><br><br>将一个Torch Tensor转换为NumPy数组<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = torch.ones(5)</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure><br><code>tensor([1., 1., 1., 1., 1.])</code><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b = a.numpy()</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure><br><code>[1. 1. 1. 1. 1.]</code><br><br></p>
<h3 id="numpy数组的值是如何改变的。"><a href="#numpy数组的值是如何改变的。" class="headerlink" title="numpy数组的值是如何改变的。"></a>numpy数组的值是如何改变的。</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a.add_(1)</span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([2., 2., 2., 2., 2.])</span><br><span class="line">[2. 2. 2. 2. 2.]</span><br></pre></td></tr></table></figure>
<h4 id="使用from-numpy自动转化"><a href="#使用from-numpy自动转化" class="headerlink" title="使用from_numpy自动转化"></a>使用from_numpy自动转化</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">a = np.ones(5)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line">np.add(a, 1, out=a)</span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[2. 2. 2. 2. 2.]</span><br><span class="line">tensor([2., 2., 2., 2., 2.], dtype=torch.float64)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>所有的 Tensor 类型默认都是基于CPU， CharTensor 类型不支持到 NumPy 的转换.</p>
<h2 id="CUDA-张量"><a href="#CUDA-张量" class="headerlink" title="CUDA 张量"></a>CUDA 张量</h2><p>使用.to 方法 可以将Tensor移动到任何设备中<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># is_available 函数判断是否有cuda可以使用</span><br><span class="line"># ``torch.device``将张量移动到指定的设备中</span><br><span class="line">if torch.cuda.is_available():</span><br><span class="line">    device = torch.device(&quot;cuda&quot;)          # a CUDA 设备对象</span><br><span class="line">    y = torch.ones_like(x, device=device)  # 直接从GPU创建张量</span><br><span class="line">    x = x.to(device)                       # 或者直接使用``.to(&quot;cuda&quot;)``将张量移动到cuda中</span><br><span class="line">    z = x + y</span><br><span class="line">    print(z)</span><br><span class="line">    print(z.to(&quot;cpu&quot;, torch.double))       # ``.to`` 也会对变量的类型做更改</span><br></pre></td></tr></table></figure><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([0.7632], device=&#x27;cuda:0&#x27;)</span><br><span class="line">tensor([0.7632], dtype=torch.float64)</span><br></pre></td></tr></table></figure></p>
</blockquote>

                <hr>
                

                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2021/02/19/Pytorch学习笔记2-Autograd 自动求导机制/" data-toggle="tooltip" data-placement="top"
                           title="Pytorch学习笔记--自动求导机制">&larr; Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/2021/01/27/语义分割_入门_经验分享/" data-toggle="tooltip" data-placement="top"
                           title="人工智能小测试">Next Post &rarr;</a>
                    </li>
                    
                </ul>

                

                


                <!--加入新的评论系统-->
                

                

            </div>

            <div class="hidden-xs col-sm-3 toc-col">
                <div class="toc-wrap">
                    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#PyTorch%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">PyTorch是什么</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tensors-%E5%BC%A0%E9%87%8F"><span class="toc-text">Tensors 张量</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA"><span class="toc-text">创建</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA-5x3-%E7%9F%A9%E9%98%B5-%E4%BD%86%E6%98%AF%E6%9C%AA%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-text">创建一个 5x3 矩阵, 但是未初始化:</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E9%9A%8F%E6%9C%BA%E5%88%9D%E5%A7%8B%E5%8C%96%E7%9A%84%E7%9F%A9%E9%98%B5"><span class="toc-text">创建一个随机初始化的矩阵:</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA0%E5%A1%AB%E5%85%85%E7%9A%84%E7%9F%A9%E9%98%B5%EF%BC%8C%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B8%BAlong"><span class="toc-text">创建一个0填充的矩阵，数据类型为long:</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAtensor%E5%B9%B6%E4%BD%BF%E7%94%A8%E7%8E%B0%E6%9C%89%E6%95%B0%E6%8D%AE%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-text">创建tensor并使用现有数据初始化:</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B9%E6%8D%AE%E7%8E%B0%E6%9C%89%E7%9A%84%E5%BC%A0%E9%87%8F%E5%88%9B%E5%BB%BA%E5%BC%A0%E9%87%8F%E3%80%82-%E8%BF%99%E4%BA%9B%E6%96%B9%E6%B3%95%E5%B0%86%E9%87%8D%E7%94%A8%E8%BE%93%E5%85%A5%E5%BC%A0%E9%87%8F%E7%9A%84%E5%B1%9E%E6%80%A7%EF%BC%8C%E4%BE%8B%E5%A6%82%EF%BC%8C-dtype%EF%BC%8C%E9%99%A4%E9%9D%9E%E8%AE%BE%E7%BD%AE%E6%96%B0%E7%9A%84%E5%80%BC%E8%BF%9B%E8%A1%8C%E8%A6%86%E7%9B%96"><span class="toc-text">根据现有的张量创建张量。 这些方法将重用输入张量的属性，例如， dtype，除非设置新的值进行覆盖</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96-size"><span class="toc-text">获取 size</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%A0%E9%87%8F%E7%9A%84%E6%93%8D%E4%BD%9C"><span class="toc-text">张量的操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A0%E6%B3%95"><span class="toc-text">加法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%A0%E6%B3%951"><span class="toc-text">加法1</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%A0%E6%B3%952"><span class="toc-text">加法2</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8F%90%E4%BE%9B%E8%BE%93%E5%87%BAtensor%E4%BD%9C%E4%B8%BA%E5%8F%82%E6%95%B0"><span class="toc-text">提供输出tensor作为参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9B%BF%E6%8D%A2"><span class="toc-text">替换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#torch-view-%E5%8F%AF%E4%BB%A5%E6%94%B9%E5%8F%98%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BB%B4%E5%BA%A6%E5%92%8C%E5%A4%A7%E5%B0%8F"><span class="toc-text">torch.view: 可以改变张量的维度和大小</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%AA%E6%9C%89%E4%B8%80%E4%B8%AA%E5%85%83%E7%B4%A0%E7%9A%84%E5%BC%A0%E9%87%8F%EF%BC%8C%E4%BD%BF%E7%94%A8-item-%E6%9D%A5%E5%BE%97%E5%88%B0Python%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%95%B0%E5%80%BC"><span class="toc-text">只有一个元素的张量，使用.item()来得到Python数据类型的数值</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NumPy-%E8%BD%AC%E6%8D%A2"><span class="toc-text">NumPy 转换</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#numpy%E6%95%B0%E7%BB%84%E7%9A%84%E5%80%BC%E6%98%AF%E5%A6%82%E4%BD%95%E6%94%B9%E5%8F%98%E7%9A%84%E3%80%82"><span class="toc-text">numpy数组的值是如何改变的。</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8from-numpy%E8%87%AA%E5%8A%A8%E8%BD%AC%E5%8C%96"><span class="toc-text">使用from_numpy自动转化</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CUDA-%E5%BC%A0%E9%87%8F"><span class="toc-text">CUDA 张量</span></a></li></ol>
                </div>
            </div>
        </div>

        <div class="row">
            <!-- Sidebar Container -->

            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <!-- no hr -->
                    <h5 class="text-center">
                        <a href="/tags/">FEATURED TAGS</a>
                    </h5>
                    <div class="tags">
                        
                        <a class="tag" href="/tags/#学习"
                           title="学习">学习</a>
                        
                        <a class="tag" href="/tags/#记录"
                           title="记录">记录</a>
                        
                        <a class="tag" href="/tags/#经验"
                           title="经验">经验</a>
                        
                        <a class="tag" href="/tags/#Pytorch"
                           title="Pytorch">Pytorch</a>
                        
                    </div>
                </section>
                

                <!-- Friends Blog -->
                
            </div>
        </div>

    </div>
</article>







<!-- Footer -->
<!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 text-center">
                <br>
                <ul class="list-inline text-center">
                
                
                

                

                

                
                    <li>
                        <a target="_blank"  href="https://github.com/Ao021">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; Dante-Game 2022
                    <br>
                    <span id="busuanzi_container_site_pv" style="font-size: 12px;">PV: <span id="busuanzi_value_site_pv"></span> Times</span>
                    <br>
                    Theme by <a target="_blank" rel="noopener" href="https://haojen.github.io/">Haojen Ma</a>
                </p>

            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->

<script src="/js/jquery.min.js"></script>


<!-- Bootstrap Core JavaScript -->

<script src="/js/bootstrap.min.js"></script>


<!-- Custom Theme JavaScript -->

<script src="/js/blog.js"></script>


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("https://www.dante-game.com.cn/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("//cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>



<!-- Google Analytics -->



<!-- Baidu Tongji -->


<!-- swiftype -->
<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install','','2.0.0');
</script>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<!--wechat title img-->
<img class="wechat-title-img" src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220902170530.png">
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>

</html>
