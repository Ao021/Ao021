<!DOCTYPE html>
<html lang="en">


<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, user-scalable=no">
  <title>
    Pytorch学习笔记--张量 | Dante的个人博客
  </title>
  <meta name="description" content="">
  
  <meta name="keywords" content="
  学习,记录,经验,Pytorch
  ">
  
  <meta name="author" content="Dante">

  <meta http-equiv="Cache-Control" content="no-transform"/>
  <meta http-equiv="Cache-Control" content="no-siteapp">
  <meta name="theme-color" content="#1e2327">
  <link rel="apple-touch-icon" href="https://github.githubassets.com/apple-touch-icon.png">
  <link rel="apple-touch-icon" sizes="180x180" href="https://github.githubassets.com/apple-touch-icon-180x180.png">

  <link rel="icon" type="image/x-icon" href="https://github.githubassets.com/favicon.ico">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="stylesheet"
        href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  

  

  <script src="//cdnjs.cloudflare.com/ajax/libs/vue/1.0.25-csp/vue.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/moment.js/2.11.2/moment.min.js"></script>
<meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="Dante的个人博客" type="application/atom+xml">
</head>

<body id="replica-app">

<nav class="navbar-wrapper">
  <div class="navbar">
    <div class="container clearfix">
      <a href="/" class="navbar-logo"><i class="fa fa-github"></i></a>

      <div class="navbar-search float-left desktop-only">
        <div class="navbar-search-form">
          <label for="gsc-i-id1">This website</label>
          <div id="google-search">
            <gcse:search></gcse:search>
          </div>
        </div>
      </div>

      <ul class="navbar-nav float-left">
        
        <li><a href="/">Archives</a></li>
        
        
        <li><a href="/">Categories</a></li>
        
        
        <li><a href="/">Tags</a></li>
        
        
        <li class="desktop-only"><a href="/atom.xml" target="_blank">RSS</a></li>
        
      </ul>

      <ul class="navbar-nav user-nav float-right desktop-only">
        <li class="user-nav-notification">
          <a><span class="user-nav-unread"></span><i class="fa fa-bell"></i></a>
        </li>
        <li>
          <a><i class="fa fa-plus"></i> <i class="fa fa-caret-down"></i></a>
        </li>
        <li class="user-nav-logo">
          <a><img src="https://octodex.github.com/images/baracktocat.jpg"> <i class="fa fa-caret-down"></i></i></a>
        </li>
      </ul>
    </div>
  </div>
</nav>

<div class="main-container">
  <header class="header-wrapper desktop-only">
  <div class="container header-site-detail">
    <ul class="header-toolbar">
      <li class="clearfix">
        <a href="/" class="header-toolbar-left"><i
                  class="fa fa-file-text"></i> Posts </a>
        <a href="/"
           class="header-toolbar-right"> 21 </a>
      </li>
      <li>
        <a href="/" class="header-toolbar-left"><i
                  class="fa fa-tags"></i> Tags </a>
        <a href="/"
           class="header-toolbar-right"> 9 </a>
      </li>
      <li>
        <a href="/" class="header-toolbar-left"><i
                  class="fa fa-folder-open"></i> Categories </a>
        <a href="/"
           class="header-toolbar-right"> 4 </a>
      </li>
    </ul>
    <h2 class="header-title">
      <i class="fa fa-book text-muted"></i>
      <a href="/">Dante的个人博客</a>
      
      
    </h2>
  </div>

  <div class="container">
    <div class="header-tab-wrapper clearfix">
      <span class="header-tab header-tab-selected"><i class="fa fa-thumbs-o-up"></i> Like</span>
      <span class="header-tab"><i class="fa fa-share-alt"></i> Share</span>
      <span class="header-tab"><i class="fa fa-comments-o"></i> Discussion</span>
      <span class="header-tab"><i class="fa fa-bookmark-o"></i> Bookmark </span>
      <span class="header-tab"><i class="fa fa-smile-o"></i> Smile <i class="fa fa-caret-down"></i></span>
    </div>
  </div>
</header>


<div class="post-container container">
  <h3>
    <i class="fa fa-user-o"></i>
    Dante

    <span class="post-date float-right" title="{{moment(1611757874000).format('MMM DD, YYYY, h:mm:ss A')}}">
      
          <i class="fa fa-pencil-square-o"></i>
      
      {{moment(1611757874000).fromNow()}}
    </span>
  </h3>

  <article class="post-content">
    <h1>Pytorch学习笔记--张量</h1>
    <h2 id="PyTorch是什么"><a href="#PyTorch是什么" class="headerlink" title="PyTorch是什么"></a>PyTorch是什么</h2><p>基于Python的科学计算包，服务于以下两种场景:</p>
<ul>
<li>作为NumPy的替代品，可以使用GPU的强大计算能力</li>
<li>提供最大的灵活性和高速的深度学习研究平台</li>
</ul>
<a id="more"></a>
<h2 id="Tensors-张量"><a href="#Tensors-张量" class="headerlink" title="Tensors 张量"></a>Tensors 张量</h2><h3 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h3><p>Tensors与Numpy中的 ndarrays类似，但是在PyTorch中 Tensors 可以使用GPU进行计算.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from __future__ import print_function</span><br><span class="line">import torch</span><br></pre></td></tr></table></figure></p>
<h4 id="创建一个-5x3-矩阵-但是未初始化"><a href="#创建一个-5x3-矩阵-但是未初始化" class="headerlink" title="创建一个 5x3 矩阵, 但是未初始化:"></a>创建一个 5x3 矩阵, 但是未初始化:</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x &#x3D; torch.empty(5, 3)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.0000, 0.0000, 0.0000],  </span><br><span class="line">        [0.0000, 0.0000, 0.0000],  </span><br><span class="line">        [0.0000, 0.0000, 0.0000],  </span><br><span class="line">        [0.0000, 0.0000, 0.0000],  </span><br><span class="line">        [0.0000, 0.0000, 0.0000]])</span><br></pre></td></tr></table></figure>
<h4 id="创建一个随机初始化的矩阵"><a href="#创建一个随机初始化的矩阵" class="headerlink" title="创建一个随机初始化的矩阵:"></a>创建一个随机初始化的矩阵:</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x &#x3D; torch.rand(5, 3)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.6972, 0.0231, 0.3087],</span><br><span class="line">        [0.2083, 0.6141, 0.6896],</span><br><span class="line">        [0.7228, 0.9715, 0.5304],</span><br><span class="line">        [0.7727, 0.1621, 0.9777],</span><br><span class="line">        [0.6526, 0.6170, 0.2605]])</span><br></pre></td></tr></table></figure>
<h4 id="创建一个0填充的矩阵，数据类型为long"><a href="#创建一个0填充的矩阵，数据类型为long" class="headerlink" title="创建一个0填充的矩阵，数据类型为long:"></a>创建一个0填充的矩阵，数据类型为long:</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x &#x3D; torch.zeros(5, 3, dtype&#x3D;torch.long)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0]])</span><br></pre></td></tr></table></figure>
<h4 id="创建tensor并使用现有数据初始化"><a href="#创建tensor并使用现有数据初始化" class="headerlink" title="创建tensor并使用现有数据初始化:"></a>创建tensor并使用现有数据初始化:</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x &#x3D; torch.tensor([5.5, 3])</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([5.5000, 3.0000])</span><br></pre></td></tr></table></figure>
<h4 id="根据现有的张量创建张量。-这些方法将重用输入张量的属性，例如，-dtype，除非设置新的值进行覆盖"><a href="#根据现有的张量创建张量。-这些方法将重用输入张量的属性，例如，-dtype，除非设置新的值进行覆盖" class="headerlink" title="根据现有的张量创建张量。 这些方法将重用输入张量的属性，例如， dtype，除非设置新的值进行覆盖"></a>根据现有的张量创建张量。 这些方法将重用输入张量的属性，例如， dtype，除非设置新的值进行覆盖</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x &#x3D; x.new_ones(5, 3, dtype&#x3D;torch.double)      # new_* 方法来创建对象</span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line">x &#x3D; torch.randn_like(x, dtype&#x3D;torch.float)    # 覆盖 dtype!</span><br><span class="line">print(x)                                      #  对象的size 是相同的，只是值和类型发生了变化</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1., 1., 1.],</span><br><span class="line">        [1., 1., 1.],</span><br><span class="line">        [1., 1., 1.],</span><br><span class="line">        [1., 1., 1.],</span><br><span class="line">        [1., 1., 1.]], dtype&#x3D;torch.float64)</span><br><span class="line">tensor([[ 0.5691, -2.0126, -0.4064],</span><br><span class="line">        [-0.0863,  0.4692, -1.1209],</span><br><span class="line">        [-1.1177, -0.5764, -0.5363],</span><br><span class="line">        [-0.4390,  0.6688,  0.0889],</span><br><span class="line">        [ 1.3334, -1.1600,  1.8457]])</span><br></pre></td></tr></table></figure>
<h4 id="获取-size"><a href="#获取-size" class="headerlink" title="获取 size"></a>获取 size</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x.size())</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([5, 3])</span><br></pre></td></tr></table></figure>
<h2 id="张量的操作"><a href="#张量的操作" class="headerlink" title="张量的操作"></a>张量的操作</h2><h3 id="加法"><a href="#加法" class="headerlink" title="加法"></a>加法</h3><h4 id="加法1"><a href="#加法1" class="headerlink" title="加法1"></a>加法1</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y &#x3D; torch.rand(5, 3)</span><br><span class="line">print(x + y)</span><br></pre></td></tr></table></figure>
<h4 id="加法2"><a href="#加法2" class="headerlink" title="加法2"></a>加法2</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(torch.add(x, y))</span><br></pre></td></tr></table></figure>
<h4 id="提供输出tensor作为参数"><a href="#提供输出tensor作为参数" class="headerlink" title="提供输出tensor作为参数"></a>提供输出tensor作为参数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">result &#x3D; torch.empty(5, 3)</span><br><span class="line">torch.add(x, y, out&#x3D;result)</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>
<h4 id="替换"><a href="#替换" class="headerlink" title="替换"></a>替换</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.add_(x)</span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>任何 以<code>_</code> 结尾的操作都会用结果替换原变量. 例如: <code>x.copy_(y)</code>, <code>x.t_()</code>, 都会改变 <code>x</code>.这里便是 y+=x</p>
</blockquote>
<h4 id="torch-view-可以改变张量的维度和大小"><a href="#torch-view-可以改变张量的维度和大小" class="headerlink" title="torch.view: 可以改变张量的维度和大小"></a>torch.view: 可以改变张量的维度和大小</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x &#x3D; torch.randn(4, 4)</span><br><span class="line">y &#x3D; x.view(16)</span><br><span class="line">z &#x3D; x.view(-1, 8)  #  size -1 从其他维度推断</span><br><span class="line">print(x.size(), y.size(), z.size())</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])</span><br></pre></td></tr></table></figure>
<h4 id="只有一个元素的张量，使用-item-来得到Python数据类型的数值"><a href="#只有一个元素的张量，使用-item-来得到Python数据类型的数值" class="headerlink" title="只有一个元素的张量，使用.item()来得到Python数据类型的数值"></a>只有一个元素的张量，使用.item()来得到Python数据类型的数值</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x &#x3D; torch.randn(1)</span><br><span class="line">print(x)</span><br><span class="line">print(x.item())</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([-0.2368])</span><br><span class="line">-0.23680149018764496</span><br></pre></td></tr></table></figure>
<h2 id="NumPy-转换"><a href="#NumPy-转换" class="headerlink" title="NumPy 转换"></a>NumPy 转换</h2><p>将一个Torch Tensor转换为NumPy数组是一件轻松的事，反之亦然。<br>Torch Tensor与NumPy数组共享底层内存地址，修改一个会导致另一个的变化。<br><br><br>将一个Torch Tensor转换为NumPy数组<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a &#x3D; torch.ones(5)</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure><br><code>tensor([1., 1., 1., 1., 1.])</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b &#x3D; a.numpy()</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure><br><code>[1. 1. 1. 1. 1.]</code><br><br></p>
<h3 id="numpy数组的值是如何改变的。"><a href="#numpy数组的值是如何改变的。" class="headerlink" title="numpy数组的值是如何改变的。"></a>numpy数组的值是如何改变的。</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a.add_(1)</span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([2., 2., 2., 2., 2.])</span><br><span class="line">[2. 2. 2. 2. 2.]</span><br></pre></td></tr></table></figure>
<h4 id="使用from-numpy自动转化"><a href="#使用from-numpy自动转化" class="headerlink" title="使用from_numpy自动转化"></a>使用from_numpy自动转化</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">a &#x3D; np.ones(5)</span><br><span class="line">b &#x3D; torch.from_numpy(a)</span><br><span class="line">np.add(a, 1, out&#x3D;a)</span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[2. 2. 2. 2. 2.]</span><br><span class="line">tensor([2., 2., 2., 2., 2.], dtype&#x3D;torch.float64)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>所有的 Tensor 类型默认都是基于CPU， CharTensor 类型不支持到 NumPy 的转换.</p>
<h2 id="CUDA-张量"><a href="#CUDA-张量" class="headerlink" title="CUDA 张量"></a>CUDA 张量</h2><p>使用.to 方法 可以将Tensor移动到任何设备中<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># is_available 函数判断是否有cuda可以使用</span><br><span class="line"># &#96;&#96;torch.device&#96;&#96;将张量移动到指定的设备中</span><br><span class="line">if torch.cuda.is_available():</span><br><span class="line">    device &#x3D; torch.device(&quot;cuda&quot;)          # a CUDA 设备对象</span><br><span class="line">    y &#x3D; torch.ones_like(x, device&#x3D;device)  # 直接从GPU创建张量</span><br><span class="line">    x &#x3D; x.to(device)                       # 或者直接使用&#96;&#96;.to(&quot;cuda&quot;)&#96;&#96;将张量移动到cuda中</span><br><span class="line">    z &#x3D; x + y</span><br><span class="line">    print(z)</span><br><span class="line">    print(z.to(&quot;cpu&quot;, torch.double))       # &#96;&#96;.to&#96;&#96; 也会对变量的类型做更改</span><br></pre></td></tr></table></figure><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([0.7632], device&#x3D;&#39;cuda:0&#39;)</span><br><span class="line">tensor([0.7632], dtype&#x3D;torch.float64)</span><br></pre></td></tr></table></figure></p>
</blockquote>

  </article>
</div>


    




</div>

<div class="footer-wrapper container">
  <footer class="footer clearfix">
    <div class="clearfix">
    <a href="http://dante-game.com.cn" class="footer-logo">
      <i class="fa fa-github"></i>
    </a>
    <ul class="footer-social-link">
      <li>© 2019 Dante</li>
      <li><a href="http://dante-game.com.cn">Home</a></li>
      
    </ul>
    <div class="footer-theme-info">
      Theme <a target="_blank" rel="noopener" href="//github.com/sabrinaluo/hexo-theme-replica">Replica</a>
      by <a target="_blank" rel="noopener" href="//github.com/sabrinaluo">Hiitea</a> ❤ Powered by Hexo
    </div>
    </div>
    
  </footer>
</div>




<script src="/js/main.js"></script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
