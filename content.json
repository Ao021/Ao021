{"pages":[{"title":"分类","text":"","link":"/categories/index.html"}],"posts":[{"title":"OpenGL(glut包)在Visual Studio配置","text":"OpenGL(glut包)在Visual Studio配置1.glut下载 下载链接 2.环境配置 下载好会有如下文件 .h 文件 glut.h 放入路径 C:\\Program Files (x86) \\ Microsoft Visual Studio \\ (VS版本如2019) \\ (VS版本如community/professional/Enterprise) \\ VC \\ Tools \\ MSVC \\ 14.28.29333 (版本号) \\ include \\ GL \\，GL是文件夹手动创建的。 .lib 文件 glut32.lib 放入路径 C:\\Program Files (x86) \\ Microsoft Visual Studio \\ (VS版本如2019) \\ (VS版本如community/professional/Enterprise) \\ VC \\ Tools \\ MSVC \\ 14.28.29333 (版本号) \\ lib \\ x86 \\ glut32.lib 放入路径 C:\\Program Files (x86) \\ Microsoft Visual Studio \\ (VS版本如2019) \\ (VS版本如community/professional/Enterprise) \\ VC \\ Tools \\ MSVC \\ 14.28.29333 (版本号) \\ lib \\ x64 \\ .dll 文件glut.dll 和 glut32.dll 放入C:\\ Windows \\ SysWOW64 \\glut32.dll 放入 C:\\ Windows \\ System32 \\ 参考blog","link":"/2021/03/04/OpenGL(glut%E5%8C%85)%E5%9C%A8Visual%20Studio%E9%85%8D%E7%BD%AE/"},{"title":"OpenGL GLFW, GLAD 在 Visual Studio 配置","text":"GLFW下载GLFW下载地址 下载好后解压解压 github下载可能略慢,建议翻墙 下载CMake下载地址下载好后解压,打开’bin/cmake-gui.exe’我们现在需要一个源代码目录(即之前下好的glfw)和一个存放编译结果的目标文件目录(新建一个build文件夹) 注意路径不要有中文Configure(设置)按钮,选择VS2019 16,然后保存 最后点击Generate(生成)按钮，生成的工程文件会在你的build文件夹中 编译在build文件夹里可以找到GLFW.sln文件，用VS打开,直接生成解决方案glfw3.lib 就会出现在 src/Debug glfw3.lib 放入路径 C:\\Program Files (x86) \\ Microsoft Visual Studio \\ (VS版本如2019) \\ (VS版本如community/professional/Enterprise) \\ VC \\ Tools \\ MSVC \\ 14.28.29333 (版本号) \\ lib \\ x86或者x64 \\ 取决于编译,建议使用x32 将glfw-3.3.3\\include\\GLFW 整个文件夹放入路径 C:\\Program Files (x86) \\ Microsoft Visual Studio \\ (VS版本如2019) \\ (VS版本如community/professional/Enterprise) \\ VC \\ Tools \\ MSVC \\ 14.28.29333 (版本号) \\ include 链接在VS项目-&gt;工程属性-&gt;连接器-&gt;输入(input)-&gt;附加依赖项(第一项)添加glfw3.lib GLAD配置GLAD打开GLAD在线服务设置如下后generate,下载提供的zip文件,解压把glad\\include中的2个文件夹放入路径C:\\Program Files (x86) \\ Microsoft Visual Studio \\ (VS版本如2019) \\ (VS版本如community/professional/Enterprise) \\ VC \\ Tools \\ MSVC \\ 14.28.29333 (版本号) \\ include 把glad.c添加到工程文件中最后你就能将以下的指令加到你的文件顶部了1#include &lt;glad/glad.h&gt;","link":"/2021/03/08/OpenGL%20%20GLFW,%20GLAD%20%E5%9C%A8%20Visual%20Studio%20%E9%85%8D%E7%BD%AE/"},{"title":"OpenGL_02_向量和矩阵","text":"向量和矩阵默认大家都学过向量和矩阵,这里就记录一些核心的东西 向量向量点积(dot product)向量点积，也称为向量的数量积，点积的结果是一个标量，其定义为$|\\ A\\ |\\cdot{|\\ B\\ |\\cos\\theta}$,其几何意义如下,一般用于计算投影和夹角 向量的叉积(cross product)两个向量a和b的叉积,结果是一个向量$c=a×b$,c的方向垂直于a和b，据右手规则来确定；c的大小等于 $|c| = |a||b|\\sin\\theta$ $a×b=−b×a$ 在利用以坐标形式表示向量a和b时，在3D空间中，叉积的结果用矩阵表示为:$c = a×b\\=\\begin{bmatrix}i&amp;j&amp;k\\a_x&amp;a_y&amp;a_z\\b_x&amp;b_y&amp;b_z\\\\end{bmatrix} $ $=\\begin{bmatrix}a_y&amp;a_z\\b_y&amp;b_z\\end{bmatrix}i-\\begin{bmatrix}a_x&amp;a_z\\b_x&amp;b_z\\end{bmatrix}j+\\begin{bmatrix}a_x&amp;a_y\\b_x&amp;b_y\\end{bmatrix}k$ $=\\begin{bmatrix}a_yb_z-a_zb_y\\a_xb_z-a_zb_x\\a_xb_y-a_yb_x\\end{bmatrix}$ 其中 i,j,k为x,y,z三个方向上的单位向量 叉积的几何意义叉积的模可以视为以a和b为两边的平行四边形的面积，如下图所示同时在OpenGL中还可以用来确定第三个方向 $up=dir×side$ 矩阵矩阵和矩阵乘法向量的点积公式可以重新表示为:$a=(a1,b2,⋯,cn),\\ b=(b1,b2,⋯,bn)$ $a\\cdot{b}=a1b_1+a_2b_2+\\dots+a_nb_n\\$$=\\sum{i=1}^na_ib_i\\$$=a^Tb$ 行列式 逆矩阵对于n阶方阵A，如果存在一个n阶方阵B使得:$AB=BA=I_{nxn}$ 逆矩阵的应用意义在3D图形处理中，用一个变换矩阵乘以向量，代表了对原始图形进行了某种变换，例如缩小，旋转等，逆矩阵表示这个操作的逆操作，也就是能够撤销这一操作。例如对一个向量$v$用矩阵$M$相乘，然后再用$M^{−1}$相乘，则能得到原来的向量$v$ 注意转换矩阵应用顺序 当用矩阵$A,B,C$转换向量$v$时，如果$v$用行向量记法，则矩阵按转换顺序从左往右列出，表达为$vABC$;如果$v$采用列向量记法，则转换矩阵应该放在左边，并且转换从右往左发生，对应的转换记为$CBAv$ 正交矩阵对于方阵M，当且仅当$M$与其转置矩阵$M^T$的乘积等于单位矩阵时，称其为正交矩阵。即：$MM^T=E$正交矩阵的一大优势在于，计算逆矩阵时，只需要对原矩阵转置即可，从而减少了计算量。在3D图形处理中的旋转和镜像变换都是正交的 正交矩阵一定是可逆的","link":"/2021/05/24/OpenGL-02-%E5%90%91%E9%87%8F%E5%92%8C%E7%9F%A9%E9%98%B5/"},{"title":"OpenGL_03_坐标系统与摄像机","text":"坐标系统与摄像机本篇简单的记录了关于坐标系统的机制与摄像机,为了方便理解去掉了数学内容,详细的后面会写 坐标系统 我们先来认识这张图,为了将坐标从一个坐标系转换到另一个坐标系，我们需要用到几个转换矩阵，最重要的几个分别是模型(Model) 、视图(View) 、投影(Projection) 三个矩阵。首先，顶点坐标开始于局部空间(Local Space) ，称为局部坐标(Local Coordinate) ，然后经过世界坐标(World Coordinate) ，观察坐标(View Coordinate) ，裁剪坐标(Clip Coordinate) ，并最后以屏幕坐标(Screen Coordinate) 结束。 我们先理解每个矩阵的作用,从开始到结尾一共经过了四个过程: Model Matrix View Matrix Projection Matrix Viewport Transform Model Matrix我们知道模型坐标以点位置的形式传入着色器, 这些点的参考原点就是本地坐标的原点,即使模型做了变化,这些变化都是相对于原点的变化. 可以理解为3D软件中模型中心点的意思,我们的操作都是以中心点为参照进行的 View Matrix显然,这样并不能让模型很直观的显示出来,所以我们需要一个View Matrix来设置一个摄像机来观察模型,具体会在下一个点提到. Projection Matrix我们现在得到了View Space,但这样的视图显然并不是我们想要的最终结果. 通过Projection Matrix我们将指定范围的坐标转换到标准化设备坐标系中(-1,1). 这是一个投影(Projection)的过程, 他会减裁掉多余的坐标保留我们所看到的部分,得到裁剪坐标(Clip Coordinate). 投影矩阵除了起到减裁的作用,还能够指定投影的方式, 正射投影(Orthographic Projection) 将坐标以正交的方式投影到标准坐标系,呈现中国画的透视关系;而透视投影(Perspective Projection) 创建一定角度的平截头体来实现我们人眼所见的透视关系,如下图: 我们可以简单看看代码 正射投影glm::ortho(0.0f, 800.0f, 0.0f, 600.0f, 0.1f, 100.0f);前两个参数指定了平截头体的左右坐标，第三和第四参数指定了平截头体的底部和上部,第五和第六个参数则定义了近平面和远平面的距离。这个指定的投影矩阵将处于这些x，y，z范围之间的坐标转换到标准化设备坐标系中。 透视投影glm::mat4 proj = glm::perspective(45.0f, (float)width/(float)height, 0.1f, 100.0f);它的第一个参数定义了fov 的值,第二个参数设置了宽高比，第三和第四个参数设置了平截头体的近和远平面。 如果只是片段的一部分例如三角形，超出了裁剪体积(Clipping Volume)，则OpenGL会重新构建三角形以使一个或多个三角形能适应在裁剪范围内。 Viewport Transform 一旦所有顶点被转换到裁剪空间，最终的操作——透视划分(Perspective Division) 将会执行，在这个过程中我们将位置向量的x，y，z分量分别除以向量的齐次w分量；透视划分是将4维裁剪空间坐标转换为3维标准化设备坐标。这一步会在每一个顶点着色器运行的最后被自动执行。 在这一阶段之后，坐标经过转换的结果将会被映射到屏幕空间(由glViewport设置)且被转换成片段。 $V{clip} = M{projection} \\cdot M{view} \\cdot M{model} \\cdot V_{local}$就是这些矩阵变化的最终组合,他将被传入着色器 12345678910111213#version 330 corelayout (location = 0) in vec3 position;...uniform mat4 model;uniform mat4 view;uniform mat4 projection;void main(){ // 注意从右向左读 gl_Position = projection * view * model * vec4(position, 1.0f); ...} 摄像机摄像机如何才能满足我们的需求呢, 我们不妨摄像摄像机所需的参数: 摄像机的位置, 摄像机的方向, 摄像机的变换 摄像机的位置我们通过对目标的相对移动来控制摄像机的位置, 故我们可以相对于原点传入摄像机位置的反方向. 摄像机的方向我们可以指定目标的位置,通过向量相减我们可以得到摄像机的朝向向量,反之亦然 摄像机的变换我们在各种三维软件中所认识的摄像机都能通过各种变换来得到一个理想的视角, 想要进行这些变换就需要对摄像机进行矩阵运算,但现在我们并没有一个属于摄像机的坐标空间, 所以我们要利用前面向量和矩阵中的方法来建立一个摄像机坐标空间 我们需要的另一个向量是一个右向量(Right Vector)，它代表摄像机空间的x轴的正方向。为获取右向量我们需要先使用一个小技巧：定义一个上向量(Up Vector)。我们把上向量和第二步得到的摄像机方向向量进行叉乘。两个向量叉乘的结果就是同时垂直于两向量的向量，因此我们会得到指向x轴正方向的那个向量(如果我们交换两个向量的顺序就会得到相反的指向x轴负方向的向量)： 现在我们已经有了x轴向量和z轴向量，获取摄像机的正y轴相对简单；我们把右向量和方向向量(Direction Vector)进行叉乘; 123glm::vec3 up = glm::vec3(0.0f, 1.0f, 0.0f); glm::vec3 cameraRight = glm::normalize(glm::cross(up, cameraDirection));glm::vec3 cameraUp = glm::cross(cameraDirection, cameraRight); 可以简单的看看官方给出的源码理解下","link":"/2021/05/25/OpenGL-03-%E5%9D%90%E6%A0%87%E7%B3%BB%E7%BB%9F%E4%B8%8E%E6%91%84%E5%83%8F%E6%9C%BA/"},{"title":"OpenGL_01_OpenGL的绘图基本流程与概念","text":"OpenGL的绘图基本流程与概念前言本博客仅记录本人的理解全部内容来源于OpenGL与GLSL以及傅老师OpenGL课程如有问题,欢迎评论 图形渲染管线 图形渲染管线可以被划分为两个主要部分： 第一部分把你的3D坐标转换为2D坐标 第二部分是把2D坐标转变为实际的有颜色的像素。 分别对应第一排和第二排,实际学习中我们基本只用关注vertex shader和fragment shader,其他暂且不管 而图形渲染管线的输入便是顶点数据(vertex data),可以包含空间位置,颜色,uv等等信息 GPU与CPU首先我们需要对CPU与GPU有一定的认识,打个比方CPU就像是精英怪或者BOSS,GPU就像是小兵,GPU有着很高的性能,但对于大量的简单运算就显得CPU势单力薄,而GPU却能很好的解决这些问题,GPU有着庞大的基数,虽然每个GPU只能进行简单的运算和处理,但处理大量简单运算时速度就比孤军奋战的CPU快很多.所以在OpenGL中我们使用GPU来处理庞大的顶点数据,而这些运行在GPU的程序被称为shader也就是着色器. VAO与VBO所以我们来看这样一幅图 VBO (顶点缓冲对象 [Vertex Buffer Objects] )CPU中的顶点数据通过一系列过程传输到GPU,为了节省CPU宝贵的内存,传输到GPU的数据会以数组的形式被立即保存在VBO中使用这些缓冲对象的好处是我们可以一次性的发送一大批数据到显卡上，而不是每个顶点发送一次。从CPU把数据发送到显卡相对较慢，所以只要可能我们都要尝试尽量一次性发送尽可能多的数据。当数据发送至显卡的内存中后，顶点着色器几乎能立即访问顶点，这是个非常快的过程。 VAO (顶点数组对象 [Vertex Array Object] )顶点着色器允许我们指定任何以顶点属性为形式的输入.我们传入VBO的数组有顶点位置有颜色有uv等各种信息,显然我们的顶点着色器是无法区分这些信息的.所以我们需要用VAO来让顶点着色器认识我们VBO数组中传入的信息都是些什么.我们的顶点缓冲数据会被解析为下面这样子：我们会指定每几个数据位一个顶点,如图中每3个数据为一个顶点的位置,如果有多个类型的数据,比如0,1,2为位置数据;3,4,5为颜色数据;6,7为uv数据,我们就需要指定8为一个步长,其中前三个为位置数据,偏移量为3的3个数据为颜色数据;偏移量为6的2个数据为uv数据.将这些标注好后VAO就像下图一样 EBO(索引缓冲对象 [ Element Buffer Object] 也叫 [Index Buffer Object，IBO] )我们回到最开始的那张图,可以看出VAO除了Array buffer 还有一个Element Buffer.在用glDrawArrays(GL_TRIANGLES)绘图时,如果我们只指定Array buffer,那么OpenGL就会以数组的顺序挨个逆时针以三角形的形式绘制这些顶点. 如果我们的图形较为复杂,这意味着会有很多重复的顶点出现,这会让我们的数组显得非常冗长,这时候我们可以定义一个EBO用来指定绘制顺序,如[0,1,2,1,0,2]就是以0,1,2的顺序绘制第一个三角形,再以1,0,2的顺序绘制第二个三角形 注意:当目标是GL_ELEMENT_ARRAY_BUFFER的时候，VAO会储存glBindBuffer的函数调用。这也意味着它也会储存解绑调用，所以确保你没有在解绑VAO之前解绑索引数组缓冲，否则它就没有这个EBO配置了。 着色器 Shader之前已经提到,着色器就是运行在GPU中的一个一个小程序.目前我们主要使用顶点着色器(vertex shader)和片段着色器(fragment shader).对于着色器,我们采用的是GLSL语言(OpenGL Shading Language)编写的程序,类似于C语言程序。要使用着色器需要经历3个步骤: 创建和编译shader object 创建shader program,链接多个shader object到program 在绘制场景时启用shader program具体流程如下图所示:我们可以通过两个简单的顶点着色器代码来认识Shader 顶点着色器12345678#version 330 // 指定GLSL版本3.3layout(location = 0) in vec3 position; // 顶点属性索引void main(){ gl_Position = vec4(position, 1.0); // 输出顶点} 片段着色器12345678#version 330out vec4 color; // 输出片元颜色void main(){ color = vec4(0.8, 0.8, 0.0, 1.0);} 着色器程序通过in 和 out也就是输入与输出连成一条线; 我们的顶点数据通过in传入顶点着色器然后输出顶点,然后顶点着色器的out通过片段着色器的in传入片段着色器并进行输出 这里由于传入的数据没有颜色数据,所以在片段着色器的main中指定了一个颜色 代码由于qt和glfw语法略有不同, 且官网有具体代码, 这里只介绍流程 12345671.加载库2.创建窗口3.传入数据4.定义VBO,并传入数据5.定义VAO,并链接VBO6.创建着色器程序7.创建引擎(渲染与其他操作) 状态机 OpenGL自身是一个巨大的状态机状态机(State Machine)一系列的变量描述OpenGL此刻应当如何运行。OpenGL的正在运行的状态通常被称为OpenGL上下文(Context)。我们通常使用如下途径去更改OpenGL状态：设置选项，操作缓冲。最后，我们使用当前OpenGL上下文来渲染。假设当我们想告诉OpenGL去画线段而不是三角形的时候，我们通过改变一些上下文变量来改变OpenGL状态，从而告诉OpenGL如何去绘图。一旦我们改变了OpenGL的状态为绘制线段，下一个绘制命令就会画出线段而不是三角形。所以OpenGL本质上是个大状态机下图是之前所提到的内容用状态机来表示的示例,我们可以通过glEnable来操作状态机里的各种状态 VAO只能绑定一个VBO,所以如果有其他数据,需要解绑当前的VBO在bind所需VBO 对象OpenGL库是用C语言写的，内核是一个C库。由于C的一些语言结构不易被翻译到其它的高级语言，因此OpenGL开发的时候引入了一些抽象层。“对象(Object)”就是其中一个。在OpenGL中一个对象是指一些选项的集合，它代表OpenGL状态的一个子集。比如，我们可以用一个对象来代表绘图窗口的设置，之后我们就可以设置它的大小、支持的颜色位数等等。可以把对象看做一个C风格的结构体(Struct)：12345struct object_name { float option1; int option2; char[] name;};当我们使用一个对象时，通常看起来像如下一样（把OpenGL上下文看作一个大的结构体）：123456// OpenGL的状态struct OpenGL_Context { ... object* object_Window_Target; ... };12345678910// 创建对象unsigned int objectId = 0;glGenObject(1, &amp;objectId);// 绑定对象至上下文glBindObject(GL_WINDOW_TARGET, objectId);// 设置当前绑定到 GL_WINDOW_TARGET 的对象的一些选项glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_WIDTH, 800);glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_HEIGHT, 600);// 将上下文对象设回默认,解绑对象glBindObject(GL_WINDOW_TARGET, 0);","link":"/2021/05/24/OpenGL_01_OpenGL%E7%9A%84%E7%BB%98%E5%9B%BE%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B%E4%B8%8E%E6%A6%82%E5%BF%B5/"},{"title":"PicGo GitHub图床设置","text":"PicGo GitHub图床设置 创建一个仓库,用于存储图片 生成一个token,点击github右上角头像选项的Settings/Developer settings/Personal access tokens,点击generate new token生成token generate token后记得复制显示的token,只会出现这一次,如果忘记了需要regenerate 最后设置图床信息,仓库名为 用户名/仓库名形式,分支名为master,token为之前复制的一长串 加速图床,由于GitHub国内访问速度很慢,在自定义域名加上https://cdn.jsdelivr.net/gh/用户名/仓库名 最后保存就ok了","link":"/2021/03/04/PicGo%20GitHub%E5%9B%BE%E5%BA%8A%E8%AE%BE%E7%BD%AE/"},{"title":"Pytorch学习笔记-pip安装python模块使用国内镜像","text":"镜像源由于pip install 都是从海外源下载,正常的 install 很慢使用国内的镜像源会大幅度提升 install 速度 以下的国内的一些镜像源 镜像源：豆瓣：https://pypi.douban.com/simple/清华：https://pypi.douban.com/simple/阿里：https://pypi.douban.com/simple/中国科技大学 ：https://pypi.douban.com/simple/ 使用方法 方法1pip install 模块名 -i 以上镜像源网址 方法2在user目录中创建一个pip目录，如：C:\\Users\\用户名\\pip，新建文件pip.ini，内容如下 12 [global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple url内容可以任意更换为以上源 参考blog","link":"/2021/03/02/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-pip%E5%AE%89%E8%A3%85python%E6%A8%A1%E5%9D%97%E4%BD%BF%E7%94%A8%E5%9B%BD%E5%86%85%E9%95%9C%E5%83%8F/"},{"title":"Pytorch学习笔记--张量","text":"PyTorch是什么基于Python的科学计算包，服务于以下两种场景: 作为NumPy的替代品，可以使用GPU的强大计算能力 提供最大的灵活性和高速的深度学习研究平台 Tensors 张量创建Tensors与Numpy中的 ndarrays类似，但是在PyTorch中 Tensors 可以使用GPU进行计算.12from __future__ import print_functionimport torch 创建一个 5x3 矩阵, 但是未初始化:12x = torch.empty(5, 3)print(x) 12345tensor([[0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000]]) 创建一个随机初始化的矩阵:12x = torch.rand(5, 3)print(x) 12345tensor([[0.6972, 0.0231, 0.3087], [0.2083, 0.6141, 0.6896], [0.7228, 0.9715, 0.5304], [0.7727, 0.1621, 0.9777], [0.6526, 0.6170, 0.2605]]) 创建一个0填充的矩阵，数据类型为long:12x = torch.zeros(5, 3, dtype=torch.long)print(x) 12345tensor([[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]) 创建tensor并使用现有数据初始化:12x = torch.tensor([5.5, 3])print(x) 1tensor([5.5000, 3.0000]) 根据现有的张量创建张量。 这些方法将重用输入张量的属性，例如， dtype，除非设置新的值进行覆盖12345x = x.new_ones(5, 3, dtype=torch.double) # new_* 方法来创建对象print(x)x = torch.randn_like(x, dtype=torch.float) # 覆盖 dtype!print(x) # 对象的size 是相同的，只是值和类型发生了变化 12345678910tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], dtype=torch.float64)tensor([[ 0.5691, -2.0126, -0.4064], [-0.0863, 0.4692, -1.1209], [-1.1177, -0.5764, -0.5363], [-0.4390, 0.6688, 0.0889], [ 1.3334, -1.1600, 1.8457]]) 获取 size1print(x.size()) 1torch.Size([5, 3]) 张量的操作加法加法112y = torch.rand(5, 3)print(x + y) 加法21print(torch.add(x, y)) 提供输出tensor作为参数123result = torch.empty(5, 3)torch.add(x, y, out=result)print(result) 替换12y.add_(x)print(y) 任何 以_ 结尾的操作都会用结果替换原变量. 例如: x.copy_(y), x.t_(), 都会改变 x.这里便是 y+=x torch.view: 可以改变张量的维度和大小1234x = torch.randn(4, 4)y = x.view(16)z = x.view(-1, 8) # size -1 从其他维度推断print(x.size(), y.size(), z.size()) 1torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8]) 只有一个元素的张量，使用.item()来得到Python数据类型的数值123x = torch.randn(1)print(x)print(x.item()) 12tensor([-0.2368])-0.23680149018764496 NumPy 转换将一个Torch Tensor转换为NumPy数组是一件轻松的事，反之亦然。Torch Tensor与NumPy数组共享底层内存地址，修改一个会导致另一个的变化。将一个Torch Tensor转换为NumPy数组12a = torch.ones(5)print(a)tensor([1., 1., 1., 1., 1.])12b = a.numpy()print(b)[1. 1. 1. 1. 1.] numpy数组的值是如何改变的。123a.add_(1)print(a)print(b) 12tensor([2., 2., 2., 2., 2.])[2. 2. 2. 2. 2.] 使用from_numpy自动转化123456import numpy as npa = np.ones(5)b = torch.from_numpy(a)np.add(a, 1, out=a)print(a)print(b) 12[2. 2. 2. 2. 2.]tensor([2., 2., 2., 2., 2.], dtype=torch.float64) 所有的 Tensor 类型默认都是基于CPU， CharTensor 类型不支持到 NumPy 的转换. CUDA 张量使用.to 方法 可以将Tensor移动到任何设备中123456789# is_available 函数判断是否有cuda可以使用# ``torch.device``将张量移动到指定的设备中if torch.cuda.is_available(): device = torch.device(&quot;cuda&quot;) # a CUDA 设备对象 y = torch.ones_like(x, device=device) # 直接从GPU创建张量 x = x.to(device) # 或者直接使用``.to(&quot;cuda&quot;)``将张量移动到cuda中 z = x + y print(z) print(z.to(&quot;cpu&quot;, torch.double)) # ``.to`` 也会对变量的类型做更改12tensor([0.7632], device='cuda:0')tensor([0.7632], dtype=torch.float64)","link":"/2021/01/27/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01-%E5%BC%A0%E9%87%8F/"},{"title":"Pytorch学习笔记--自动求导机制","text":"Autograd: 自动求导机制PyTorch 中所有神经网络的核心是 autograd 包。 我们先简单介绍一下这个包，然后训练第一个简单的神经网络。 autograd包为张量上的所有操作提供了自动求导。 它是一个在运行时定义的框架，这意味着反向传播是根据你的代码来确定如何运行，并且每次迭代可以是不同的。 示例 张量（Tensor）torch.Tensor是这个包的核心类。如果设置 .requires_grad 为 True，那么将会追踪所有对于该张量的操作。 当完成计算后通过调用 .backward()，自动计算所有的梯度， 这个张量的所有梯度将会自动积累到 .grad 属性。 要阻止张量跟踪历史记录，可以调用.detach()方法将其与计算历史记录分离，并禁止跟踪它将来的计算记录。 为了防止跟踪历史记录（和使用内存），可以将代码块包装在with torch.no_grad()：中。 在评估模型时特别有用，因为模型可能具有requires_grad = True的可训练参数，但是我们不需要梯度计算。 在自动梯度计算中还有另外一个重要的类Function. Tensor and Function are interconnected and build up an acyclic graph, that encodes a complete history of computation. Each tensor has a .grad_fn attribute that references a Function that has created the Tensor (except for Tensors created by the user - their grad_fn is None). Tensor 和 Function互相连接并生成一个非循环图，它表示和存储了完整的计算历史。 每个张量都有一个.grad_fn属性，这个属性引用了一个创建了Tensor的Function（除非这个张量是用户手动创建的，即，这个张量的 grad_fn 是 None）。 如果需要计算导数，你可以在Tensor上调用.backward()。 如果Tensor是一个标量（即它包含一个元素数据）则不需要为backward()指定任何参数， 但是如果它有更多的元素，你需要指定一个gradient 参数来匹配张量的形状。","link":"/2021/02/19/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02-Autograd%20%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC%E6%9C%BA%E5%88%B6/"},{"title":"Pytorch学习笔记4--回归Regression","text":"过程通过一个散点图建立一个简单神经网络 步骤为 建立xy数据点集 定义神经网络结构,只有hidden和predict 2层 训练神经网络同时绘制图像 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import torchimport torch.nn.functional as Fimport matplotlib.pyplot as plt#print(torch.linspace(-1,1,100))x = torch.unsqueeze(torch.linspace(-1,1,100),dim=1) #生成二维的-1到1的伪数据,输出是个列向量#print('\\n',x)y = x.pow(2) + 0.2* torch.rand(x.size()) #把点应造成X^2的抖动函数plt.scatter(x.numpy(),y.numpy())plt.show()#输出图片class Net(torch.nn.Module): def __init__(self,n_feature, n_hidden,n_output): super(Net, self).__init__() self.hidden = torch.nn.Linear(n_feature, n_hidden)#定义隐藏层结构 self.predict = torch.nn.Linear(n_hidden,n_output)#定义预测层结构,输出一个y def forward(self,x): #正向传播输入一个x x = torch.relu(self.hidden(x)) #正向传播x-&gt;relu过的x-&gt;output x = self.predict(x) return xnet = Net(n_feature=1,n_hidden=10,n_output=1) #创建神经网络print(net)#可以看出神经网络的结构# 下面开始训练optimizer = torch.optim.SGD(net.parameters(),lr=0.2)#传入net的全部参数,学习率为0.2,越高越快,但也会出现梯度爆炸之类的问题loss_func = torch.nn.MSELoss()for i in range(500): #训练500次 prediction = net(x) #向神经网络传入 x , prediction 相当于神经网络正向传播完的y loss = loss_func(prediction,y) #计算loss optimizer.zero_grad()#梯度归零清空上一步的残余更新参数值 loss.backward()# 误差反向传播, 计算参数更新值 optimizer.step() # 将参数更新值施加到 net 的 parameters 上#绘图 if i % 5 == 0: # plot and show learning process plt.cla() plt.scatter(x.data.numpy(), y.data.numpy()) plt.plot(x.data.numpy(), prediction.data.numpy(), 'r-', lw=5) plt.text(0.5, 0, 'Loss=%.4f' % loss.data.numpy(), fontdict={'size': 20, 'color': 'red'}) plt.pause(0.1)","link":"/2021/03/04/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04-%E5%9B%9E%E5%BD%92Regression/"},{"title":"Pytorch学习笔记3--激励函数","text":"激励函数什么是 Activation激励函数是非线性函数神经网络每一层出来都是线性的需要Activation掰弯来处理非线性问题 常用的激励函数有 relu sigmoid tanh softplus Torch中的激励函数python的可视化模块以下是测试代码1234567891011121314151617181920212223242526272829303132333435import torchimport torch.nn.functional as Ffrom torch.autograd import variable #没啥用了好像import matplotlib.pyplot as pltx = torch.linspace(-5,5,200)x_np = x.numpy()y_relu = torch.relu(x).numpy()y_sigmoid = torch.sigmoid(x).numpy()y_tanh = torch.tanh(x).numpy()y_softplus = F.softplus(x).numpy()plt.figure(1, figsize=(8, 6))plt.subplot(221)plt.plot(x_np, y_relu, c='red', label='relu')plt.ylim((-1, 5))plt.legend(loc='best')plt.subplot(222)plt.plot(x_np, y_sigmoid, c='red', label='sigmoid')plt.ylim((-0.2, 1.2))plt.legend(loc='best')plt.subplot(223)plt.plot(x_np, y_tanh, c='red', label='tanh')plt.ylim((-1.2, 1.2))plt.legend(loc='best')plt.subplot(224)plt.plot(x_np, y_softplus, c='red', label='softplus')plt.ylim((-0.2, 6))plt.legend(loc='best')plt.show()","link":"/2021/03/04/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03-%E6%BF%80%E5%8A%B1%E5%87%BD%E6%95%B0/"},{"title":"Pytorch学习笔记5--分类Classification","text":"过程其实和回归那个神经网络没差,就是数据集变化了,神经网络的输入输出端变为2个参数 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071import torchimport torch.nn.functional as Fimport matplotlib.pyplot as pltimport time#数据集n_data = torch.ones(1000, 2) # 数据的基本形态x0 = torch.normal(2*n_data, 1) # 类型0 x data (tensor), shape=(100, 2)y0 = torch.zeros(1000) # 类型0 y data (tensor), shape=(100, )x1 = torch.normal(-2*n_data, 1) # 类型1 x data (tensor), shape=(100, 1)y1 = torch.ones(1000) # 类型1 y data (tensor), shape=(100, )# 注意 x, y 数据的数据形式是一定要像下面一样 (torch.cat 是在合并数据)x = torch.cat((x0, x1), 0).type(torch.FloatTensor) # FloatTensor = 32-bit floatingy = torch.cat((y0, y1), ).type(torch.LongTensor) # LongTensor = 64-bit integer#网络class Net(torch.nn.Module): def __init__(self,n_feature, n_hidden,n_output): super(Net, self).__init__() self.hidden = torch.nn.Linear(n_feature, n_hidden)#定义隐藏层结构 self.predict = torch.nn.Linear(n_hidden,n_output)#定义预测层结构,输出一个y def forward(self,x): #正向传播输入一个x x = torch.relu(self.hidden(x)) #正向传播x-&gt;relu过的x-&gt;output x = self.predict(x) return xnet = Net(n_feature = 2,n_hidden=10,n_output = 2) #创建神经网络print(net)#可以看出神经网络的结构# 训练optimizer = torch.optim.SGD(net.parameters(),lr=0.02)#传入net的全部参数,学习率为0.2,越高越快,但也会出现梯度爆炸之类的问题#loss_func = torch.nn.MSELoss() MSE用于回归类型loss_func = torch.nn.CrossEntropyLoss()for i in range(500): #训练500次 out = net(x) #向神经网络传入 x , prediction 相当于神经网络正向传播完的y loss = loss_func(out,y) #计算loss print(loss) time.sleep(0.5)#这里只是为了方便观察 optimizer.zero_grad()#梯度归零清空上一步的残余更新参数值 loss.backward()# 误差反向传播, 计算参数更新值 optimizer.step() # 将参数更新值施加到 net 的 parameters 上 if i % 2 == 0: plt.cla() # 过了一道 softmax 的激励函数后的最大概率才是预测值 prediction = torch.max(F.softmax(out,dim=1), 1)[1] pred_y = prediction.data.numpy().squeeze() target_y = y.data.numpy() plt.scatter(x.data.numpy()[:, 0], x.data.numpy()[:, 1], c=pred_y, s=100, lw=0, cmap='RdYlGn') accuracy = sum(pred_y == target_y)/2000. # 预测中有多少和真实值一样 plt.text(1.5, -4, 'Accuracy=%.2f' % accuracy, fontdict={'size': 20, 'color': 'red'}) plt.pause(0.1) plt.ion() plt.show()plt.ioff() # 停止画图plt.show()","link":"/2021/03/04/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05-%E5%88%86%E7%B1%BBClassification/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2022/09/02/hello-world/"},{"title":"Unity实验作业 手动搭建指定的三维场景","text":"实验作业 0目的： 熟悉游戏引擎的场景构建功能 要求： 手动搭建指定的三维场景（三选一） 实验思考本次实验考察unity的移动旋转等建模基础操作,观察要求的几个结果来看,大致可以总结出几种搭建方法 最简单直接,但也是最麻烦的方法,用unity自带的3Dobjct搭建 这种方法若不经过详细的计算与特殊的技巧很难精确的达到题目效果,取巧的方法是可以通过外部建模软件将顶点信息导入后作为父节点将2种组对象(如图1的3角球与6连立方体)作为子节点进行较为快速精准的搭建 代码党 同上述取巧方法类似,构建组对象预置物件,通过代码构建物件 外部建模导入 由于没有插件unity自带的建模能力较差,所以干脆选择外部建模软件对实验要求进行构建,这也是我选择的方法(懒) 步骤blender建模在blender中构建棱角球,将其细分调至1以方便后续构建 对棱角球进行倒角,构建题目要求的主体形状 将面剔除留下我们所需的框架结构 ![图 8] 添加经纬球,并将其作为上述框架的子物件实例化,并将坐标(0,0,0)的经纬球隐藏 复制一份框架结构,对其进行倒角构建柱状框架,将2个物件结合即可构成实验目的结构 简单的着色,并导出为fbx格式 导入到unity场景,并设置摄像机,可以得到一个较为满意的结果","link":"/2021/11/01/%E6%B8%B8%E6%88%8F%E7%BC%96%E7%A8%8B%E5%AE%9E%E9%AA%8C0/"},{"title":"Unity实验作业 动态的“日-地-月”场景","text":"实验作业 1目的： 熟悉世界坐标和局部坐标 要求： 完成一个动态的“日-地-月”场景 实验思考本次实验是制作一个动态日地月场景,基本步骤就是场景搭建与动效实现 场景搭建采用日-&gt;地-&gt;月的顺序依次包含子物件,在变换时会较为方便,动效实现可以直接对位置采取变换,也可以设置各个天体之间的力来控制运动来实现平衡运动 虽然现实生活中的天体轨迹是椭圆的,但既然只是练习,就以圆代替 实验步骤首先搭建场景,从网上找来地月日模型与宇宙天空盒来搭建场景 并且将其按照上述父子节点关系整理,通过局部position归零来快速构建,其中将太阳的模型的阴影效果去除以达到发光体效果,将平行光设为太阳子节点并朝向地月系统以实现局部平行光的效果,将摄像机置于太阳子节点以实现追拍效果 添加运动脚本,这里采用协程动画 type用于控制旋转方向,每种天体均有整体的rotate速度与其子节点planet也就是其星球本体的旋转速度 由于数据太大,场景搭建不规范,也并不涉及力学知识,参数就随便取的令人便于观赏的值 最后为星体添加trail render组件来更直观的显示移动轨迹","link":"/2021/11/01/%E6%B8%B8%E6%88%8F%E7%BC%96%E7%A8%8B%E5%AE%9E%E9%AA%8C01/"},{"title":"Unity实验作业 制作一个动态3D时钟","text":"实验作业2目的： 熟悉世界坐标和局部坐标 要求： 制作一个动态3D时钟 实验思考本题和实验二差别并不是很大,思路基本想通,依旧是搭建场景与动效实现 实验步骤搭建场景部分简单的用几个基本物件组合了一下,将整个底座作为父节点,每个时针都与一个empty object绑定为父子关系以方便实现旋转 24个指示点用empty object+cube的方式制作成了prefab通过代码实现旋转布局 动效的实现依旧是协程,这里采用rotate(gameobject , float)的形式以方便泛用与多个时针 这样一个简单的时钟就做好了,当然如果根据时针的运动与24个指示点有交互(比如时针经过指示点上下起伏一下)就能让时钟变得更加有意思 实验结果就是如下的时钟(因为时间太慢了不方便演示,采取加速时间)","link":"/2021/11/01/%E6%B8%B8%E6%88%8F%E7%BC%96%E7%A8%8B%E5%AE%9E%E9%AA%8C02/"},{"title":"Unity实验作业 探索SDK之外的秘密","text":"实验作业 3目的： 实践程序实验，自主探索SDK之外的秘密 要求： 探索不同GameObject上的Start和Update函数执行顺序。 要求自行设计脚本，可以直接验证执行顺序，并给出合理解释。 实验思考通过书写几个事件打印出执行顺序,可以让我们更深刻的理解Unity的运作原理() 实验步骤我在场景中建立3个空物体来做顺序对比,通过Debug.Log可以了解程式的运作 我们可以看出最先运行的是Awake,其中主相机最先awake,然后平行光随后awake 我所按顺序加进去的test123 3个空物件以从新到旧的顺序awake 随后各对象触发OnApplicationFocus,顺序并不规律,应该是异步性 之后开始按照最开始awake顺序执行start() 我们看下面没截取完的部分 fixedUpdate也是按照之前顺序进行,随后是UpDate随后是LateUpDate 结论除开OnApplicationFocus异步触发 可以看出对象的执行顺序是主相机,平行光,从新到旧的game object 方法的触发顺序是 Awake -&gt; Start -&gt; fixedUpdate -&gt; UpDate -&gt; LateUpDate 但Update一类并不是单次触发的函数 查阅资料可知 Update()：每一帧执行时，都会立即调用此方法。LateUpdate()：LateUpdate 是在所有 Update 方法调用之后被调用（语出圣典）。FixedUpdate()：固定更新。默认情况下，系统每0.02秒调用一次。 具体的间隔时间可以在 TimeManager 中配置。 总体来说，Update() 和 LateUpdate() 属于立即更新，更新之间的频率是不固定的，比如某一帧有一个耗时操作时，就会影响到下一帧更新时间，所以对更新频率要求比较稳定的物理系统（如Rididbody）就不太适合在这里处理更新。 FixedUpdate() 虽然是固定更新，但是其实也是相对固定的，比如某一帧耗了好几秒，它依然会卡住。不过正常的程序会优化耗时操作，小范围的帧率波动是正常的，可以让它更新的时间间隔稍微长一点，这样它的更新是比较平滑的。 在实际的开发中，例如以秒为单位的倒计时，并不需要每一帧去判断时间，所以用 FixedUpdate 就再合适不过了。 代码```using System.Collections;using System.Collections.Generic;using UnityEngine; public class test : MonoBehaviour{ // Start is called before the first frame update void Start() { Debug.Log(this.name + “run Start()”); } // Update is called once per frame void Update() { Debug.Log(this.name + &quot;run UpDate()&quot;); } private void OnApplicationFocus(bool focus) { Debug.Log(this.name + &quot;run OnApplicationFocus:&quot; + focus); } private void OnAnimatorMove() { Debug.Log(this.name + &quot;run OnApplicationFocus&quot;); } private void OnAnimatorIK(int layerIndex) { Debug.Log(this.name + &quot;run OnAnimatorIK:&quot; + layerIndex); } private void LateUpdate() { Debug.Log(this.name + &quot;run LateUpdate&quot;); } private void FixedUpdate() { Debug.Log(this.name + &quot;run FixedUpdate&quot;); } private void Awake() { Debug.Log(this.name + &quot;Awake&quot;); } }","link":"/2021/11/01/%E6%B8%B8%E6%88%8F%E7%BC%96%E7%A8%8B%E5%AE%9E%E9%AA%8C03/"},{"title":"Unity实验作业 实现对mesh的破碎效果","text":"实验作业 4目的： 熟悉Mesh的概念，能自由利用Mesh数据 要求： 编写一个脚本，实现对mesh的破碎效果 实验思路想要实现破碎的效果,大致可以分为几种思路, 首先最朴实无华但效果也不错的就是直接进行物理模拟,将cube切割成碎片,为其添加刚体与碰撞属性,使其具有基本的物理特性,这种方法能够得到较为真实的破碎模拟,但开销较大 也可以通过脚本控制mesh顶点偏移的方式实现,但我觉得视觉效果欠佳 退而求其次的方法是采用外部动画导入,只对特定情况的碰撞做出反应,这样就不用给予每个子物件物理与碰撞属性,只需检测碰撞后播放动画即可,这种方法也能达到不错的效果,但缺乏交互的多样性 再者就是更复杂的着色器效果,通过着色器能够实现非物理效果形式的破碎,比如化为飞灰之类的效果,但这部分编写代码较为复杂和繁琐 实验步骤本次实验我采取的是纯粹的物理模仿的方式 首先我在外部建模软件对mesh进行处理 将其碎片化为多个mesh的结合体 然后导入unity,为其添加物理属性 这里我试了几种不同的方法来实现破碎效果,首先就是将模型制成帧动画,通过animator controller对其进行动画控制,由碰撞脚本触发破碎效果,在动画快结束时将材质透明度降低并释放内存(但实际效果很辣眼睛) 后来我便采用物理模拟的方法来着手,mesh collider能够比较好的模拟,但实际肯定不能使用这么浪费性能的方法,可以在触发想要发生碰撞动画前关闭碰撞检测,由大碰撞体检测,在落地大碰撞触发时,将碎片碰撞打开,进行碰撞模拟 这种方法也同样适用于当碎片以box collider的时候,但box collider因为挤压,在落地的一瞬间会产生强大的排斥力,让碎片四散飞去.效果略显夸张,在低重力指数的情况下可以模仿烟花爆破等场景(但应该没人会用实体模仿吧)","link":"/2021/11/01/%E6%B8%B8%E6%88%8F%E7%BC%96%E7%A8%8B%E5%AE%9E%E9%AA%8C04/"},{"title":"人工智能小测试","text":"前置 翻墙工具 github账号,看源码必备 基于pytorch 最好有个Google账号 使用Google的深度学习服务器Colab,自带24G显存的GPU,如果要长时间使用9.99美元/月(65块/月),我们的数据集通过Google云端硬盘上传,自带15G免费内存,可扩充100G/月(250日元/月,差不多15块吧,我们学习阶段应该用不上扩充) 步骤 学习完全可以跟着这个网站学 我先跳过理论直接做了UNet框架的训练,具体步骤参照这个网站手把手教学,有源码和数据集 我们需要做的只有学会怎么用colab 进入colab首先配置GPU加速模式,不然训练的超级慢进去后硬件加速器选GPU(训练模型用GPU,不充钱不稳定后文有推荐本地运行的方法) 记得选择这个显示模式,更直观 然后跟着使用入门连接你的Google云端硬盘 然后再文件-&gt;新建笔记本 再左侧栏最下面文件夹里就是你的目录了,可以新建文件或者文件夹,你也能看见你的云端硬盘的文件夹,可以直接通过复制路径调用资源 记得自己的代码最好建立在本地或云端硬盘里,colab容易丢失,谢邀写到这里发现我代码没了 写的.py文件通过第一栏的笔记本输入!python 绝对路径(直接复制的路径)/相对路径执行 本地运行点击右上角 连接-&gt;切换到本地运行时,使用jupyter本地运行 请在终端分别输入以下代码(前提你已经配置好了python环境) 12pip install jupyter_http_over_wsjupyter serverextension enable --py jupyter_http_over_ws 12 jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' \\--port=8888 --no-browser 在colab输入你 终端显示的http://localhost:8888/?token=xxxxx","link":"/2021/01/27/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2_%E5%85%A5%E9%97%A8_%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB/"},{"title":"Unity实验作业 用Cube实现篝火动态效果","text":"实验作业 5目的： 熟悉脚本控制的“动态过程”。 要求： 编写一个脚本，用Cube实现篝火动态效果。 实验思考 看到如图示的效果我第一个想到的是利用顶点着色器来做,因为之前看见过类似的方块着色器作品,但奈何能力和时间有限 既然是考察动态过程,那么做法其实已经很明显了,火的效果有着大小的缩放,位置的移动与微量的旋转以及颜色的渐变,好家伙,基本上该变的都变了,如果说要在此基础上锦上添花,可以对这些移动加入抖动,也可以做一些后处理 另外的做法的话可以考虑使用失重的物理性质来做 实验步骤12345678910111213141516171819IEnumerator getFire(){ while (true) { if (num &lt; maxNum) { GameObject fire = GameObject.CreatePrimitive(PrimitiveType.Cube); num++; fire.transform.position = new Vector3(NextGaussian(0,4f,-4f,4f), 0, NextGaussian(0, 4f,-4f,4f)); fire.transform.localScale = Vector3.one * 2f; StartCoroutine(zoom(fire, 2f, 0.2f, 200f - 15 * fire.transform.position.x)); StartCoroutine(rotate(fire, 1f)); StartCoroutine(rise(fire, 0.1f, 30f - 5*fire.transform.position.x)); StartCoroutine(color(fire)); } yield return new WaitForSeconds(0.1f); }}过程没怎么截图,由代码说起吧 上面放的是生成火立方和开始协程动画的代码,首先我们观察火焰的生成,是一个类似于正态分布一样的存在,简单的random所生成的均值火焰显然不符合自然火焰的样貌,所以我嫖了一个正太分布的代码过来,通过协程进行火焰立方的生成,限制最大生成个数以保证火焰稳定 123456789101112131415161718192021222324252627 public static float NextGaussian() { float v1, v2, s; do { v1 = 2.0f * Random.Range(0f, 1f) - 1.0f; v2 = 2.0f * Random.Range(0f, 1f) - 1.0f; s = v1 * v1 + v2 * v2; } while (s &gt;= 1.0f || s == 0f); s = Mathf.Sqrt((-2.0f * Mathf.Log(s)) / s); return v1 * s; } public static float NextGaussian(float mean, float standard_deviation) { return mean + NextGaussian() * standard_deviation; } public static float NextGaussian(float mean, float standard_deviation, float min, float max) { float x; do { x = NextGaussian(mean, standard_deviation); } while (x &lt; min || x &gt; max); return x; }} 生成了cube之后,显然还需要上升动画,这里通过协程用非线性运动的上升曲线来做直线上升运动(本来还应该做抖动的,但好像有点麻烦了),这样生成的火焰像圆柱一样,所以协程部分以最大高度为参数书写,最大高度会根据距离火源的距离产生衰减,来达到火焰中间高,两边低的效果 为了火焰立方不单调,我采用多轴的随机旋转来让火立方生动形象一点,这里采用四元组旋转 这样直直方法的立方柱并不是我想要的,因为火焰外围的立方应该小一点才对,于是我又用了另一条非线性曲线对cube大小进行协程缩减(协程多了控制条件也多了)为了达成以上几个协程中途还是吃了不少麻烦的.同样,依葫芦画瓢,大小缩减的动画也加入了距离火源的距离衰减 最后就是颜色部分,采用距离实现线性插值(不想管火焰怎么生成的了),外焰红色,内焰黄色. 我做到这里就不是很想做下去了,但事实上作为发光物体的火立方,我没有对其阴影和发光属性进行处理,但由于是用代码生成的cube而不是预先准备好的prefab,所以我选择放弃,这是实验开始时没想好的(偷懒的借口),当然,如果能够对其进行后处理就再好不过了,不过这些都是后话了,实验主要的目的还是做动效.嗯 但结果还是有点怪怪的(可能是因为用正太分布的时候对最大值最小值进行了裁剪导致的)","link":"/2021/11/01/%E6%B8%B8%E6%88%8F%E7%BC%96%E7%A8%8B%E5%AE%9E%E9%AA%8C05/"},{"title":"Unity实验作业 鼠标操作3D空间物体","text":"实验作业 6要求： 鼠标操作3D空间物体 必备：悬停高亮 左键拖拽 右键旋转 可单独旋转某个物体，或者旋转整体视角 实验思考主要是对射线进行考察,可通过协程实现对鼠标左右按键拖拽的监控,由事件进行鼠标位置的判定 实验步骤当鼠标悬停时,物体会变红当鼠标离开时,红色物体会慢慢褪为白色当鼠标持续按下左键或右键时,会计算鼠标偏移量,并将物体标绿,经过坐标转换使物体拖拽移动当鼠标持续右键时,会将物体标蓝,并根据鼠标偏移量进行旋转 创建协程123456789101112131415161718192021222324252627282930IEnumerator OnMouseDown(){ Material mt = GetComponent&lt;MeshRenderer&gt;().material; cubeScreenPos = Camera.main.WorldToScreenPoint(transform.position); Vector3 mousePos = new Vector3(Input.mousePosition.x, Input.mousePosition.y, cubeScreenPos.z); mousePos = Camera.main.ScreenToWorldPoint(mousePos); offset = transform.position - mousePos; while (Input.GetMouseButton(0) || Input.GetMouseButton(1)) { if (Input.GetMouseButton(0) &amp;&amp; !Input.GetMouseButton(1)) { mt.color = Color.green; Vector3 curMousePos = new Vector3(Input.mousePosition.x, Input.mousePosition.y, cubeScreenPos.z); curMousePos = Camera.main.ScreenToWorldPoint(curMousePos); transform.position = curMousePos + offset; } if(Input.GetMouseButton(1)) { mt.color = Color.blue; Vector3 curMousePos = new Vector3(Input.mousePosition.x, Input.mousePosition.y, cubeScreenPos.z); curMousePos = Camera.main.ScreenToWorldPoint(curMousePos); transform.Rotate(offset*10); } yield return new WaitForFixedUpdate(); }}","link":"/2021/11/01/%E6%B8%B8%E6%88%8F%E7%BC%96%E7%A8%8B%E5%AE%9E%E9%AA%8C06/"}],"tags":[{"name":"学习","slug":"学习","link":"/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"记录","slug":"记录","link":"/tags/%E8%AE%B0%E5%BD%95/"},{"name":"经验","slug":"经验","link":"/tags/%E7%BB%8F%E9%AA%8C/"},{"name":"计算机图形学","slug":"计算机图形学","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"OpenGL","slug":"OpenGL","link":"/tags/OpenGL/"},{"name":"Pytorch","slug":"Pytorch","link":"/tags/Pytorch/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"Unity","slug":"Unity","link":"/tags/Unity/"},{"name":"人工智能","slug":"人工智能","link":"/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}],"categories":[{"name":"环境配置","slug":"环境配置","link":"/categories/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"},{"name":"计算机图形学","slug":"计算机图形学","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"机器学习","slug":"机器学习","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"课程","slug":"课程","link":"/categories/%E8%AF%BE%E7%A8%8B/"}]}