<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Dante-Game</title>
  <icon>https://www.gravatar.com/avatar/3d52e60c6199417f09d966057eded997</icon>
  <subtitle>致热爱游戏的人</subtitle>
  <link href="https://www.dante-game.com.cn/atom.xml" rel="self"/>
  
  <link href="https://www.dante-game.com.cn/"/>
  <updated>2022-09-25T13:37:21.148Z</updated>
  <id>https://www.dante-game.com.cn/</id>
  
  <author>
    <name>Dante</name>
    <email>a980735179@gmail.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Unity Shader</title>
    <link href="https://www.dante-game.com.cn/2022/09/25/UnityShader/"/>
    <id>https://www.dante-game.com.cn/2022/09/25/UnityShader/</id>
    <published>2022-09-25T13:37:10.000Z</published>
    <updated>2022-09-25T13:37:21.148Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>A Star启发式搜索</title>
    <link href="https://www.dante-game.com.cn/2022/09/24/A%20Star%E5%90%AF%E5%8F%91%E5%BC%8F%E6%90%9C%E7%B4%A2/"/>
    <id>https://www.dante-game.com.cn/2022/09/24/A%20Star%E5%90%AF%E5%8F%91%E5%BC%8F%E6%90%9C%E7%B4%A2/</id>
    <published>2022-09-24T11:26:43.000Z</published>
    <updated>2022-09-24T11:35:29.487Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>待总结的部分</title>
    <link href="https://www.dante-game.com.cn/2022/09/24/%E5%BE%85%E6%80%BB%E7%BB%93%E7%9A%84%E9%83%A8%E5%88%86/"/>
    <id>https://www.dante-game.com.cn/2022/09/24/%E5%BE%85%E6%80%BB%E7%BB%93%E7%9A%84%E9%83%A8%E5%88%86/</id>
    <published>2022-09-24T05:45:40.000Z</published>
    <updated>2022-09-25T13:48:12.589Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220925214748.png" alt=""></p><blockquote><p>参考的课程: GAMES101 GAMES104 GAMES202 动画机系列 百人计划</p></blockquote><span id="more"></span><p>这是接下来想要详细总结的部分,要动手编程哦</p><ul><li>渲染管线<br><input type='checkbox' checked>光栅化<br><input type='checkbox'>延迟渲染管线<br><input type='checkbox'>光线追踪</li><li>理论基础<br><input type='checkbox'>向量与矩阵<br><input type='checkbox'>纹理<br><input type='checkbox'>模型与材质<br><input type='checkbox'>伽马矫正<br><input type='checkbox'>LDR与HDR<br><input type='checkbox'>色彩空间<br><input type='checkbox'>GPU硬件架构<br><input type='checkbox'>PC手机图形API<br><input type='checkbox'>移动端TBDR架构</li><li>混合测试<br><input type='checkbox'>EarlyZ和Zprepass<br><input type='checkbox'>混合模式和剔除<br><input type='checkbox'>深度测试与模板测试</li><li>光照模型<br><input type='checkbox'>传统光照模型<br><input type='checkbox'>实时阴影<br><input type='checkbox'>SSAO<br><input type='checkbox'>pbr<br><input type='checkbox'>基于物理的相机<br><input type='checkbox'>光线专题</li><li>后处理<br><input type='checkbox'>景深<br><input type='checkbox'>Bloom实现<br><input type='checkbox'>抗锯齿</li><li>Shader效果<br><input type='checkbox'>URP与command buffer<br><input type='checkbox'>常用函数<br><input type='checkbox'>BUMP图<br><input type='checkbox'>flowmap<br><input type='checkbox'>曲面细分与几何着色器<br><input type='checkbox'>shader实战</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220925214748.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;参考的课程: GAMES101 GAMES104 GAMES202 动画机系列 百人计划&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="游戏" scheme="https://www.dante-game.com.cn/categories/%E6%B8%B8%E6%88%8F/"/>
    
    
    <category term="学习" scheme="https://www.dante-game.com.cn/tags/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="记录" scheme="https://www.dante-game.com.cn/tags/%E8%AE%B0%E5%BD%95/"/>
    
    <category term="经验" scheme="https://www.dante-game.com.cn/tags/%E7%BB%8F%E9%AA%8C/"/>
    
  </entry>
  
  <entry>
    <title>毕设初期策划</title>
    <link href="https://www.dante-game.com.cn/2022/09/07/%E6%AF%95%E8%AE%BE%E5%88%9D%E6%9C%9F%E7%AD%96%E5%88%92/"/>
    <id>https://www.dante-game.com.cn/2022/09/07/%E6%AF%95%E8%AE%BE%E5%88%9D%E6%9C%9F%E7%AD%96%E5%88%92/</id>
    <published>2022-09-07T11:49:19.000Z</published>
    <updated>2022-09-25T13:44:53.918Z</updated>
    
    <content type="html"><![CDATA[<h1 id="毕设"><a href="#毕设" class="headerlink" title="毕设"></a>毕设</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><div class="table-container"><table><thead><tr><th style="text-align:center">要点</th><th>内容</th></tr></thead><tbody><tr><td style="text-align:center">名字</td><td>暂定</td></tr><tr><td style="text-align:center">指导老师</td><td>暂无</td></tr><tr><td style="text-align:center">类型</td><td>第三人称搜集解密可双人协作游戏</td></tr><tr><td style="text-align:center">概述</td><td>基于URP面向移动端的搜集解密型单/双人游戏, 角色拥有飞行系统与撞击交互系统</td></tr></tbody></table></div><ul><li>游戏设想:<br>做一个以飞行和碰撞为主要游戏玩法的解密探索游戏,<br>用各种渲染知识设计美术元素与解密要素,<br>编写一套基于由脚本控制的root motion的 飞行-步行 角色控制器,<br>制作换装系统,<blockquote><p>主要的玩法是高速碰撞,通过飞行撞向目标合适的部位能够造成伤害或交互效果(参考超级泡泡boss战),目标可以是解密的关卡触发器,可以是ai</p></blockquote></li></ul><span id="more"></span><hr><h2 id="游戏设计"><a href="#游戏设计" class="headerlink" title="游戏设计"></a>游戏设计</h2><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220907193557.png" alt=""></p><p>基本参考光遇的设计,玩家能够在不同的场景进行搜集,每个场景中会有各种搜集物(如可以增加飞行次数上限的道具, 可以反复收集换取服装的道具),场景本身尽量设计的让飞行探索也需要一定时间,且搜集物主要分布在具有解密游戏的地点(可以是找机关,可以是拼图,可以是按顺序触发等)</p><ul><li><p><strong><font color="#FF0000">飞行</font></strong><br>玩家具有一定的飞行次数上限, 飞行采取滑翔飞行和上升飞行2种模式</p><ul><li><strong><font color="#0000FF">上升飞行</font></strong><br>玩家在平地时只能通过上升飞行进行高度的提升,上升飞行速度慢,且水平位移很小<br>滑行飞行切换到上升飞行模式会有急停刹车的效果.</li><li><strong><font color="#0000FF">滑行飞行</font></strong><br>玩家在一定高度(如上升飞行后/从高处落下时)可以切换为滑翔模式<br>滑翔模式下再次使用飞行能够增加滑翔的速度,通过视角控制方向,可以通过视角上抬来获得上升的速度. 滑翔时候通过按键[待定]能够进行侧翻,来进行空中的转弯</li><li><strong><font color="#0000FF">飞行碰撞</font></strong><br>仅有在速度超过一定值(消耗飞行次数可达到)的情况下能够具有碰撞效果,碰撞可以进行场景交互(如破坏机关门)与攻击</li><li><strong><font color="#0000FF">回复飞行次数</font></strong><br>通过特定的地点(如存档点,体积云)可以进行回复,获取提升飞行上限的搜集物能够直接回满次数.本着让玩家前期不能自由飞行吃屎的原则,一些特定搜集物也可以用堆高度来防止玩家前期获取</li></ul></li><li><p><strong><font color="#FF0000">交互</font></strong></p><ul><li>飞行碰撞机制</li><li>按键交互(触发机关,触发UI)</li><li>移动交互(触发机关/视觉特效)</li></ul></li><li><strong><font color="#FF0000">搜集</font></strong><ul><li>能够增加飞行次数上限的道具</li><li>能够用于兑换服装/肢体动作的道具</li><li>场景解锁需要搜集的道具</li></ul></li><li><strong><font color="#FF0000">解密</font></strong><ul><li>总之就是解密小游戏</li></ul></li></ul><h2 id="人物设计"><a href="#人物设计" class="headerlink" title="人物设计"></a>人物设计</h2><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220907194108.png" alt=""></p><p>总之就是简单的,不需要手,斗篷遮住大半部分,lowpoly的,方便做简单的动画<br>人物的本体就是一个A字形<br>主要参考GRIS,主要要做斗篷的物理模拟</p><h2 id="美术风格"><a href="#美术风格" class="headerlink" title="美术风格"></a>美术风格</h2><p>主要以矢量化的几何风格作为元素的基调<br>色彩偏向水墨,色彩柔和,但阴影反差大</p><hr><h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a><strong><font color="#0000FF">需求</font></strong></h2><h3 id="人物"><a href="#人物" class="headerlink" title="人物"></a>人物</h3><p><input type='checkbox'>角色模型</p><p><input type='checkbox'>角色控制器</p><p><input type='checkbox'>角色动作</p><p><input type='checkbox'>服装</p><hr><h3 id="系统"><a href="#系统" class="headerlink" title="系统"></a>系统</h3><p><input type='checkbox'>存档系统</p><p><input type='checkbox'>搜集系统</p><p><input type='checkbox'>换装系统</p><p><input type='checkbox'>场景与资源加载系统</p><p><input type='checkbox'><del>ESC架构</del></p><hr><h3 id="GamePlay"><a href="#GamePlay" class="headerlink" title="GamePlay"></a>GamePlay</h3><p><input type='checkbox'>A*寻路系统(总之就是要做一个用得上寻路的小游戏)</p><p><input type='checkbox'>拼图</p><p><input type='checkbox'>跑酷</p><p><input type='checkbox'>场景交互</p><p><input type='checkbox'>传送</p><hr><h3 id="物理"><a href="#物理" class="headerlink" title="物理"></a>物理</h3><p><input type='checkbox'>飞行系统</p><p><input type='checkbox'>碰撞交互系统</p><p><input type='checkbox'>碰撞检测系统</p><hr><h3 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h3><p><input type='checkbox'>地形</p><p><input type='checkbox'>动态物体(鲸群)</p><p><input type='checkbox'>静态物体</p><p><input type='checkbox'>空间划分</p><hr><h3 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h3><p><input type='checkbox'>联机与同步</p><p><input type='checkbox'>双人协作内容</p><p><input type='checkbox'>热更新</p><hr><h3 id="渲染"><a href="#渲染" class="headerlink" title="渲染"></a>渲染</h3><p><input type='checkbox'>特色shader</p><p><input type='checkbox'>体积云</p><p><input type='checkbox'>场景迷雾</p><p><input type='checkbox'>体积光</p><p><input type='checkbox'>动态沙滩</p><p><input type='checkbox'>动态草地</p><p><input type='checkbox'>动态模拟</p><hr><h3 id="粒子特效与音效"><a href="#粒子特效与音效" class="headerlink" title="粒子特效与音效"></a>粒子特效与音效</h3><hr><h3 id="CG与剧情"><a href="#CG与剧情" class="headerlink" title="CG与剧情"></a>CG与剧情</h3><p><input type='checkbox'>相机系统</p><hr><h3 id="UI"><a href="#UI" class="headerlink" title="UI"></a>UI</h3><p><input type='checkbox' checked>做个屁</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;毕设&quot;&gt;&lt;a href=&quot;#毕设&quot; class=&quot;headerlink&quot; title=&quot;毕设&quot;&gt;&lt;/a&gt;毕设&lt;/h1&gt;&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;div class=&quot;table-container&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;要点&lt;/th&gt;
&lt;th&gt;内容&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;名字&lt;/td&gt;
&lt;td&gt;暂定&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;指导老师&lt;/td&gt;
&lt;td&gt;暂无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;类型&lt;/td&gt;
&lt;td&gt;第三人称搜集解密可双人协作游戏&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;概述&lt;/td&gt;
&lt;td&gt;基于URP面向移动端的搜集解密型单/双人游戏, 角色拥有飞行系统与撞击交互系统&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;游戏设想:&lt;br&gt;做一个以飞行和碰撞为主要游戏玩法的解密探索游戏,&lt;br&gt;用各种渲染知识设计美术元素与解密要素,&lt;br&gt;编写一套基于由脚本控制的root motion的 飞行-步行 角色控制器,&lt;br&gt;制作换装系统,&lt;blockquote&gt;
&lt;p&gt;主要的玩法是高速碰撞,通过飞行撞向目标合适的部位能够造成伤害或交互效果(参考超级泡泡boss战),目标可以是解密的关卡触发器,可以是ai&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="游戏" scheme="https://www.dante-game.com.cn/categories/%E6%B8%B8%E6%88%8F/"/>
    
    
    <category term="项目" scheme="https://www.dante-game.com.cn/tags/%E9%A1%B9%E7%9B%AE/"/>
    
    <category term="unity" scheme="https://www.dante-game.com.cn/tags/unity/"/>
    
  </entry>
  
  <entry>
    <title>学习资料参考</title>
    <link href="https://www.dante-game.com.cn/2022/09/06/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E5%8F%82%E8%80%83/"/>
    <id>https://www.dante-game.com.cn/2022/09/06/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E5%8F%82%E8%80%83/</id>
    <published>2022-09-06T09:06:23.000Z</published>
    <updated>2022-09-25T13:48:28.320Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>这篇文章用于记录学习过程中受启发很大的文章,都很干,值得反复阅读<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/98956123_p0.jpg" alt="配图"></p><span id="more"></span><h2 id="链接列表"><a href="#链接列表" class="headerlink" title="链接列表"></a>链接列表</h2><p><a href="https://zhuanlan.zhihu.com/p/430541328">【游戏开发面经汇总】- 图形学基础篇</a><br><a href="https://www.zhihu.com/question/400628576/answer/2403237801">如何保证UDP可靠传输？ - 零声Github分享官的回答 - 知乎</a><br><a href="https://zhuanlan.zhihu.com/p/163672179">从Lambert模型到PBR模型2：Phong、BinnPhong与NDF - 科学养猪的文章 - 知乎</a><br><a href="http://t.csdn.cn/7ocsb">IEEE754浮点标准</a><br><a href="https://space.bilibili.com/7398208/channel/seriesdetail?sid=1067039">技术美术百人计划</a><br><a href="https://games-cn.org/gamescoursescollection/">GAMES101</a><br><a href="www.games-104.com">GAMES104</a><br><a href="http://t.csdn.cn/7exaw">重心坐标与透视矫正</a><br><a href="http://events.jianshu.io/p/3fef69e2efb6">内置管线Shader升级到URP详细手册</a></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;这篇文章用于记录学习过程中受启发很大的文章,都很干,值得反复阅读&lt;br&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/98956123_p0.jpg&quot; alt=&quot;配图&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="游戏" scheme="https://www.dante-game.com.cn/categories/%E6%B8%B8%E6%88%8F/"/>
    
    
    <category term="学习" scheme="https://www.dante-game.com.cn/tags/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="记录" scheme="https://www.dante-game.com.cn/tags/%E8%AE%B0%E5%BD%95/"/>
    
    <category term="经验" scheme="https://www.dante-game.com.cn/tags/%E7%BB%8F%E9%AA%8C/"/>
    
  </entry>
  
  <entry>
    <title>光照模型</title>
    <link href="https://www.dante-game.com.cn/2022/09/05/%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B/"/>
    <id>https://www.dante-game.com.cn/2022/09/05/%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B/</id>
    <published>2022-09-05T09:17:53.000Z</published>
    <updated>2022-09-26T04:44:05.629Z</updated>
    
    <content type="html"><![CDATA[<h1 id="光照模型"><a href="#光照模型" class="headerlink" title="光照模型"></a>光照模型</h1><h2 id="光学原理"><a href="#光学原理" class="headerlink" title="光学原理"></a>光学原理</h2><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220925210448.png" alt=""><br>我们肉眼能看见物体是因为光线直接进入到了我们的眼睛,而进入我们眼睛的光线可能是一条直线,也可能是经过无数次反射形成的复杂折现, 那么物体为什么会有颜色呢?</p><span id="more"></span><ul><li><a href="#光照模型">光照模型</a><ul><li><a href="#光学原理">光学原理</a></li><li><a href="#传统光照模型">传统光照模型</a><ul><li><a href="#lambert兰伯特光照模型">lambert兰伯特光照模型</a></li><li><a href="#phong模型">phong模型</a></li><li><a href="#blin-phong模型">blin-phong模型</a></li></ul></li><li><a href="#基于物理的光照模型">基于物理的光照模型</a></li></ul></li></ul><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220925210829.png" alt=""><br>我们平时最常见的太阳光是由不同频率的光所组成的,人类可以看见的范围是可见光,光线射到物体表面会被物体吸收,由于物体材质不同,对于不同光端的吸收率不同,导致最终我们看见的颜色不同</p><h2 id="传统光照模型"><a href="#传统光照模型" class="headerlink" title="传统光照模型"></a>传统光照模型</h2><p>那么游戏中我们是如何对物体进行绘制的呢</p><blockquote><p>$L<em>0(p,w_o) = L_e(p,w_o)+\int</em>\Omega f_r(p,w_i,w_o)L_i(p,w_i)n\cdot w_idw_i$</p></blockquote><p>这个很复杂的公式是渲染方程,我们暂时不讨论每个值是什么意思,后续将pbr会仔细说明.</p><p>我们将公式简化为$L_o = L_e + L_i^<code>$,即最终到我们眼睛中的光(出射光$L_o$)是由自发光$L_e$与入射光经过反射后的$L_i^</code>$构成的.<br>而反射后的光线可以简单划分为我们耳熟能详的漫反射与镜面反射,传统光照模型很好的模拟了这2部分.</p><h3 id="lambert兰伯特光照模型"><a href="#lambert兰伯特光照模型" class="headerlink" title="lambert兰伯特光照模型"></a>lambert兰伯特光照模型</h3><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220925212727.png" alt=""><br>我们之前所说的漫反射还可以进一步被拆分为直接光照形成的漫反射和间接光照形成漫反射,我们以美术中的明暗交界线为例,暗面最暗的地方是与亮面相交的地方,而不是离光线最远的地方.这是因为光线照射到背景布的光经过漫反射射到了球的下半部分,所以球的下半部分也会呈现一部分布的颜色.<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220925212951.png" alt=""><br>我们回到主题的兰伯特光照模型, 这是一个描述漫反射直接光照部分的光照模型,原理很简单,我们认为相同的受光面积下,与光照垂直的平面更亮,而与光照形成斜面的平面更暗,与光线垂直的面或者被遮挡的面不受光. 那么直接用光线方向与平面的法线方向的夹角即可描述这个关系,这就是兰伯特光照模型.<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220926095803.png" alt=""><br>关键代码<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">half4 frag(const v2f i) : SV_TARGET&#123;</span><br><span class="line">    half4 col = tex2D(_MainTex,i.uv);</span><br><span class="line">    float3 n = normalize(i.worldNormal);</span><br><span class="line">    float3 l = normalize(_MainLightPosition.xyz);</span><br><span class="line">    col *= max(0,dot(n,l));</span><br><span class="line">    return col;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>在早期的应用中为了模拟环境光防止背光面死黑, 还有一种半兰伯特模型,原理也很简单,就是将点乘的结果从(0,1)映射到了(0.5,1),即<code>col *= max(0,dot(n,l))/2+0.5;</code>.效果如下<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220926100139.png" alt=""></p><h3 id="phong模型"><a href="#phong模型" class="headerlink" title="phong模型"></a>phong模型</h3><p>我们之前所说,物体由直接光的漫反射和镜面反射以间接接光组成,而兰伯特只解决了直接光的漫反射,phong模型将这三个部分抽象为diffuse（漫反射）、specular（镜面反射）、ambient（环境光）<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220926100654.png" alt=""><br>延续了兰伯特模型的漫反射部分， 镜面反射部分通过判断光线经过反射能够进入相机的部分 ， 环境光作为底色防止死黑， 主要就是镜面反射部分</p><p>phong模型通过入射光线和法向量能够通过简单的几何运算计算出出射光线（很简单，不细说），将出射光线与相机方向做点乘即可判断该点是否能够形成镜面反射，通过求幂来缩减反射范围来描述粗糙度<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220926103645.png" alt=""><br>可以看出我们已经得到了一个光照信息较为全面的球体,代码如下<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">half4 frag(const v2f i) : SV_TARGET&#123;</span><br><span class="line">    half4 col =  _Color*tex2D(_MainTex,i.uv);</span><br><span class="line">    float3 n = normalize(i.worldNormal);</span><br><span class="line">    float3 l = normalize(_MainLightPosition.xyz);</span><br><span class="line">    float3 v = GetWorldSpaceNormalizeViewDir(i.worldPos);</span><br><span class="line">    float3 w_o = normalize(-2*(l-dot(l,n)*n)+l);</span><br><span class="line">    </span><br><span class="line">    half4 diffuse = col*_DiffColor*max(0,dot(n,l))  ;</span><br><span class="line">    half4 spec = _SpecColor*pow(max(0,dot(v,w_o)),_Gloss);</span><br><span class="line">    half4 ambient = _GlossyEnvironmentColor;</span><br><span class="line">    return col*lerp(ambient+diffuse,diffuse+spec,dot(n,l));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="blin-phong模型"><a href="#blin-phong模型" class="headerlink" title="blin-phong模型"></a>blin-phong模型</h3><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220926104709.png" alt=""><br>phong模型判断的是反射光线与相机视线的重合程度,但计算反射光线的性能消耗似乎有点大,光路总是由入射光-&gt;法线-&gt;反射光这样的对称关系组成的,blin-phong就提出了一种不需要计算反射光线的方法,判断法线与入射光和相机视线的角平分线的重合度,我们把$normalize(l+v)$称作半角向量$h$,那么稍微更改phong模型即可得到更简洁的blin-phong模型<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">half4 frag(const v2f i) : SV_TARGET&#123;</span><br><span class="line">    half4 col =  _Color*tex2D(_MainTex,i.uv);</span><br><span class="line">    float3 n = normalize(i.worldNormal);</span><br><span class="line">    float3 l = normalize(_MainLightPosition.xyz - i.worldPos);</span><br><span class="line">    float3 v = GetWorldSpaceNormalizeViewDir(i.worldPos);</span><br><span class="line">    float3 h = normalize(l+v);</span><br><span class="line">    </span><br><span class="line">    half4 diffuse = col*_DiffColor*max(0,dot(n,l))  ;</span><br><span class="line">    half4 spec = _SpecColor*pow(max(0,dot(h,n)),_Gloss);</span><br><span class="line">    half4 ambient = _GlossyEnvironmentColor;</span><br><span class="line">    return col*lerp(ambient+diffuse,diffuse+spec,dot(n,l));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="基于物理的光照模型"><a href="#基于物理的光照模型" class="headerlink" title="基于物理的光照模型"></a>基于物理的光照模型</h2><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220926121216.png" alt=""><br>我们将不同光滑的blin-phong模型作为第一排和第二排中不同光滑度和金属度的pbr模型进行对比。</p><p>很明显第二排的pbr能够表现更多的材质，并且能够反射环境，而非高光点；<br>blin-phong模型则只能表现不同光滑度的塑料材质，可以看出blin-phong模型1-1和pbr模型2-2恨相似，但仔细观察可以发现，除了微弱的环境反射以外，blin-phong1-1的高光部分太过亮了，这也是经验模型的一个通病，不遵循能量守恒（当然也存在模仿能量守恒的经验模型。</p><p>现在我们可以再次看看之前提到过的渲染方程了</p><blockquote><p>$L<em>0(p,w_o) = L_e(p,w_o)+\int</em>\Omega f_r(p,w_i,w_o)L_i(p,w_i)n\cdot w_idw_i$</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;光照模型&quot;&gt;&lt;a href=&quot;#光照模型&quot; class=&quot;headerlink&quot; title=&quot;光照模型&quot;&gt;&lt;/a&gt;光照模型&lt;/h1&gt;&lt;h2 id=&quot;光学原理&quot;&gt;&lt;a href=&quot;#光学原理&quot; class=&quot;headerlink&quot; title=&quot;光学原理&quot;&gt;&lt;/a&gt;光学原理&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220925210448.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;我们肉眼能看见物体是因为光线直接进入到了我们的眼睛,而进入我们眼睛的光线可能是一条直线,也可能是经过无数次反射形成的复杂折现, 那么物体为什么会有颜色呢?&lt;/p&gt;</summary>
    
    
    
    <category term="计算机图形学" scheme="https://www.dante-game.com.cn/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
    <category term="学习" scheme="https://www.dante-game.com.cn/tags/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="记录" scheme="https://www.dante-game.com.cn/tags/%E8%AE%B0%E5%BD%95/"/>
    
    <category term="经验" scheme="https://www.dante-game.com.cn/tags/%E7%BB%8F%E9%AA%8C/"/>
    
    <category term="计算机图形学" scheme="https://www.dante-game.com.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="游戏引擎" scheme="https://www.dante-game.com.cn/tags/%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E/"/>
    
  </entry>
  
  <entry>
    <title>图形渲染管线</title>
    <link href="https://www.dante-game.com.cn/2022/09/03/%E5%9B%BE%E5%83%8F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/"/>
    <id>https://www.dante-game.com.cn/2022/09/03/%E5%9B%BE%E5%83%8F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/</id>
    <published>2022-09-02T17:04:18.000Z</published>
    <updated>2022-09-25T12:57:48.788Z</updated>
    
    <content type="html"><![CDATA[<h1 id="图形渲染管线"><a href="#图形渲染管线" class="headerlink" title="图形渲染管线"></a>图形渲染管线</h1><h2 id="渲染管线概述"><a href="#渲染管线概述" class="headerlink" title="渲染管线概述"></a>渲染管线概述</h2><p>本文用于记录与整理实时渲染管线的流程,参考<a href="https://games-cn.org">GAMES101</a>,<a href="https://games-cn.org">GAMES104</a>,<a href="https://www.bilibili.com/video/BV1L54y1s7xw?p=2&amp;share_source=copy_web&amp;vd_source=da8280c5c3d89248027ccac72e16e11e">技术美术百人计划</a></p><p>图形渲染管线是一系列输入输出组合而成的流水线,即输入顶点数据,得到屏幕上显示的图像,这个过程中会经历很多操作来使得计算机能够将由顶点数据构成的图形显示成由像素块组成的屏幕上的图像</p><blockquote><p>很喜欢GAMES101里的一句话,我们往往会更关注what和why,而how是最不重要的地方<br>因此本文会注重WHAT与WHY,具体的HOW会以超链接形式插入(陆续补充…)</p></blockquote><span id="more"></span><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li><a href="#图形渲染管线">图形渲染管线</a><ul><li><a href="#渲染管线概述">渲染管线概述</a></li><li><a href="#目录">目录</a></li><li><a href="#渲染管线的分类">渲染管线的分类</a><ul><li><a href="#光栅化渲染管线">光栅化渲染管线</a></li><li><a href="#光线追踪渲染管线">光线追踪渲染管线</a></li></ul></li><li><a href="#整体流程">整体流程</a></li><li><a href="#具体流程">具体流程</a><ul><li><a href="#cpu应用阶段">CPU(应用阶段)</a><ul><li><a href="#1数据的读取">1.数据的读取</a></li><li><a href="#2准备基本数据">2.准备基本数据</a></li><li><a href="#3光源与阴影">3.光源与阴影</a></li><li><a href="#4加速算法">4.加速算法</a></li><li><a href="#5渲染设置">5.渲染设置</a></li><li><a href="#6输出到显存">6.输出到显存</a></li></ul></li><li><a href="#gpu">GPU</a><ul><li><a href="#gpu基础架构">GPU基础架构</a></li><li><a href="#simd-与simt">SIMD 与SIMT</a></li><li><a href="#7几何阶段">7.几何阶段</a></li><li><a href="#8光栅化阶段">8.光栅化阶段</a></li><li><a href="#9逐片元操作">9.逐片元操作</a></li><li><a href="#10后处理">10.后处理</a></li></ul></li></ul></li><li><a href="#总结">总结</a></li><li><a href="#补充">补充</a></li></ul></li></ul><h2 id="渲染管线的分类"><a href="#渲染管线的分类" class="headerlink" title="渲染管线的分类"></a>渲染管线的分类</h2><p>为了更好的说明渲染管线,首先不妨看一看渲染管线的分类和应用。</p><p>渲染管线就是将模型文件中的顶点数据转化成由屏幕上像素方块组成的图像的过程。可以说由AI中制作的矢量图形转换成PS中的像素图像这个过程也算是一种渲染管线。但我们平时玩游戏或者建模所接触到的渲染管线是面向三维的模型的。</p><h3 id="光栅化渲染管线"><a href="#光栅化渲染管线" class="headerlink" title="光栅化渲染管线"></a>光栅化渲染管线</h3><p>如游戏中的实时渲染管线，大多采用的是<font color = red><b>光栅化渲染管线</b></font>，即将顶点挨个变成像素，通过插值和计算补全由顶点组成的三角的空间,最终得到图像.这也是我们今天要主要介绍的渲染管线。</p><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220925202803.png" alt=""></p><p>光栅化的渲染管线也有 <strong>前向渲染管线</strong> 和 <strong>延迟渲染管线</strong>等分支，在unity中我们也可以通过URP、HDRP等基于可编程渲染管线的模板来自定义光栅化渲染管线。我们可以巧妙的利用各种缓存和绘制方式（不同的绘制顺序，规定绘制的范围）等来实现各种效果与性能的优化。所以有许多不同的光栅化渲染管线。</p><h3 id="光线追踪渲染管线"><a href="#光线追踪渲染管线" class="headerlink" title="光线追踪渲染管线"></a>光线追踪渲染管线</h3><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220925203932.png" alt=""><br>如果说在游戏中的渲染管线是为了满足实时性的话，那么光线追踪渲染管线就是为了满足真实性与准确性，我们愿意牺牲大量的时间对光线的反射进行计算。<br>光线追踪的渲染管线不是将顶点换算到像素块上然后进行计算，而是从像素块出发根据光路可逆的原则判断有哪些光线会被该像素点所接收（即判断射到人眼的同一方向上的所有光线），根据光线计算的不同方向（是否逆路径）将光线追踪分为了前向和后向光线追踪。<br>这并不是讨论的重点,可以看<a href="https://www.bilibili.com/video/BV1n5411M7pa/?spm_id_from=333.337.search-card.all.click&amp;vd_source=26f358375b19c380eea8013ae3143ec5">《十分钟看懂光线追踪到底是怎么追的？》</a>这个视频了解更多</p><blockquote><p>值得一提的是游戏中的光线追踪有的采用的高度优化的光线追踪渲染管线(如我的世界RTX),有的采用的是光栅化渲染管线加上光线追踪形成的部分信息</p></blockquote><h2 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h2><p>那么让我们来好好看一看光栅化的具体流程吧,记住输入是 顶点数据(.obj等文件),输出是屏幕上的像素</p><div class="table-container"><table><thead><tr><th style="text-align:center">阶段</th><th style="text-align:center">内容</th></tr></thead><tbody><tr><td style="text-align:center">应用阶段:</td><td style="text-align:center">粗颗粒剔除, 渲染设置, 准备基本数据, 输出到几何阶段</td></tr><tr><td style="text-align:center">几何阶段:</td><td style="text-align:center">顶点着色器, 曲面细分, 几何着色器, 顶点裁剪, 屏幕映射</td></tr><tr><td style="text-align:center">光栅化阶段:</td><td style="text-align:center">三角形设置, 三角形遍历, 片段着色器</td></tr><tr><td style="text-align:center">逐片元操作:</td><td style="text-align:center">裁剪测试, 透明度测试, 深度测试, 模板测试, 混合</td></tr><tr><td style="text-align:center">后处理:</td><td style="text-align:center">泛光 边缘检测 模糊 景深 HDR FXAA</td></tr></tbody></table></div><h2 id="具体流程"><a href="#具体流程" class="headerlink" title="具体流程"></a>具体流程</h2><p>渲染管线相当于一个流水线车间,加工产品是数据,磁盘上的数据会经过 cpu-&gt;gpu 这2个车间,最终加工成屏幕上像素点中的色彩信息</p><h3 id="CPU-应用阶段"><a href="#CPU-应用阶段" class="headerlink" title="CPU(应用阶段)"></a>CPU(应用阶段)</h3><h4 id="1-数据的读取"><a href="#1-数据的读取" class="headerlink" title="1.数据的读取"></a>1.数据的读取</h4><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210524125640.png" alt=""></p><p>我们的模型与贴图是存储在磁盘上的,这些数据是其他软件的加工品如3dmax,maya,blender等,里面存储着顶点,法线,uv等等我们常见的信息,当然也包含着一些为了更好的效果或者是更快的速度为软件所独有一些信息,这一部分信息是无法被有效利用的.<br>这些数据经过规整化(不同软件可能有着不同的数据定义方式),剔除掉不可用的数据,加载到了内存上以待进一步的处理.</p><h4 id="2-准备基本数据"><a href="#2-准备基本数据" class="headerlink" title="2.准备基本数据"></a>2.准备基本数据</h4><p>对于需要渲染的数据进行准备</p><ul><li>场景物体数据<ul><li>物体的变换数据(位置,缩放,旋转等)</li><li>物体的网格数据(顶点,贴图,法线,切线等)</li></ul></li><li>光源数据<ul><li>光源类型(方向光,点光,聚光等)</li><li>光源的位置,角度,方向,颜色等</li></ul></li><li>摄像机数据<ul><li>位置,方向,远近裁剪平面等</li><li>正交/透视模式</li><li>屏幕尺寸/比例等</li></ul></li></ul><h4 id="3-光源与阴影"><a href="#3-光源与阴影" class="headerlink" title="3.光源与阴影"></a>3.光源与阴影</h4><ul><li>设置光源<ul><li>方向光:颜色,方向等</li><li>点光:颜色,位置,范围等</li><li>聚光:颜色,位置,方向,内外圆锥角等</li></ul></li><li>设置阴影<ul><li>是否需要阴影</li><li>阴影参数:对应光源,阴影强度,级联参数,深度偏移,近平面偏移等</li></ul></li><li>逐光源绘制阴影贴图<ul><li>近平面偏移</li><li>逐级联<ul><li>计算当前光源+级联对应的观察矩阵、投影矩阵、阴影贴图的视口区域</li><li>绘制到阴影贴图</li></ul></li></ul></li></ul><h4 id="4-加速算法"><a href="#4-加速算法" class="headerlink" title="4.加速算法"></a>4.加速算法</h4><ul><li>可见光裁剪:裁剪掉距离过远,光线与视锥不相交的光源</li><li>场景物体裁剪:裁剪被遮挡,不在视锥范围内的物体<ul><li>八叉树</li><li>BSP树</li><li>K-D树</li><li>BVH包围盒</li></ul></li></ul><h4 id="5-渲染设置"><a href="#5-渲染设置" class="headerlink" title="5.渲染设置"></a>5.渲染设置</h4><ul><li>绘制设置<ul><li>使用不同着色器</li><li>合批方式(动态,静态批处理,GPU instance)</li></ul></li><li>绘制物体的顺序<ul><li>相对摄像机的距离</li><li>材质RenderQueue</li><li>UICanvas</li></ul></li><li>渲染目标<ul><li>FrameBuffer</li><li>RenderTexture</li></ul></li><li>渲染模式<ul><li>前向渲染</li><li>延迟渲染</li></ul></li></ul><h4 id="6-输出到显存"><a href="#6-输出到显存" class="headerlink" title="6.输出到显存"></a>6.输出到显存</h4><p>将之前处理好的顶点数据和其他数据如(mvp变换矩阵,纹理贴图等)按照渲染设置输出到GPU</p><h3 id="GPU"><a href="#GPU" class="headerlink" title="GPU"></a>GPU</h3><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220905140016.png" alt=""></p><h4 id="GPU基础架构"><a href="#GPU基础架构" class="headerlink" title="GPU基础架构"></a>GPU基础架构</h4><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220905131333.png" alt=""></p><p>GPU如图所示可以简单的划分为3个层级,</p><ul><li>GPU: 如图左下侧所示,主要由SM,DRAM(显存),L2(二级缓存)组成</li><li>GPC: 图形处理集群，一个GPU有多个GPC，一个GPC包含多个SM</li><li>SM: 计算单元，一个GPU有多个SM,每个SM如图右侧所示</li><li>Texture Units: 纹理处理单元，可以提取和过滤纹理</li><li>Core: 允许不同处理器同时处理数据的并行处理器</li><li>Warp: 在SM里面将SP（thread）进行分组，一般每32个thread称为一个warp</li></ul><blockquote><p>LD/ST：load/store，用于内存操作的，读取单元。<br>SFU：special function unit，来执行超指令（transcendental instruction）如正弦、余弦、倒数和平方根等函数。每个 SFU 一次执行一个线程块中一个线程的一条指令</p></blockquote><h4 id="SIMD-与SIMT"><a href="#SIMD-与SIMT" class="headerlink" title="SIMD 与SIMT"></a>SIMD 与SIMT</h4><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220905133545.png" alt=""></p><p><strong>SIMD</strong> (Single Instruction Multiple Data)</p><ul><li>单指令处理多数据,处理单元可以同时对多个数据点执行相同的操作(如向量加法)</li></ul><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20220905134337.png" alt=""></p><p><strong>SIMT</strong> (Single Instruction Multiple Threads)</p><ul><li>单指令处理多线程,并行计算中使用的一种执行模型，将单指令多数据(SIMD)与多线程结合在一起</li></ul><p>这样的硬件构成使得GPU能够轻松进行大量的浮点运算,尤为适合进行大量多维度数据的运算,当然也能通过硬件支持如sin,cos一类较为复杂的数学运算(机器学习中也使用到了GPU进行加速), 现代GPU更是将光线追踪的运算硬件化来适应实时光线追踪.</p><blockquote><p>注意这只是电脑的GPU架构,在移动手机端的架构更加特殊,所以所使用的渲染管线也相应的有一定的调整(TBDR基于块元的渲染),这里不多做叙述</p><h4 id="7-几何阶段"><a href="#7-几何阶段" class="headerlink" title="7.几何阶段"></a>7.几何阶段</h4></blockquote><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210525075935.png" alt=""></p><ul><li>顶点着色<ul><li>视图变换(MVP): <code>将模型坐标空间转换到了裁剪坐标空间</code></li><li>顶点着色</li></ul></li><li>曲面细分着色器-&gt;几何着色器: <code>在原有的顶点数据基础上进一步增加新的顶点数据来实现不同的效果</code><ul><li>曲面细分</li><li>几何着色</li></ul></li><li>投影<ul><li>除以w将投影坐标系转换到NDC标准坐标系</li></ul></li><li>裁剪<ul><li>视锥体裁剪(CVV)</li><li>正面背面剔除</li></ul></li><li>屏幕映射: <code>将裁剪空间转换到屏幕空间</code><ul><li>视口转化(xy分别映射到WH,z映射到远近平面,平移+缩放)</li></ul></li></ul><h4 id="8-光栅化阶段"><a href="#8-光栅化阶段" class="headerlink" title="8.光栅化阶段"></a>8.光栅化阶段</h4><ul><li>三角形设置(计算三角形/直线边界信息,图元装配)</li><li>三角形遍历(检查像素是否被三角形覆盖,若在三角形内计算插值(<a href="http://t.csdn.cn/7exaw">重心坐标与透视矫正</a>),更新深度)</li><li>抗锯齿(MSAA,SSAA,FXAA/TXAA(后处理))</li></ul><h4 id="9-逐片元操作"><a href="#9-逐片元操作" class="headerlink" title="9.逐片元操作"></a>9.逐片元操作</h4><ul><li>片段着色: <code>绘制阶段,在这之前都没有绘图操作</code></li><li>颜色混合<ul><li>透明度测试</li><li>深度测试</li><li>模板测试</li></ul></li><li>目标缓冲区</li></ul><h4 id="10-后处理"><a href="#10-后处理" class="headerlink" title="10.后处理"></a>10.后处理</h4><ul><li>泛光</li><li>边缘检测</li><li>模糊</li><li>景深</li><li>HDR</li><li>FXAA<br>……</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">flowchart TB</span><br><span class="line">subgraph 渲染管线</span><br><span class="line">  subgraph 应用阶段</span><br><span class="line">    direction LR</span><br><span class="line">    数据--粗颗粒剔除--&gt;渲染设置</span><br><span class="line">  end</span><br><span class="line">  subgraph 几何阶段</span><br><span class="line">    direction LR</span><br><span class="line">    顶点着色器--&gt;曲面细分着色器--&gt;几何着色器--&gt;投影--&gt;裁剪--&gt;屏幕映射</span><br><span class="line">  end</span><br><span class="line">  subgraph 光栅化阶段</span><br><span class="line">    direction LR</span><br><span class="line">    三角形设置--&gt;三角形遍历--&gt;片段着色器</span><br><span class="line">  end</span><br><span class="line">  subgraph 逐片元操作</span><br><span class="line">    direction LR</span><br><span class="line">    裁剪测试--&gt;透明度测试--&gt;模板测试--&gt;深度测试</span><br><span class="line">  end</span><br><span class="line">  后处理</span><br><span class="line">end</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>渲染管线是一个复杂的流水线, 理解起来会有很多误区, 这里简单的介绍了一下通用的渲染管线以加深理解.如果以一个顶点的一生来描述渲染管线的话:</p><ul><li><strong>应用</strong><br>存储在磁盘上的顶点A被选择有效数据后加载到内存上,cpu对他的同胞数据进行了各种处理,处理结果会最终作用到自己身上,顶点A被识别为三角形的一员送入了GPU;</li><li><strong>几何</strong><br>GPU中顶点A经历了模型矩阵,视口矩阵,投影矩阵的变换;模型被细分后加入了许多新顶点,顶点A随之进行了位置的调整,加入了新的三角形中;顶点A除以自身的w后被转换到了一个以原点为中心向各轴延展1的正方形空间中,没有被划分进来的顶点被裁剪掉了,划分了一半的三角形为了维持形状新增了新的顶点进行补全,根据三角形绘制时针方向判断正反面,不该被渲染的面也被剔除掉了,顶点A再次转换到了屏幕空间中(0-W,0-H,Near-Far),顶点A覆盖了像素B,接下来就是像素B的一生了</li><li><strong>光栅化</strong><br>像素B是顶点A在其坐标所对应的像素,但他属于许多三角形,三角形通过顶点的插值决定了三角形在像素B上的数据,像素B要根据深度测试,alpha测试等判断是否要采用三角形的数据,同样应用阶段的各种数据也会作用到像素B的生成上(如阴影,光照等),像素B经过各种数据的混合最终变成了屏幕上所显示的像素</li></ul><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><ul><li>各种测试的相对顺序：裁剪-&gt;Alpha-&gt;模板-&gt;深度</li><li>Early-Z<ul><li>Early-Z是一种提前深度测试的技术，它位于光栅化阶段之后，像素处理阶段之前，目的是减少进入像素着色阶段的片段，优化性能。Early-Z会带来透明测试的冲突，例如某个片元A虽然遮挡了另一个片元B，但A却是透明的，GPU应当渲染的是片元B，这就产生了矛盾，这就是透明度测试会导致性能下降的原因(因为无法用Early-Z)，但是有一种叫PreZ的技术可以解决这个问题，参考上面的链接，不再详述。</li></ul></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;图形渲染管线&quot;&gt;&lt;a href=&quot;#图形渲染管线&quot; class=&quot;headerlink&quot; title=&quot;图形渲染管线&quot;&gt;&lt;/a&gt;图形渲染管线&lt;/h1&gt;&lt;h2 id=&quot;渲染管线概述&quot;&gt;&lt;a href=&quot;#渲染管线概述&quot; class=&quot;headerlink&quot; title=&quot;渲染管线概述&quot;&gt;&lt;/a&gt;渲染管线概述&lt;/h2&gt;&lt;p&gt;本文用于记录与整理实时渲染管线的流程,参考&lt;a href=&quot;https://games-cn.org&quot;&gt;GAMES101&lt;/a&gt;,&lt;a href=&quot;https://games-cn.org&quot;&gt;GAMES104&lt;/a&gt;,&lt;a href=&quot;https://www.bilibili.com/video/BV1L54y1s7xw?p=2&amp;amp;share_source=copy_web&amp;amp;vd_source=da8280c5c3d89248027ccac72e16e11e&quot;&gt;技术美术百人计划&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;图形渲染管线是一系列输入输出组合而成的流水线,即输入顶点数据,得到屏幕上显示的图像,这个过程中会经历很多操作来使得计算机能够将由顶点数据构成的图形显示成由像素块组成的屏幕上的图像&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;很喜欢GAMES101里的一句话,我们往往会更关注what和why,而how是最不重要的地方&lt;br&gt;因此本文会注重WHAT与WHY,具体的HOW会以超链接形式插入(陆续补充…)&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="计算机图形学" scheme="https://www.dante-game.com.cn/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
    <category term="学习" scheme="https://www.dante-game.com.cn/tags/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="记录" scheme="https://www.dante-game.com.cn/tags/%E8%AE%B0%E5%BD%95/"/>
    
    <category term="经验" scheme="https://www.dante-game.com.cn/tags/%E7%BB%8F%E9%AA%8C/"/>
    
    <category term="计算机图形学" scheme="https://www.dante-game.com.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="游戏引擎" scheme="https://www.dante-game.com.cn/tags/%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E/"/>
    
  </entry>
  
  <entry>
    <title>OpenGL_03_坐标系统与摄像机</title>
    <link href="https://www.dante-game.com.cn/2021/05/25/OpenGL-03-%E5%9D%90%E6%A0%87%E7%B3%BB%E7%BB%9F%E4%B8%8E%E6%91%84%E5%83%8F%E6%9C%BA/"/>
    <id>https://www.dante-game.com.cn/2021/05/25/OpenGL-03-%E5%9D%90%E6%A0%87%E7%B3%BB%E7%BB%9F%E4%B8%8E%E6%91%84%E5%83%8F%E6%9C%BA/</id>
    <published>2021-05-25T00:55:42.000Z</published>
    <updated>2022-09-02T06:49:21.358Z</updated>
    
    <content type="html"><![CDATA[<h1 id="坐标系统与摄像机"><a href="#坐标系统与摄像机" class="headerlink" title="坐标系统与摄像机"></a>坐标系统与摄像机</h1><p>本篇简单的记录了关于坐标系统的机制与摄像机,为了方便理解去掉了数学内容,详细的后面会写</p><h2 id="坐标系统"><a href="#坐标系统" class="headerlink" title="坐标系统"></a>坐标系统</h2><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210525075935.png" alt=""></p><p>我们先来认识这张图,为了将坐标从一个坐标系转换到另一个坐标系，我们需要用到几个转换矩阵，最重要的几个分别是<strong>模型(Model)</strong> 、<strong>视图(View)</strong> 、<strong>投影(Projection)</strong> 三个矩阵。首先，顶点坐标开始于<strong>局部空间(Local Space)</strong> ，称为<strong>局部坐标(Local Coordinate)</strong> ，然后经过<strong>世界坐标(World Coordinate)</strong> ，<strong>观察坐标(View Coordinate)</strong> ，<strong>裁剪坐标(Clip Coordinate)</strong> ，并最后以<strong>屏幕坐标(Screen Coordinate)</strong> 结束。</p><span id="more"></span><p>我们先理解每个矩阵的作用,从开始到结尾一共经过了四个过程:</p><ol><li>Model Matrix</li><li>View Matrix</li><li>Projection Matrix</li><li>Viewport Transform</li></ol><ul><li><strong>Model Matrix</strong><br>我们知道模型坐标以点位置的形式传入着色器, 这些点的参考原点就是本地坐标的原点,即使模型做了变化,这些变化都是相对于原点的变化. 可以理解为3D软件中模型中心点的意思,我们的操作都是以中心点为参照进行的</li><li><strong>View Matrix</strong><br>显然,这样并不能让模型很直观的显示出来,所以我们需要一个View Matrix来设置一个摄像机来观察模型,具体会在下一个点提到.</li><li><p><strong>Projection Matrix</strong><br>我们现在得到了View Space,但这样的视图显然并不是我们想要的最终结果. 通过Projection Matrix我们将指定范围的坐标转换到标准化设备坐标系中(-1,1). 这是一个投影(Projection)的过程, 他会减裁掉多余的坐标保留我们所看到的部分,得到<strong>裁剪坐标(Clip Coordinate)</strong>. 投影矩阵除了起到减裁的作用,还能够指定投影的方式, <strong>正射投影(Orthographic Projection)</strong> 将坐标以正交的方式投影到标准坐标系,呈现中国画的透视关系;而<strong>透视投影(Perspective Projection)</strong> 创建一定角度的平截头体来实现我们人眼所见的透视关系,如下图:</p><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210525075953.png" alt=""><br>我们可以简单看看代码</p><p><strong>正射投影</strong><code>glm::ortho(0.0f, 800.0f, 0.0f, 600.0f, 0.1f, 100.0f);</code>前两个参数指定了平截头体的左右坐标，第三和第四参数指定了平截头体的底部和上部,第五和第六个参数则定义了近平面和远平面的距离。这个指定的投影矩阵将处于这些x，y，z范围之间的坐标转换到标准化设备坐标系中。</p><p><strong>透视投影</strong><code>glm::mat4 proj = glm::perspective(45.0f, (float)width/(float)height, 0.1f, 100.0f);</code>它的第一个参数定义了<strong>fov</strong> 的值,第二个参数设置了宽高比，第三和第四个参数设置了平截头体的近和远平面。</p><blockquote><p>如果只是片段的一部分例如三角形，超出了裁剪体积(Clipping Volume)，则OpenGL会重新构建三角形以使一个或多个三角形能适应在裁剪范围内。</p></blockquote></li><li><p><strong>Viewport Transform</strong></p><p>一旦所有顶点被转换到裁剪空间，最终的操作——<strong>透视划分(Perspective Division)</strong> 将会执行，在这个过程中我们将位置向量的x，y，z分量分别除以向量的齐次w分量；透视划分是将4维裁剪空间坐标转换为3维标准化设备坐标。这一步会在每一个顶点着色器运行的最后被自动执行。</p><p>在这一阶段之后，坐标经过转换的结果将会被映射到屏幕空间(由<code>glViewport</code>设置)且被转换成片段。</p></li></ul><p>$V<em>{clip} = M</em>{projection} \cdot M<em>{view} \cdot M</em>{model} \cdot V_{local}$就是这些矩阵变化的最终组合,他将被传入着色器</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#version 330 core</span><br><span class="line">layout (location = 0) in vec3 position;</span><br><span class="line">...</span><br><span class="line">uniform mat4 model;</span><br><span class="line">uniform mat4 view;</span><br><span class="line">uniform mat4 projection;</span><br><span class="line"></span><br><span class="line">void main()</span><br><span class="line">&#123;</span><br><span class="line">    // 注意从右向左读</span><br><span class="line">    gl_Position = projection * view * model * vec4(position, 1.0f);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="摄像机"><a href="#摄像机" class="headerlink" title="摄像机"></a>摄像机</h2><p>摄像机如何才能满足我们的需求呢, 我们不妨摄像摄像机所需的参数:  摄像机的位置, 摄像机的方向, 摄像机的变换</p><ul><li>摄像机的位置<br>我们通过对目标的相对移动来控制摄像机的位置, 故我们可以相对于原点传入摄像机位置的反方向.</li><li>摄像机的方向<br>我们可以指定目标的位置,通过向量相减我们可以得到摄像机的朝向向量,反之亦然</li><li>摄像机的变换<br>我们在各种三维软件中所认识的摄像机都能通过各种变换来得到一个理想的视角, 想要进行这些变换就需要对摄像机进行矩阵运算,但现在我们并没有一个属于摄像机的坐标空间, 所以我们要利用前面向量和矩阵中的方法来建立一个摄像机坐标空间<details>我们需要的另一个向量是一个右向量(Right Vector)，它代表摄像机空间的x轴的正方向。为获取右向量我们需要先使用一个小技巧：定义一个上向量(Up Vector)。我们把上向量和第二步得到的摄像机方向向量进行叉乘。两个向量叉乘的结果就是同时垂直于两向量的向量，因此我们会得到指向x轴正方向的那个向量(如果我们交换两个向量的顺序就会得到相反的指向x轴负方向的向量)：现在我们已经有了x轴向量和z轴向量，获取摄像机的正y轴相对简单；我们把右向量和方向向量(Direction Vector)进行叉乘;</details></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">glm::vec3 up = glm::vec3(0.0f, 1.0f, 0.0f); </span><br><span class="line">glm::vec3 cameraRight = glm::normalize(glm::cross(up, cameraDirection));</span><br><span class="line">glm::vec3 cameraUp = glm::cross(cameraDirection, cameraRight);</span><br></pre></td></tr></table></figure><p>可以简单的看看官方给出的<a href="https://learnopengl.com/code_viewer.php?code=getting-started/camera_zoom">源码</a>理解下</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;坐标系统与摄像机&quot;&gt;&lt;a href=&quot;#坐标系统与摄像机&quot; class=&quot;headerlink&quot; title=&quot;坐标系统与摄像机&quot;&gt;&lt;/a&gt;坐标系统与摄像机&lt;/h1&gt;&lt;p&gt;本篇简单的记录了关于坐标系统的机制与摄像机,为了方便理解去掉了数学内容,详细的后面会写&lt;/p&gt;
&lt;h2 id=&quot;坐标系统&quot;&gt;&lt;a href=&quot;#坐标系统&quot; class=&quot;headerlink&quot; title=&quot;坐标系统&quot;&gt;&lt;/a&gt;坐标系统&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210525075935.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们先来认识这张图,为了将坐标从一个坐标系转换到另一个坐标系，我们需要用到几个转换矩阵，最重要的几个分别是&lt;strong&gt;模型(Model)&lt;/strong&gt; 、&lt;strong&gt;视图(View)&lt;/strong&gt; 、&lt;strong&gt;投影(Projection)&lt;/strong&gt; 三个矩阵。首先，顶点坐标开始于&lt;strong&gt;局部空间(Local Space)&lt;/strong&gt; ，称为&lt;strong&gt;局部坐标(Local Coordinate)&lt;/strong&gt; ，然后经过&lt;strong&gt;世界坐标(World Coordinate)&lt;/strong&gt; ，&lt;strong&gt;观察坐标(View Coordinate)&lt;/strong&gt; ，&lt;strong&gt;裁剪坐标(Clip Coordinate)&lt;/strong&gt; ，并最后以&lt;strong&gt;屏幕坐标(Screen Coordinate)&lt;/strong&gt; 结束。&lt;/p&gt;</summary>
    
    
    
    <category term="计算机图形学" scheme="https://www.dante-game.com.cn/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
    <category term="学习" scheme="https://www.dante-game.com.cn/tags/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="记录" scheme="https://www.dante-game.com.cn/tags/%E8%AE%B0%E5%BD%95/"/>
    
    <category term="经验" scheme="https://www.dante-game.com.cn/tags/%E7%BB%8F%E9%AA%8C/"/>
    
    <category term="计算机图形学" scheme="https://www.dante-game.com.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="OpenGL" scheme="https://www.dante-game.com.cn/tags/OpenGL/"/>
    
  </entry>
  
  <entry>
    <title>OpenGL_02_向量和矩阵</title>
    <link href="https://www.dante-game.com.cn/2021/05/24/OpenGL-02-%E5%90%91%E9%87%8F%E5%92%8C%E7%9F%A9%E9%98%B5/"/>
    <id>https://www.dante-game.com.cn/2021/05/24/OpenGL-02-%E5%90%91%E9%87%8F%E5%92%8C%E7%9F%A9%E9%98%B5/</id>
    <published>2021-05-24T08:47:26.000Z</published>
    <updated>2022-09-02T06:49:21.358Z</updated>
    
    <content type="html"><![CDATA[<h1 id="向量和矩阵"><a href="#向量和矩阵" class="headerlink" title="向量和矩阵"></a>向量和矩阵</h1><p>默认大家都学过向量和矩阵,这里就记录一些核心的东西</p><h2 id="向量"><a href="#向量" class="headerlink" title="向量"></a>向量</h2><h3 id="向量点积-dot-product"><a href="#向量点积-dot-product" class="headerlink" title="向量点积(dot product)"></a>向量点积(dot product)</h3><p>向量点积，也称为向量的数量积，点积的结果是一个标量，其定义为$|\ A\ |\cdot{|\ B\ |\cos\theta}$,其几何意义如下,一般用于计算投影和夹角<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210524154830.png" alt=""></p><span id="more"></span><h3 id="向量的叉积-cross-product"><a href="#向量的叉积-cross-product" class="headerlink" title="向量的叉积(cross product)"></a>向量的叉积(cross product)</h3><p>两个向量a和b的叉积,结果是一个向量$c=a×b$,c的方向垂直于a和b，据右手规则来确定；c的大小等于  $|c| = |a||b|\sin\theta$<img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210524155621.png" alt=""></p><blockquote><p>$a×b=−b×a$</p></blockquote><p>在利用以坐标形式表示向量a和b时，在3D空间中，叉积的结果用矩阵表示为:<br>$c = a×b\=<br>\begin{bmatrix}<br>i&amp;j&amp;k\<br>a_x&amp;a_y&amp;a_z\<br>b_x&amp;b_y&amp;b_z\<br>\end{bmatrix} $</p><p>$=<br>\begin{bmatrix}<br>a_y&amp;a_z\<br>b_y&amp;b_z<br>\end{bmatrix}i-<br>\begin{bmatrix}<br>a_x&amp;a_z\<br>b_x&amp;b_z<br>\end{bmatrix}j+<br>\begin{bmatrix}<br>a_x&amp;a_y\<br>b_x&amp;b_y<br>\end{bmatrix}k$</p><p>$=<br>\begin{bmatrix}<br>a_yb_z-a_zb_y\<br>a_xb_z-a_zb_x\<br>a_xb_y-a_yb_x<br>\end{bmatrix}<br>$</p><blockquote><p>其中 i,j,k为x,y,z三个方向上的单位向量</p></blockquote><p>叉积的几何意义<br>叉积的模可以视为以a和b为两边的平行四边形的面积，如下图所示<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210524162017.png" alt=""><br>同时在OpenGL中还可以用来确定第三个方向 $up=dir×side$</p><h2 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h2><h3 id="矩阵和矩阵乘法"><a href="#矩阵和矩阵乘法" class="headerlink" title="矩阵和矩阵乘法"></a>矩阵和矩阵乘法</h3><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210524162238.png" alt=""><br>向量的点积公式可以重新表示为:<br>$a=(a1,b2,⋯,cn),\ b=(b1,b2,⋯,bn)$</p><p>$a\cdot{b}=a<em>1b_1+a_2b_2+\dots+a_nb_n\$<br>$=\sum</em>{i=1}^na_ib_i\$<br>$=a^Tb$</p><h3 id="行列式"><a href="#行列式" class="headerlink" title="行列式"></a>行列式</h3><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210524163031.png" alt=""></p><h3 id="逆矩阵"><a href="#逆矩阵" class="headerlink" title="逆矩阵"></a>逆矩阵</h3><p>对于n阶方阵A，如果存在一个n阶方阵B使得:$AB=BA=I_{nxn}$</p><ul><li>逆矩阵的应用意义<br>在3D图形处理中，用一个变换矩阵乘以向量，代表了对原始图形进行了某种变换，例如缩小，旋转等，逆矩阵表示这个操作的逆操作，也就是能够撤销这一操作。例如对一个向量$v$用矩阵$M$相乘，然后再用$M^{−1}$相乘，则能得到原来的向量$v$</li></ul><blockquote><p>注意转换矩阵应用顺序 当用矩阵$A,B,C$转换向量$v$时，如果$v$用行向量记法，则矩阵按转换顺序从左往右列出，表达为$vABC$;如果$v$采用列向量记法，则转换矩阵应该放在左边，并且转换从右往左发生，对应的转换记为$CBAv$</p></blockquote><h3 id="正交矩阵"><a href="#正交矩阵" class="headerlink" title="正交矩阵"></a>正交矩阵</h3><p>对于方阵M，当且仅当$M$与其转置矩阵$M^T$的乘积等于单位矩阵时，称其为正交矩阵。即：$MM^T=E$正交矩阵的一大优势在于，计算逆矩阵时，只需要对原矩阵转置即可，从而减少了计算量。在3D图形处理中的旋转和镜像变换都是正交的</p><blockquote><p>正交矩阵一定是可逆的</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;向量和矩阵&quot;&gt;&lt;a href=&quot;#向量和矩阵&quot; class=&quot;headerlink&quot; title=&quot;向量和矩阵&quot;&gt;&lt;/a&gt;向量和矩阵&lt;/h1&gt;&lt;p&gt;默认大家都学过向量和矩阵,这里就记录一些核心的东西&lt;/p&gt;
&lt;h2 id=&quot;向量&quot;&gt;&lt;a href=&quot;#向量&quot; class=&quot;headerlink&quot; title=&quot;向量&quot;&gt;&lt;/a&gt;向量&lt;/h2&gt;&lt;h3 id=&quot;向量点积-dot-product&quot;&gt;&lt;a href=&quot;#向量点积-dot-product&quot; class=&quot;headerlink&quot; title=&quot;向量点积(dot product)&quot;&gt;&lt;/a&gt;向量点积(dot product)&lt;/h3&gt;&lt;p&gt;向量点积，也称为向量的数量积，点积的结果是一个标量，其定义为$|\ A\ |\cdot{|\ B\ |\cos\theta}$,其几何意义如下,一般用于计算投影和夹角&lt;br&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210524154830.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="计算机图形学" scheme="https://www.dante-game.com.cn/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
    <category term="学习" scheme="https://www.dante-game.com.cn/tags/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="记录" scheme="https://www.dante-game.com.cn/tags/%E8%AE%B0%E5%BD%95/"/>
    
    <category term="经验" scheme="https://www.dante-game.com.cn/tags/%E7%BB%8F%E9%AA%8C/"/>
    
    <category term="计算机图形学" scheme="https://www.dante-game.com.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="OpenGL" scheme="https://www.dante-game.com.cn/tags/OpenGL/"/>
    
  </entry>
  
  <entry>
    <title>OpenGL_01_OpenGL的绘图基本流程与概念</title>
    <link href="https://www.dante-game.com.cn/2021/05/24/OpenGL_01_OpenGL%E7%9A%84%E7%BB%98%E5%9B%BE%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B%E4%B8%8E%E6%A6%82%E5%BF%B5/"/>
    <id>https://www.dante-game.com.cn/2021/05/24/OpenGL_01_OpenGL%E7%9A%84%E7%BB%98%E5%9B%BE%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B%E4%B8%8E%E6%A6%82%E5%BF%B5/</id>
    <published>2021-05-24T05:21:14.000Z</published>
    <updated>2022-09-02T06:49:21.359Z</updated>
    
    <content type="html"><![CDATA[<h1 id="OpenGL的绘图基本流程与概念"><a href="#OpenGL的绘图基本流程与概念" class="headerlink" title="OpenGL的绘图基本流程与概念"></a>OpenGL的绘图基本流程与概念</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本博客仅记录本人的理解<br>全部内容来源于<a href="https://learnopengl-cn.readthedocs.io/zh/latest/">OpenGL</a>与<a href="http://colin1994.github.io/2017/11/11/OpenGLES-Lesson04/">GLSL</a>以及<a href="https://space.bilibili.com/211153830">傅老师OpenGL课程</a><br>如有问题,欢迎评论<br><span id="more"></span></p><h2 id="图形渲染管线"><a href="#图形渲染管线" class="headerlink" title="图形渲染管线"></a>图形渲染管线</h2><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210524115540.png" alt=""></p><p>图形渲染管线可以被划分为两个主要部分：</p><ul><li>第一部分把你的3D坐标转换为2D坐标</li><li>第二部分是把2D坐标转变为实际的有颜色的像素。<blockquote><p>分别对应第一排和第二排,实际学习中我们基本只用关注vertex shader和fragment shader,其他暂且不管</p></blockquote></li></ul><p>而图形渲染管线的输入便是顶点数据(vertex data),可以包含空间位置,颜色,uv等等信息</p><h2 id="GPU与CPU"><a href="#GPU与CPU" class="headerlink" title="GPU与CPU"></a>GPU与CPU</h2><p>首先我们需要对CPU与GPU有一定的认识,打个比方CPU就像是精英怪或者BOSS,GPU就像是小兵,GPU有着很高的性能,但对于大量的简单运算就显得CPU势单力薄,而GPU却能很好的解决这些问题,GPU有着庞大的基数,虽然每个GPU只能进行简单的运算和处理,但处理大量简单运算时速度就比孤军奋战的CPU快很多.所以在OpenGL中我们使用GPU来处理庞大的顶点数据,而这些运行在GPU的程序被称为shader也就是着色器.  </p><h2 id="VAO与VBO"><a href="#VAO与VBO" class="headerlink" title="VAO与VBO"></a>VAO与VBO</h2><p>所以我们来看这样一幅图<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210524122721.png" alt="">  </p><h3 id="VBO-顶点缓冲对象-Vertex-Buffer-Objects"><a href="#VBO-顶点缓冲对象-Vertex-Buffer-Objects" class="headerlink" title="VBO (顶点缓冲对象 [Vertex Buffer Objects] )"></a>VBO (顶点缓冲对象 [Vertex Buffer Objects] )</h3><p>CPU中的顶点数据通过一系列过程传输到GPU,为了节省CPU宝贵的内存,传输到GPU的数据会以数组的形式被立即保存在VBO中使用这些缓冲对象的好处是我们可以一次性的发送一大批数据到显卡上，而不是每个顶点发送一次。从CPU把数据发送到显卡相对较慢，所以只要可能我们都要尝试尽量一次性发送尽可能多的数据。当数据发送至显卡的内存中后，顶点着色器几乎能立即访问顶点，这是个非常快的过程。</p><h3 id="VAO-顶点数组对象-Vertex-Array-Object"><a href="#VAO-顶点数组对象-Vertex-Array-Object" class="headerlink" title="VAO (顶点数组对象 [Vertex Array Object] )"></a>VAO (顶点数组对象 [Vertex Array Object] )</h3><p>顶点着色器允许我们指定任何以顶点属性为形式的输入.我们传入VBO的数组有顶点位置有颜色有uv等各种信息,显然我们的顶点着色器是无法区分这些信息的.所以我们需要用VAO来让顶点着色器认识我们VBO数组中传入的信息都是些什么.我们的顶点缓冲数据会被解析为下面这样子：<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210524124443.png" alt=""><br>我们会指定每几个数据位一个顶点,如图中每3个数据为一个顶点的位置,如果有多个类型的数据,比如0,1,2为位置数据;3,4,5为颜色数据;6,7为uv数据,我们就需要指定8为一个步长,其中前三个为位置数据,偏移量为3的3个数据为颜色数据;偏移量为6的2个数据为uv数据.<br>将这些标注好后VAO就像下图一样<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210524125024.png" alt="">  </p><h3 id="EBO-索引缓冲对象-Element-Buffer-Object-也叫-Index-Buffer-Object，IBO"><a href="#EBO-索引缓冲对象-Element-Buffer-Object-也叫-Index-Buffer-Object，IBO" class="headerlink" title="EBO(索引缓冲对象 [ Element Buffer Object] 也叫 [Index Buffer Object，IBO] )"></a>EBO(索引缓冲对象 [ Element Buffer Object] 也叫 [Index Buffer Object，IBO] )</h3><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210524122721.png" alt=""><br>我们回到最开始的那张图,可以看出VAO除了Array buffer 还有一个Element Buffer.<br>在用glDrawArrays(GL_TRIANGLES)绘图时,如果我们只指定Array buffer,那么OpenGL就会以数组的顺序挨个逆时针以三角形的形式绘制这些顶点. 如果我们的图形较为复杂,这意味着会有很多重复的顶点出现,这会让我们的数组显得非常冗长,这时候我们可以定义一个EBO用来指定绘制顺序,如[0,1,2,1,0,2]就是以0,1,2的顺序绘制第一个三角形,再以1,0,2的顺序绘制第二个三角形</p><blockquote><p>注意:当目标是GL_ELEMENT_ARRAY_BUFFER的时候，VAO会储存glBindBuffer的函数调用。这也意味着它也会储存解绑调用，所以确保你没有在解绑VAO之前解绑索引数组缓冲，否则它就没有这个EBO配置了。  </p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210524125640.png" alt=""></p><h2 id="着色器-Shader"><a href="#着色器-Shader" class="headerlink" title="着色器 Shader"></a>着色器 Shader</h2><p>之前已经提到,着色器就是运行在GPU中的一个一个小程序.目前我们主要使用顶点着色器(vertex shader)和片段着色器(fragment shader).对于着色器,我们采用的是GLSL语言(OpenGL Shading Language)编写的程序,类似于C语言程序。<br>要使用着色器需要经历3个步骤:</p><ol><li>创建和编译shader object</li><li>创建shader program,链接多个shader object到program</li><li>在绘制场景时启用shader program<br>具体流程如下图所示:<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210524130018.png" alt=""><br>我们可以通过两个简单的顶点着色器代码来认识Shader</li></ol><ul><li>顶点着色器<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#version 330   // 指定GLSL版本3.3</span><br><span class="line"></span><br><span class="line">layout(location = 0) in vec3 position; // 顶点属性索引</span><br><span class="line"></span><br><span class="line">void main()</span><br><span class="line">&#123;</span><br><span class="line">    gl_Position = vec4(position, 1.0); // 输出顶点</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>片段着色器<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#version 330</span><br><span class="line"></span><br><span class="line">out vec4 color; // 输出片元颜色</span><br><span class="line"></span><br><span class="line">void main()</span><br><span class="line">&#123;</span><br><span class="line">    color = vec4(0.8, 0.8, 0.0, 1.0);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>着色器程序通过in 和 out也就是输入与输出连成一条线; 我们的顶点数据通过in传入顶点着色器然后输出顶点,然后顶点着色器的out通过片段着色器的in传入片段着色器并进行输出<blockquote><p>这里由于传入的数据没有颜色数据,所以在片段着色器的main中指定了一个颜色</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>由于qt和glfw语法略有不同, 且官网有具体代码, 这里只介绍流程</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.加载库</span><br><span class="line">2.创建窗口</span><br><span class="line">3.传入数据</span><br><span class="line">4.定义VBO,并传入数据</span><br><span class="line">5.定义VAO,并链接VBO</span><br><span class="line">6.创建着色器程序</span><br><span class="line">7.创建引擎(渲染与其他操作)</span><br></pre></td></tr></table></figure></blockquote></li></ul><h2 id="状态机"><a href="#状态机" class="headerlink" title="状态机"></a>状态机</h2><p>OpenGL自身是一个巨大的状态机<strong>状态机(State Machine)</strong><br>一系列的变量描述OpenGL此刻应当如何运行。OpenGL的正在运行的状态通常被称为OpenGL上下文(Context)。<br>我们通常使用如下途径去更改OpenGL状态：设置选项，操作缓冲。<br>最后，我们使用当前OpenGL上下文来渲染。<br>假设当我们想告诉OpenGL去画线段而不是三角形的时候，我们通过改变一些上下文变量来改变OpenGL状态，从而告诉OpenGL如何去绘图。一旦我们改变了OpenGL的状态为绘制线段，下一个绘制命令就会画出线段而不是三角形。<br>所以OpenGL本质上是个大<strong>状态机</strong><br>下图是之前所提到的内容用状态机来表示的示例,我们可以通过glEnable来操作状态机里的各种状态<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210524151729.png" alt="">  </p><blockquote><p>VAO只能绑定一个VBO,所以如果有其他数据,需要解绑当前的VBO在bind所需VBO</p></blockquote><h2 id="对象"><a href="#对象" class="headerlink" title="对象"></a>对象</h2><p>OpenGL库是用C语言写的，内核是一个C库。由于C的一些语言结构不易被翻译到其它的高级语言，因此OpenGL开发的时候引入了一些抽象层。“对象(Object)”就是其中一个。<br>在OpenGL中一个对象是指一些选项的集合，它代表OpenGL状态的一个子集。比如，我们可以用一个对象来代表绘图窗口的设置，之后我们就可以设置它的大小、支持的颜色位数等等。可以把对象看做一个C风格的结构体(Struct)：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">struct object_name &#123;</span><br><span class="line">    float  option1;</span><br><span class="line">    int    option2;</span><br><span class="line">    char[] name;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><br>当我们使用一个对象时，通常看起来像如下一样（把OpenGL上下文看作一个大的结构体）：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// OpenGL的状态</span><br><span class="line">struct OpenGL_Context &#123;</span><br><span class="line">    ...</span><br><span class="line">    object* object_Window_Target;</span><br><span class="line">    ...     </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// 创建对象</span><br><span class="line">unsigned int objectId = 0;</span><br><span class="line">glGenObject(1, &amp;objectId);</span><br><span class="line">// 绑定对象至上下文</span><br><span class="line">glBindObject(GL_WINDOW_TARGET, objectId);</span><br><span class="line">// 设置当前绑定到 GL_WINDOW_TARGET 的对象的一些选项</span><br><span class="line">glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_WIDTH, 800);</span><br><span class="line">glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_HEIGHT, 600);</span><br><span class="line">// 将上下文对象设回默认,解绑对象</span><br><span class="line">glBindObject(GL_WINDOW_TARGET, 0);</span><br></pre></td></tr></table></figure></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;OpenGL的绘图基本流程与概念&quot;&gt;&lt;a href=&quot;#OpenGL的绘图基本流程与概念&quot; class=&quot;headerlink&quot; title=&quot;OpenGL的绘图基本流程与概念&quot;&gt;&lt;/a&gt;OpenGL的绘图基本流程与概念&lt;/h1&gt;&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;本博客仅记录本人的理解&lt;br&gt;全部内容来源于&lt;a href=&quot;https://learnopengl-cn.readthedocs.io/zh/latest/&quot;&gt;OpenGL&lt;/a&gt;与&lt;a href=&quot;http://colin1994.github.io/2017/11/11/OpenGLES-Lesson04/&quot;&gt;GLSL&lt;/a&gt;以及&lt;a href=&quot;https://space.bilibili.com/211153830&quot;&gt;傅老师OpenGL课程&lt;/a&gt;&lt;br&gt;如有问题,欢迎评论&lt;br&gt;</summary>
    
    
    
    <category term="计算机图形学" scheme="https://www.dante-game.com.cn/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
    <category term="学习" scheme="https://www.dante-game.com.cn/tags/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="记录" scheme="https://www.dante-game.com.cn/tags/%E8%AE%B0%E5%BD%95/"/>
    
    <category term="经验" scheme="https://www.dante-game.com.cn/tags/%E7%BB%8F%E9%AA%8C/"/>
    
    <category term="计算机图形学" scheme="https://www.dante-game.com.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="OpenGL" scheme="https://www.dante-game.com.cn/tags/OpenGL/"/>
    
  </entry>
  
  <entry>
    <title>OpenGL GLFW, GLAD 在 Visual Studio 配置</title>
    <link href="https://www.dante-game.com.cn/2021/03/08/OpenGL%20%20GLFW,%20GLAD%20%E5%9C%A8%20Visual%20Studio%20%E9%85%8D%E7%BD%AE/"/>
    <id>https://www.dante-game.com.cn/2021/03/08/OpenGL%20%20GLFW,%20GLAD%20%E5%9C%A8%20Visual%20Studio%20%E9%85%8D%E7%BD%AE/</id>
    <published>2021-03-07T16:00:00.000Z</published>
    <updated>2022-09-02T06:49:21.357Z</updated>
    
    <content type="html"><![CDATA[<h2 id="GLFW"><a href="#GLFW" class="headerlink" title="GLFW"></a>GLFW</h2><h3 id="下载GLFW"><a href="#下载GLFW" class="headerlink" title="下载GLFW"></a>下载GLFW</h3><p><a href="https://github.com/glfw/glfw/releases/download/3.3.3/glfw-3.3.3.zip">下载地址</a>  </p><p>下载好后解压解压</p><blockquote><p>github下载可能略慢,建议翻墙</p></blockquote><span id="more"></span><h3 id="下载CMake"><a href="#下载CMake" class="headerlink" title="下载CMake"></a>下载CMake</h3><p><a href="https://cmake.org/download/">下载地址</a><br>下载好后解压,打开’bin/cmake-gui.exe’<br>我们现在需要一个源代码目录(即之前下好的glfw)和一个存放编译结果的目标文件目录(新建一个build文件夹)  </p><blockquote><p>注意路径不要有中文<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210309013232.png" alt="cmake"><br>Configure(设置)按钮,选择VS2019 16,然后保存<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210309013317.png" alt="Configure"></p></blockquote><p>最后点击Generate(生成)按钮，生成的工程文件会在你的build文件夹中</p><h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><p>在build文件夹里可以找到GLFW.sln文件，用VS打开,直接生成解决方案<br><code>glfw3.lib</code> 就会出现在 <code>src/Debug</code></p><p> <strong>glfw3.lib</strong> 放入路径 <code>C:\Program Files (x86) \ Microsoft Visual Studio \ (VS版本如2019) \ (VS版本如community/professional/Enterprise) \ VC \ Tools \ MSVC \ 14.28.29333 (版本号) \ lib \ x86或者x64 \</code></p><blockquote><p>取决于编译,建议使用x32</p></blockquote><p>将<code>glfw-3.3.3\include\GLFW</code> 整个文件夹放入路径 <code>C:\Program Files (x86) \ Microsoft Visual Studio \ (VS版本如2019) \ (VS版本如community/professional/Enterprise) \ VC \ Tools \ MSVC \ 14.28.29333 (版本号) \ include</code></p><h3 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h3><p>在VS<code>项目-&gt;工程属性-&gt;连接器-&gt;输入(input)-&gt;附加依赖项(第一项)</code>添加glfw3.lib<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210309032115.png" alt="lib"></p><h2 id="GLAD"><a href="#GLAD" class="headerlink" title="GLAD"></a>GLAD</h2><h3 id="配置GLAD"><a href="#配置GLAD" class="headerlink" title="配置GLAD"></a>配置GLAD</h3><p>打开<a href="http://glad.dav1d.de/">GLAD在线服务</a>设置如下后generate,下载提供的zip文件,解压<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210309014907.png" alt="GLAD"><br>把<code>glad\include</code>中的2个文件夹放入路径<code>C:\Program Files (x86) \ Microsoft Visual Studio \ (VS版本如2019) \ (VS版本如community/professional/Enterprise) \ VC \ Tools \ MSVC \ 14.28.29333 (版本号) \ include</code>  </p><p>把<strong>glad.c</strong>添加到工程文件中<br>最后你就能将以下的指令加到你的文件顶部了<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;glad/glad.h&gt; </span><br></pre></td></tr></table></figure></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;GLFW&quot;&gt;&lt;a href=&quot;#GLFW&quot; class=&quot;headerlink&quot; title=&quot;GLFW&quot;&gt;&lt;/a&gt;GLFW&lt;/h2&gt;&lt;h3 id=&quot;下载GLFW&quot;&gt;&lt;a href=&quot;#下载GLFW&quot; class=&quot;headerlink&quot; title=&quot;下载GLFW&quot;&gt;&lt;/a&gt;下载GLFW&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/glfw/glfw/releases/download/3.3.3/glfw-3.3.3.zip&quot;&gt;下载地址&lt;/a&gt;  &lt;/p&gt;
&lt;p&gt;下载好后解压解压&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;github下载可能略慢,建议翻墙&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="环境配置" scheme="https://www.dante-game.com.cn/categories/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
    
    <category term="学习" scheme="https://www.dante-game.com.cn/tags/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="记录" scheme="https://www.dante-game.com.cn/tags/%E8%AE%B0%E5%BD%95/"/>
    
    <category term="经验" scheme="https://www.dante-game.com.cn/tags/%E7%BB%8F%E9%AA%8C/"/>
    
    <category term="计算机图形学" scheme="https://www.dante-game.com.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch学习笔记5--分类Classification</title>
    <link href="https://www.dante-game.com.cn/2021/03/04/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05-%E5%88%86%E7%B1%BBClassification/"/>
    <id>https://www.dante-game.com.cn/2021/03/04/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05-%E5%88%86%E7%B1%BBClassification/</id>
    <published>2021-03-03T16:00:01.000Z</published>
    <updated>2022-09-02T06:49:21.362Z</updated>
    
    <content type="html"><![CDATA[<h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><p>其实和回归那个神经网络没差,就是数据集变化了,神经网络的输入输出端变为2个参数  </p><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/%E5%88%86%E7%B1%BB.gif" alt="分类"></p><span id="more"></span><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">#数据集</span><br><span class="line">n_data = torch.ones(1000, 2)         # 数据的基本形态</span><br><span class="line">x0 = torch.normal(2*n_data, 1)      # 类型0 x data (tensor), shape=(100, 2)</span><br><span class="line">y0 = torch.zeros(1000)               # 类型0 y data (tensor), shape=(100, )</span><br><span class="line">x1 = torch.normal(-2*n_data, 1)     # 类型1 x data (tensor), shape=(100, 1)</span><br><span class="line">y1 = torch.ones(1000)                # 类型1 y data (tensor), shape=(100, )</span><br><span class="line"></span><br><span class="line"># 注意 x, y 数据的数据形式是一定要像下面一样 (torch.cat 是在合并数据)</span><br><span class="line">x = torch.cat((x0, x1), 0).type(torch.FloatTensor)  # FloatTensor = 32-bit floating</span><br><span class="line"></span><br><span class="line">y = torch.cat((y0, y1), ).type(torch.LongTensor)    # LongTensor = 64-bit integer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#网络</span><br><span class="line">class Net(torch.nn.Module):</span><br><span class="line">    def __init__(self,n_feature, n_hidden,n_output):</span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.hidden = torch.nn.Linear(n_feature, n_hidden)#定义隐藏层结构</span><br><span class="line">        self.predict = torch.nn.Linear(n_hidden,n_output)#定义预测层结构,输出一个y</span><br><span class="line">    def forward(self,x): #正向传播输入一个x</span><br><span class="line">        x = torch.relu(self.hidden(x)) #正向传播x-&gt;relu过的x-&gt;output</span><br><span class="line">        x = self.predict(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">net = Net(n_feature = 2,n_hidden=10,n_output = 2)  #创建神经网络</span><br><span class="line"></span><br><span class="line">print(net)#可以看出神经网络的结构</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 训练</span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(),lr=0.02)#传入net的全部参数,学习率为0.2,越高越快,但也会出现梯度爆炸之类的问题</span><br><span class="line">#loss_func = torch.nn.MSELoss() MSE用于回归类型</span><br><span class="line">loss_func = torch.nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for i in range(500): #训练500次</span><br><span class="line">    out = net(x) #向神经网络传入 x , prediction 相当于神经网络正向传播完的y</span><br><span class="line"></span><br><span class="line">    loss = loss_func(out,y) #计算loss</span><br><span class="line"></span><br><span class="line">    print(loss)</span><br><span class="line">    time.sleep(0.5)#这里只是为了方便观察</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()#梯度归零清空上一步的残余更新参数值</span><br><span class="line">    loss.backward()# 误差反向传播, 计算参数更新值</span><br><span class="line">    optimizer.step() # 将参数更新值施加到 net 的 parameters 上</span><br><span class="line"></span><br><span class="line">    if i % 2 == 0:</span><br><span class="line">        plt.cla()</span><br><span class="line">        # 过了一道 softmax 的激励函数后的最大概率才是预测值</span><br><span class="line">        prediction = torch.max(F.softmax(out,dim=1), 1)[1]</span><br><span class="line">        pred_y = prediction.data.numpy().squeeze()</span><br><span class="line">        target_y = y.data.numpy()</span><br><span class="line">        plt.scatter(x.data.numpy()[:, 0], x.data.numpy()[:, 1], c=pred_y, s=100, lw=0, cmap=&#x27;RdYlGn&#x27;)</span><br><span class="line">        accuracy = sum(pred_y == target_y)/2000.  # 预测中有多少和真实值一样</span><br><span class="line">        plt.text(1.5, -4, &#x27;Accuracy=%.2f&#x27; % accuracy, fontdict=&#123;&#x27;size&#x27;: 20, &#x27;color&#x27;:  &#x27;red&#x27;&#125;)</span><br><span class="line">        plt.pause(0.1)</span><br><span class="line">        plt.ion()</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">plt.ioff()  # 停止画图</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;过程&quot;&gt;&lt;a href=&quot;#过程&quot; class=&quot;headerlink&quot; title=&quot;过程&quot;&gt;&lt;/a&gt;过程&lt;/h2&gt;&lt;p&gt;其实和回归那个神经网络没差,就是数据集变化了,神经网络的输入输出端变为2个参数  &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/Ao021/PicPub/%E5%88%86%E7%B1%BB.gif&quot; alt=&quot;分类&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://www.dante-game.com.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="学习" scheme="https://www.dante-game.com.cn/tags/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="记录" scheme="https://www.dante-game.com.cn/tags/%E8%AE%B0%E5%BD%95/"/>
    
    <category term="经验" scheme="https://www.dante-game.com.cn/tags/%E7%BB%8F%E9%AA%8C/"/>
    
    <category term="Pytorch" scheme="https://www.dante-game.com.cn/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>OpenGL(glut包)在Visual Studio配置</title>
    <link href="https://www.dante-game.com.cn/2021/03/04/OpenGL(glut%E5%8C%85)%E5%9C%A8Visual%20Studio%E9%85%8D%E7%BD%AE/"/>
    <id>https://www.dante-game.com.cn/2021/03/04/OpenGL(glut%E5%8C%85)%E5%9C%A8Visual%20Studio%E9%85%8D%E7%BD%AE/</id>
    <published>2021-03-03T16:00:00.000Z</published>
    <updated>2022-09-02T06:49:21.357Z</updated>
    
    <content type="html"><![CDATA[<h1 id="OpenGL-glut包-在Visual-Studio配置"><a href="#OpenGL-glut包-在Visual-Studio配置" class="headerlink" title="OpenGL(glut包)在Visual Studio配置"></a>OpenGL(glut包)在Visual Studio配置</h1><h2 id="1-glut下载"><a href="#1-glut下载" class="headerlink" title="1.glut下载"></a>1.glut下载</h2><p> <a href="https://www.opengl.org/resources/libraries/glut/glutdlls37beta.zip">下载链接</a></p><h2 id="2-环境配置"><a href="#2-环境配置" class="headerlink" title="2.环境配置"></a>2.环境配置</h2><span id="more"></span><p>下载好会有如下文件<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210304215209.png" alt="下载文件"></p><h3 id="h-文件"><a href="#h-文件" class="headerlink" title=".h 文件"></a>.h 文件</h3><p> <strong>glut.h</strong> 放入路径 <code>C:\Program Files (x86) \ Microsoft Visual Studio \ (VS版本如2019) \ (VS版本如community/professional/Enterprise) \ VC \ Tools \ MSVC \ 14.28.29333 (版本号) \ include \ GL \</code>，GL是文件夹手动创建的。</p><h3 id="lib-文件"><a href="#lib-文件" class="headerlink" title=".lib 文件"></a>.lib 文件</h3><p> <strong>glut32.lib</strong> 放入路径 <code>C:\Program Files (x86) \ Microsoft Visual Studio \ (VS版本如2019) \ (VS版本如community/professional/Enterprise) \ VC \ Tools \ MSVC \ 14.28.29333 (版本号) \ lib \ x86 \</code>  </p><p><strong>glut32.lib</strong> 放入路径 <code>C:\Program Files (x86) \ Microsoft Visual Studio \ (VS版本如2019) \ (VS版本如community/professional/Enterprise) \ VC \ Tools \ MSVC \ 14.28.29333 (版本号) \ lib \ x64 \</code>  </p><h3 id="dll-文件"><a href="#dll-文件" class="headerlink" title=".dll 文件"></a>.dll 文件</h3><p><strong>glut.dll</strong> 和 <strong>glut32.dll</strong> 放入<code>C:\ Windows \ SysWOW64 \</code><br><strong>glut32.dll</strong> 放入 <code>C:\ Windows \ System32 \</code>  </p><blockquote><p><a href="https://blog.csdn.net/jjhfen00/article/details/50646834">参考blog</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;OpenGL-glut包-在Visual-Studio配置&quot;&gt;&lt;a href=&quot;#OpenGL-glut包-在Visual-Studio配置&quot; class=&quot;headerlink&quot; title=&quot;OpenGL(glut包)在Visual Studio配置&quot;&gt;&lt;/a&gt;OpenGL(glut包)在Visual Studio配置&lt;/h1&gt;&lt;h2 id=&quot;1-glut下载&quot;&gt;&lt;a href=&quot;#1-glut下载&quot; class=&quot;headerlink&quot; title=&quot;1.glut下载&quot;&gt;&lt;/a&gt;1.glut下载&lt;/h2&gt;&lt;p&gt; &lt;a href=&quot;https://www.opengl.org/resources/libraries/glut/glutdlls37beta.zip&quot;&gt;下载链接&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;2-环境配置&quot;&gt;&lt;a href=&quot;#2-环境配置&quot; class=&quot;headerlink&quot; title=&quot;2.环境配置&quot;&gt;&lt;/a&gt;2.环境配置&lt;/h2&gt;</summary>
    
    
    
    <category term="环境配置" scheme="https://www.dante-game.com.cn/categories/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
    
    <category term="学习" scheme="https://www.dante-game.com.cn/tags/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="记录" scheme="https://www.dante-game.com.cn/tags/%E8%AE%B0%E5%BD%95/"/>
    
    <category term="经验" scheme="https://www.dante-game.com.cn/tags/%E7%BB%8F%E9%AA%8C/"/>
    
    <category term="计算机图形学" scheme="https://www.dante-game.com.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>PicGo GitHub图床设置</title>
    <link href="https://www.dante-game.com.cn/2021/03/04/PicGo%20GitHub%E5%9B%BE%E5%BA%8A%E8%AE%BE%E7%BD%AE/"/>
    <id>https://www.dante-game.com.cn/2021/03/04/PicGo%20GitHub%E5%9B%BE%E5%BA%8A%E8%AE%BE%E7%BD%AE/</id>
    <published>2021-03-03T16:00:00.000Z</published>
    <updated>2022-09-02T06:49:21.359Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PicGo-GitHub图床设置"><a href="#PicGo-GitHub图床设置" class="headerlink" title="PicGo GitHub图床设置"></a>PicGo GitHub图床设置</h1><ol><li>创建一个仓库,用于存储图片</li><li>生成一个token,点击github右上角头像选项的Settings/Developer settings/Personal access tokens,点击generate new token生成token  </li></ol><span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210304213307.png" alt="token"></p><ol><li>generate token后记得复制显示的token,只会出现这一次,如果忘记了需要regenerate</li><li>最后设置图床信息,仓库名为 用户名/仓库名形式,分支名为master,token为之前复制的一长串<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/20210304213638.png" alt="图床"></li><li>加速图床,由于GitHub国内访问速度很慢,在自定义域名加上<code>https://cdn.jsdelivr.net/gh/用户名/仓库名</code></li><li>最后保存就ok了</li></ol>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;PicGo-GitHub图床设置&quot;&gt;&lt;a href=&quot;#PicGo-GitHub图床设置&quot; class=&quot;headerlink&quot; title=&quot;PicGo GitHub图床设置&quot;&gt;&lt;/a&gt;PicGo GitHub图床设置&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;创建一个仓库,用于存储图片&lt;/li&gt;
&lt;li&gt;生成一个token,点击github右上角头像选项的Settings/Developer settings/Personal access tokens,点击generate new token生成token  &lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="环境配置" scheme="https://www.dante-game.com.cn/categories/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
    
    <category term="学习" scheme="https://www.dante-game.com.cn/tags/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="记录" scheme="https://www.dante-game.com.cn/tags/%E8%AE%B0%E5%BD%95/"/>
    
    <category term="经验" scheme="https://www.dante-game.com.cn/tags/%E7%BB%8F%E9%AA%8C/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch学习笔记3--激励函数</title>
    <link href="https://www.dante-game.com.cn/2021/03/04/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03-%E6%BF%80%E5%8A%B1%E5%87%BD%E6%95%B0/"/>
    <id>https://www.dante-game.com.cn/2021/03/04/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03-%E6%BF%80%E5%8A%B1%E5%87%BD%E6%95%B0/</id>
    <published>2021-03-03T16:00:00.000Z</published>
    <updated>2022-09-02T06:49:21.361Z</updated>
    
    <content type="html"><![CDATA[<h2 id="激励函数"><a href="#激励函数" class="headerlink" title="激励函数"></a>激励函数</h2><h3 id="什么是-Activation"><a href="#什么是-Activation" class="headerlink" title="什么是 Activation"></a>什么是 Activation</h3><p>激励函数是非线性函数<br>神经网络每一层出来都是线性的需要Activation掰弯来处理非线性问题  </p><p>常用的激励函数有</p><ul><li>relu</li><li>sigmoid</li><li>tanh</li><li>softplus</li></ul><span id="more"></span><h3 id="Torch中的激励函数"><a href="#Torch中的激励函数" class="headerlink" title="Torch中的激励函数"></a>Torch中的激励函数</h3><p><a href="https://mofanpy.com/tutorials/data-manipulation/plt/">python的可视化模块</a><br>以下是测试代码<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">from torch.autograd import variable #没啥用了好像</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">x = torch.linspace(-5,5,200)</span><br><span class="line">x_np = x.numpy()</span><br><span class="line"></span><br><span class="line">y_relu = torch.relu(x).numpy()</span><br><span class="line">y_sigmoid = torch.sigmoid(x).numpy()</span><br><span class="line">y_tanh = torch.tanh(x).numpy()</span><br><span class="line">y_softplus = F.softplus(x).numpy()</span><br><span class="line"></span><br><span class="line">plt.figure(1, figsize=(8, 6))</span><br><span class="line">plt.subplot(221)</span><br><span class="line">plt.plot(x_np, y_relu, c=&#x27;red&#x27;, label=&#x27;relu&#x27;)</span><br><span class="line">plt.ylim((-1, 5))</span><br><span class="line">plt.legend(loc=&#x27;best&#x27;)</span><br><span class="line"></span><br><span class="line">plt.subplot(222)</span><br><span class="line">plt.plot(x_np, y_sigmoid, c=&#x27;red&#x27;, label=&#x27;sigmoid&#x27;)</span><br><span class="line">plt.ylim((-0.2, 1.2))</span><br><span class="line">plt.legend(loc=&#x27;best&#x27;)</span><br><span class="line"></span><br><span class="line">plt.subplot(223)</span><br><span class="line">plt.plot(x_np, y_tanh, c=&#x27;red&#x27;, label=&#x27;tanh&#x27;)</span><br><span class="line">plt.ylim((-1.2, 1.2))</span><br><span class="line">plt.legend(loc=&#x27;best&#x27;)</span><br><span class="line"></span><br><span class="line">plt.subplot(224)</span><br><span class="line">plt.plot(x_np, y_softplus, c=&#x27;red&#x27;, label=&#x27;softplus&#x27;)</span><br><span class="line">plt.ylim((-0.2, 6))</span><br><span class="line">plt.legend(loc=&#x27;best&#x27;)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;激励函数&quot;&gt;&lt;a href=&quot;#激励函数&quot; class=&quot;headerlink&quot; title=&quot;激励函数&quot;&gt;&lt;/a&gt;激励函数&lt;/h2&gt;&lt;h3 id=&quot;什么是-Activation&quot;&gt;&lt;a href=&quot;#什么是-Activation&quot; class=&quot;headerlink&quot; title=&quot;什么是 Activation&quot;&gt;&lt;/a&gt;什么是 Activation&lt;/h3&gt;&lt;p&gt;激励函数是非线性函数&lt;br&gt;神经网络每一层出来都是线性的需要Activation掰弯来处理非线性问题  &lt;/p&gt;
&lt;p&gt;常用的激励函数有&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;relu&lt;/li&gt;
&lt;li&gt;sigmoid&lt;/li&gt;
&lt;li&gt;tanh&lt;/li&gt;
&lt;li&gt;softplus&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://www.dante-game.com.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="学习" scheme="https://www.dante-game.com.cn/tags/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="记录" scheme="https://www.dante-game.com.cn/tags/%E8%AE%B0%E5%BD%95/"/>
    
    <category term="经验" scheme="https://www.dante-game.com.cn/tags/%E7%BB%8F%E9%AA%8C/"/>
    
    <category term="Pytorch" scheme="https://www.dante-game.com.cn/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch学习笔记4--回归Regression</title>
    <link href="https://www.dante-game.com.cn/2021/03/04/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04-%E5%9B%9E%E5%BD%92Regression/"/>
    <id>https://www.dante-game.com.cn/2021/03/04/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04-%E5%9B%9E%E5%BD%92Regression/</id>
    <published>2021-03-03T16:00:00.000Z</published>
    <updated>2022-09-02T06:49:21.361Z</updated>
    
    <content type="html"><![CDATA[<h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><p>通过一个散点图建立一个简单神经网络  </p><p>步骤为  </p><ol><li>建立xy数据点集</li><li>定义神经网络结构,只有hidden和predict 2层</li><li>训练神经网络同时绘制图像<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub/%E5%9B%9E%E5%BD%92regression.gif" alt="训练过程"></li></ol><span id="more"></span><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">#print(torch.linspace(-1,1,100))</span><br><span class="line">x = torch.unsqueeze(torch.linspace(-1,1,100),dim=1) #生成二维的-1到1的伪数据,输出是个列向量</span><br><span class="line">#print(&#x27;\n&#x27;,x)</span><br><span class="line"></span><br><span class="line">y = x.pow(2) + 0.2* torch.rand(x.size())   #把点应造成X^2的抖动函数</span><br><span class="line">plt.scatter(x.numpy(),y.numpy())</span><br><span class="line">plt.show()</span><br><span class="line">#输出图片</span><br><span class="line"></span><br><span class="line">class Net(torch.nn.Module):</span><br><span class="line">    def __init__(self,n_feature, n_hidden,n_output):</span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.hidden = torch.nn.Linear(n_feature, n_hidden)#定义隐藏层结构</span><br><span class="line">        self.predict = torch.nn.Linear(n_hidden,n_output)#定义预测层结构,输出一个y</span><br><span class="line">    def forward(self,x): #正向传播输入一个x</span><br><span class="line">        x = torch.relu(self.hidden(x)) #正向传播x-&gt;relu过的x-&gt;output</span><br><span class="line">        x = self.predict(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">net = Net(n_feature=1,n_hidden=10,n_output=1)  #创建神经网络</span><br><span class="line"></span><br><span class="line">print(net)#可以看出神经网络的结构</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 下面开始训练</span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(),lr=0.2)#传入net的全部参数,学习率为0.2,越高越快,但也会出现梯度爆炸之类的问题</span><br><span class="line">loss_func = torch.nn.MSELoss()</span><br><span class="line"></span><br><span class="line">for i in range(500): #训练500次</span><br><span class="line">    prediction = net(x) #向神经网络传入 x , prediction 相当于神经网络正向传播完的y</span><br><span class="line"></span><br><span class="line">    loss = loss_func(prediction,y) #计算loss</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()#梯度归零清空上一步的残余更新参数值</span><br><span class="line">    loss.backward()# 误差反向传播, 计算参数更新值</span><br><span class="line">    optimizer.step() # 将参数更新值施加到 net 的 parameters 上</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#绘图</span><br><span class="line">    if i % 5 == 0:</span><br><span class="line">        # plot and show learning process</span><br><span class="line">        plt.cla()</span><br><span class="line">        plt.scatter(x.data.numpy(), y.data.numpy())</span><br><span class="line">        plt.plot(x.data.numpy(), prediction.data.numpy(), &#x27;r-&#x27;, lw=5)</span><br><span class="line">        plt.text(0.5, 0, &#x27;Loss=%.4f&#x27; % loss.data.numpy(), fontdict=&#123;&#x27;size&#x27;: 20, &#x27;color&#x27;:  &#x27;red&#x27;&#125;)</span><br><span class="line">        plt.pause(0.1)</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;过程&quot;&gt;&lt;a href=&quot;#过程&quot; class=&quot;headerlink&quot; title=&quot;过程&quot;&gt;&lt;/a&gt;过程&lt;/h2&gt;&lt;p&gt;通过一个散点图建立一个简单神经网络  &lt;/p&gt;
&lt;p&gt;步骤为  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;建立xy数据点集&lt;/li&gt;
&lt;li&gt;定义神经网络结构,只有hidden和predict 2层&lt;/li&gt;
&lt;li&gt;训练神经网络同时绘制图像&lt;br&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/Ao021/PicPub/%E5%9B%9E%E5%BD%92regression.gif&quot; alt=&quot;训练过程&quot;&gt;&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://www.dante-game.com.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="学习" scheme="https://www.dante-game.com.cn/tags/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="记录" scheme="https://www.dante-game.com.cn/tags/%E8%AE%B0%E5%BD%95/"/>
    
    <category term="经验" scheme="https://www.dante-game.com.cn/tags/%E7%BB%8F%E9%AA%8C/"/>
    
    <category term="Pytorch" scheme="https://www.dante-game.com.cn/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch学习笔记-pip安装python模块使用国内镜像</title>
    <link href="https://www.dante-game.com.cn/2021/03/02/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-pip%E5%AE%89%E8%A3%85python%E6%A8%A1%E5%9D%97%E4%BD%BF%E7%94%A8%E5%9B%BD%E5%86%85%E9%95%9C%E5%83%8F/"/>
    <id>https://www.dante-game.com.cn/2021/03/02/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-pip%E5%AE%89%E8%A3%85python%E6%A8%A1%E5%9D%97%E4%BD%BF%E7%94%A8%E5%9B%BD%E5%86%85%E9%95%9C%E5%83%8F/</id>
    <published>2021-03-01T16:00:00.000Z</published>
    <updated>2022-09-02T06:49:21.360Z</updated>
    
    <content type="html"><![CDATA[<h2 id="镜像源"><a href="#镜像源" class="headerlink" title="镜像源"></a>镜像源</h2><p>由于<code>pip install</code> 都是从海外源下载,正常的 install 很慢<br>使用国内的镜像源会大幅度提升 install 速度</p><h3 id="以下的国内的一些镜像源"><a href="#以下的国内的一些镜像源" class="headerlink" title="以下的国内的一些镜像源"></a>以下的国内的一些镜像源</h3><span id="more"></span><p>镜像源：<br>豆瓣：<a href="https://pypi.douban.com/simple/">https://pypi.douban.com/simple/</a><br>清华：<a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.douban.com/simple/</a><br>阿里：<a href="https://mirrors.aliyun.com/pypi/simple/">https://pypi.douban.com/simple/</a><br>中国科技大学 ：<a href="https://pypi.mirrors.ustc.edu.cn/simple/">https://pypi.douban.com/simple/</a></p><h3 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h3><ul><li>方法1<br><code>pip install 模块名 -i 以上镜像源网址</code></li><li>方法2<br>在user目录中创建一个pip目录，如：C:\Users\用户名\pip，新建文件pip.ini，内容如下 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">  [global]</span><br><span class="line">index-url = https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure>url内容可以任意更换为以上源</li></ul><blockquote><p><a href="https://www.jianshu.com/p/2e33b1ed27b7">参考blog</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;镜像源&quot;&gt;&lt;a href=&quot;#镜像源&quot; class=&quot;headerlink&quot; title=&quot;镜像源&quot;&gt;&lt;/a&gt;镜像源&lt;/h2&gt;&lt;p&gt;由于&lt;code&gt;pip install&lt;/code&gt; 都是从海外源下载,正常的 install 很慢&lt;br&gt;使用国内的镜像源会大幅度提升 install 速度&lt;/p&gt;
&lt;h3 id=&quot;以下的国内的一些镜像源&quot;&gt;&lt;a href=&quot;#以下的国内的一些镜像源&quot; class=&quot;headerlink&quot; title=&quot;以下的国内的一些镜像源&quot;&gt;&lt;/a&gt;以下的国内的一些镜像源&lt;/h3&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://www.dante-game.com.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="学习" scheme="https://www.dante-game.com.cn/tags/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="记录" scheme="https://www.dante-game.com.cn/tags/%E8%AE%B0%E5%BD%95/"/>
    
    <category term="经验" scheme="https://www.dante-game.com.cn/tags/%E7%BB%8F%E9%AA%8C/"/>
    
    <category term="Pytorch" scheme="https://www.dante-game.com.cn/tags/Pytorch/"/>
    
    <category term="python" scheme="https://www.dante-game.com.cn/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch学习笔记--自动求导机制</title>
    <link href="https://www.dante-game.com.cn/2021/02/19/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02-Autograd%20%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC%E6%9C%BA%E5%88%B6/"/>
    <id>https://www.dante-game.com.cn/2021/02/19/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02-Autograd%20%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC%E6%9C%BA%E5%88%B6/</id>
    <published>2021-02-18T16:00:00.000Z</published>
    <updated>2022-09-02T06:49:21.361Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Autograd-自动求导机制"><a href="#Autograd-自动求导机制" class="headerlink" title="Autograd: 自动求导机制"></a>Autograd: 自动求导机制</h2><p>PyTorch 中所有神经网络的核心是 autograd 包。 我们先简单介绍一下这个包，然后训练第一个简单的神经网络。</p><p>autograd包为张量上的所有操作提供了自动求导。 它是一个在运行时定义的框架，这意味着反向传播是根据你的代码来确定如何运行，并且每次迭代可以是不同的。</p><span id="more"></span><p>示例</p><p>张量（Tensor）<br>torch.Tensor是这个包的核心类。如果设置 .requires_grad 为 True，那么将会追踪所有对于该张量的操作。 当完成计算后通过调用 .backward()，自动计算所有的梯度， 这个张量的所有梯度将会自动积累到 .grad 属性。</p><p>要阻止张量跟踪历史记录，可以调用.detach()方法将其与计算历史记录分离，并禁止跟踪它将来的计算记录。</p><p>为了防止跟踪历史记录（和使用内存），可以将代码块包装在with torch.no_grad()：中。 在评估模型时特别有用，因为模型可能具有requires_grad = True的可训练参数，但是我们不需要梯度计算。</p><p>在自动梯度计算中还有另外一个重要的类Function.</p><p>Tensor and Function are interconnected and build up an acyclic graph, that encodes a complete history of computation. Each tensor has a .grad_fn attribute that references a Function that has created the Tensor (except for Tensors created by the user - their grad_fn is None).</p><p>Tensor 和 Function互相连接并生成一个非循环图，它表示和存储了完整的计算历史。 每个张量都有一个.grad_fn属性，这个属性引用了一个创建了Tensor的Function（除非这个张量是用户手动创建的，即，这个张量的 grad_fn 是 None）。</p><p>如果需要计算导数，你可以在Tensor上调用.backward()。 如果Tensor是一个标量（即它包含一个元素数据）则不需要为backward()指定任何参数， 但是如果它有更多的元素，你需要指定一个gradient 参数来匹配张量的形状。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;Autograd-自动求导机制&quot;&gt;&lt;a href=&quot;#Autograd-自动求导机制&quot; class=&quot;headerlink&quot; title=&quot;Autograd: 自动求导机制&quot;&gt;&lt;/a&gt;Autograd: 自动求导机制&lt;/h2&gt;&lt;p&gt;PyTorch 中所有神经网络的核心是 autograd 包。 我们先简单介绍一下这个包，然后训练第一个简单的神经网络。&lt;/p&gt;
&lt;p&gt;autograd包为张量上的所有操作提供了自动求导。 它是一个在运行时定义的框架，这意味着反向传播是根据你的代码来确定如何运行，并且每次迭代可以是不同的。&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://www.dante-game.com.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="学习" scheme="https://www.dante-game.com.cn/tags/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="记录" scheme="https://www.dante-game.com.cn/tags/%E8%AE%B0%E5%BD%95/"/>
    
    <category term="经验" scheme="https://www.dante-game.com.cn/tags/%E7%BB%8F%E9%AA%8C/"/>
    
    <category term="Pytorch" scheme="https://www.dante-game.com.cn/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch学习笔记--张量</title>
    <link href="https://www.dante-game.com.cn/2021/01/27/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01-%E5%BC%A0%E9%87%8F/"/>
    <id>https://www.dante-game.com.cn/2021/01/27/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01-%E5%BC%A0%E9%87%8F/</id>
    <published>2021-01-27T14:31:14.000Z</published>
    <updated>2022-09-02T06:49:21.360Z</updated>
    
    <content type="html"><![CDATA[<h2 id="PyTorch是什么"><a href="#PyTorch是什么" class="headerlink" title="PyTorch是什么"></a>PyTorch是什么</h2><p>基于Python的科学计算包，服务于以下两种场景:</p><ul><li>作为NumPy的替代品，可以使用GPU的强大计算能力</li><li>提供最大的灵活性和高速的深度学习研究平台</li></ul><span id="more"></span><h2 id="Tensors-张量"><a href="#Tensors-张量" class="headerlink" title="Tensors 张量"></a>Tensors 张量</h2><h3 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h3><p>Tensors与Numpy中的 ndarrays类似，但是在PyTorch中 Tensors 可以使用GPU进行计算.<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from __future__ import print_function</span><br><span class="line">import torch</span><br></pre></td></tr></table></figure></p><h4 id="创建一个-5x3-矩阵-但是未初始化"><a href="#创建一个-5x3-矩阵-但是未初始化" class="headerlink" title="创建一个 5x3 矩阵, 但是未初始化:"></a>创建一个 5x3 矩阵, 但是未初始化:</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.empty(5, 3)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.0000, 0.0000, 0.0000],  </span><br><span class="line">        [0.0000, 0.0000, 0.0000],  </span><br><span class="line">        [0.0000, 0.0000, 0.0000],  </span><br><span class="line">        [0.0000, 0.0000, 0.0000],  </span><br><span class="line">        [0.0000, 0.0000, 0.0000]])</span><br></pre></td></tr></table></figure><h4 id="创建一个随机初始化的矩阵"><a href="#创建一个随机初始化的矩阵" class="headerlink" title="创建一个随机初始化的矩阵:"></a>创建一个随机初始化的矩阵:</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(5, 3)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.6972, 0.0231, 0.3087],</span><br><span class="line">        [0.2083, 0.6141, 0.6896],</span><br><span class="line">        [0.7228, 0.9715, 0.5304],</span><br><span class="line">        [0.7727, 0.1621, 0.9777],</span><br><span class="line">        [0.6526, 0.6170, 0.2605]])</span><br></pre></td></tr></table></figure><h4 id="创建一个0填充的矩阵，数据类型为long"><a href="#创建一个0填充的矩阵，数据类型为long" class="headerlink" title="创建一个0填充的矩阵，数据类型为long:"></a>创建一个0填充的矩阵，数据类型为long:</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.zeros(5, 3, dtype=torch.long)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0]])</span><br></pre></td></tr></table></figure><h4 id="创建tensor并使用现有数据初始化"><a href="#创建tensor并使用现有数据初始化" class="headerlink" title="创建tensor并使用现有数据初始化:"></a>创建tensor并使用现有数据初始化:</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([5.5, 3])</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([5.5000, 3.0000])</span><br></pre></td></tr></table></figure><h4 id="根据现有的张量创建张量。-这些方法将重用输入张量的属性，例如，-dtype，除非设置新的值进行覆盖"><a href="#根据现有的张量创建张量。-这些方法将重用输入张量的属性，例如，-dtype，除非设置新的值进行覆盖" class="headerlink" title="根据现有的张量创建张量。 这些方法将重用输入张量的属性，例如， dtype，除非设置新的值进行覆盖"></a>根据现有的张量创建张量。 这些方法将重用输入张量的属性，例如， dtype，除非设置新的值进行覆盖</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = x.new_ones(5, 3, dtype=torch.double)      # new_* 方法来创建对象</span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line">x = torch.randn_like(x, dtype=torch.float)    # 覆盖 dtype!</span><br><span class="line">print(x)                                      #  对象的size 是相同的，只是值和类型发生了变化</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1., 1., 1.],</span><br><span class="line">        [1., 1., 1.],</span><br><span class="line">        [1., 1., 1.],</span><br><span class="line">        [1., 1., 1.],</span><br><span class="line">        [1., 1., 1.]], dtype=torch.float64)</span><br><span class="line">tensor([[ 0.5691, -2.0126, -0.4064],</span><br><span class="line">        [-0.0863,  0.4692, -1.1209],</span><br><span class="line">        [-1.1177, -0.5764, -0.5363],</span><br><span class="line">        [-0.4390,  0.6688,  0.0889],</span><br><span class="line">        [ 1.3334, -1.1600,  1.8457]])</span><br></pre></td></tr></table></figure><h4 id="获取-size"><a href="#获取-size" class="headerlink" title="获取 size"></a>获取 size</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x.size())</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([5, 3])</span><br></pre></td></tr></table></figure><h2 id="张量的操作"><a href="#张量的操作" class="headerlink" title="张量的操作"></a>张量的操作</h2><h3 id="加法"><a href="#加法" class="headerlink" title="加法"></a>加法</h3><h4 id="加法1"><a href="#加法1" class="headerlink" title="加法1"></a>加法1</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = torch.rand(5, 3)</span><br><span class="line">print(x + y)</span><br></pre></td></tr></table></figure><h4 id="加法2"><a href="#加法2" class="headerlink" title="加法2"></a>加法2</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(torch.add(x, y))</span><br></pre></td></tr></table></figure><h4 id="提供输出tensor作为参数"><a href="#提供输出tensor作为参数" class="headerlink" title="提供输出tensor作为参数"></a>提供输出tensor作为参数</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">result = torch.empty(5, 3)</span><br><span class="line">torch.add(x, y, out=result)</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure><h4 id="替换"><a href="#替换" class="headerlink" title="替换"></a>替换</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.add_(x)</span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure><blockquote><p>任何 以<code>_</code> 结尾的操作都会用结果替换原变量. 例如: <code>x.copy_(y)</code>, <code>x.t_()</code>, 都会改变 <code>x</code>.这里便是 y+=x</p></blockquote><h4 id="torch-view-可以改变张量的维度和大小"><a href="#torch-view-可以改变张量的维度和大小" class="headerlink" title="torch.view: 可以改变张量的维度和大小"></a>torch.view: 可以改变张量的维度和大小</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(4, 4)</span><br><span class="line">y = x.view(16)</span><br><span class="line">z = x.view(-1, 8)  #  size -1 从其他维度推断</span><br><span class="line">print(x.size(), y.size(), z.size())</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])</span><br></pre></td></tr></table></figure><h4 id="只有一个元素的张量，使用-item-来得到Python数据类型的数值"><a href="#只有一个元素的张量，使用-item-来得到Python数据类型的数值" class="headerlink" title="只有一个元素的张量，使用.item()来得到Python数据类型的数值"></a>只有一个元素的张量，使用.item()来得到Python数据类型的数值</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(1)</span><br><span class="line">print(x)</span><br><span class="line">print(x.item())</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([-0.2368])</span><br><span class="line">-0.23680149018764496</span><br></pre></td></tr></table></figure><h2 id="NumPy-转换"><a href="#NumPy-转换" class="headerlink" title="NumPy 转换"></a>NumPy 转换</h2><p>将一个Torch Tensor转换为NumPy数组是一件轻松的事，反之亦然。<br>Torch Tensor与NumPy数组共享底层内存地址，修改一个会导致另一个的变化。<br><br><br>将一个Torch Tensor转换为NumPy数组<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = torch.ones(5)</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure><br><code>tensor([1., 1., 1., 1., 1.])</code><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b = a.numpy()</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure><br><code>[1. 1. 1. 1. 1.]</code><br><br></p><h3 id="numpy数组的值是如何改变的。"><a href="#numpy数组的值是如何改变的。" class="headerlink" title="numpy数组的值是如何改变的。"></a>numpy数组的值是如何改变的。</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a.add_(1)</span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([2., 2., 2., 2., 2.])</span><br><span class="line">[2. 2. 2. 2. 2.]</span><br></pre></td></tr></table></figure><h4 id="使用from-numpy自动转化"><a href="#使用from-numpy自动转化" class="headerlink" title="使用from_numpy自动转化"></a>使用from_numpy自动转化</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">a = np.ones(5)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line">np.add(a, 1, out=a)</span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[2. 2. 2. 2. 2.]</span><br><span class="line">tensor([2., 2., 2., 2., 2.], dtype=torch.float64)</span><br></pre></td></tr></table></figure><blockquote><p>所有的 Tensor 类型默认都是基于CPU， CharTensor 类型不支持到 NumPy 的转换.</p><h2 id="CUDA-张量"><a href="#CUDA-张量" class="headerlink" title="CUDA 张量"></a>CUDA 张量</h2><p>使用.to 方法 可以将Tensor移动到任何设备中<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># is_available 函数判断是否有cuda可以使用</span><br><span class="line"># ``torch.device``将张量移动到指定的设备中</span><br><span class="line">if torch.cuda.is_available():</span><br><span class="line">    device = torch.device(&quot;cuda&quot;)          # a CUDA 设备对象</span><br><span class="line">    y = torch.ones_like(x, device=device)  # 直接从GPU创建张量</span><br><span class="line">    x = x.to(device)                       # 或者直接使用``.to(&quot;cuda&quot;)``将张量移动到cuda中</span><br><span class="line">    z = x + y</span><br><span class="line">    print(z)</span><br><span class="line">    print(z.to(&quot;cpu&quot;, torch.double))       # ``.to`` 也会对变量的类型做更改</span><br></pre></td></tr></table></figure><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([0.7632], device=&#x27;cuda:0&#x27;)</span><br><span class="line">tensor([0.7632], dtype=torch.float64)</span><br></pre></td></tr></table></figure></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;PyTorch是什么&quot;&gt;&lt;a href=&quot;#PyTorch是什么&quot; class=&quot;headerlink&quot; title=&quot;PyTorch是什么&quot;&gt;&lt;/a&gt;PyTorch是什么&lt;/h2&gt;&lt;p&gt;基于Python的科学计算包，服务于以下两种场景:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;作为NumPy的替代品，可以使用GPU的强大计算能力&lt;/li&gt;
&lt;li&gt;提供最大的灵活性和高速的深度学习研究平台&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://www.dante-game.com.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="学习" scheme="https://www.dante-game.com.cn/tags/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="记录" scheme="https://www.dante-game.com.cn/tags/%E8%AE%B0%E5%BD%95/"/>
    
    <category term="经验" scheme="https://www.dante-game.com.cn/tags/%E7%BB%8F%E9%AA%8C/"/>
    
    <category term="Pytorch" scheme="https://www.dante-game.com.cn/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>人工智能小测试</title>
    <link href="https://www.dante-game.com.cn/2021/01/27/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2_%E5%85%A5%E9%97%A8_%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB/"/>
    <id>https://www.dante-game.com.cn/2021/01/27/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2_%E5%85%A5%E9%97%A8_%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB/</id>
    <published>2021-01-27T14:31:14.000Z</published>
    <updated>2022-09-02T06:49:21.364Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前置"><a href="#前置" class="headerlink" title="前置"></a>前置</h2><ul><li>翻墙工具</li><li>github账号,看源码必备</li><li>基于pytorch</li><li>最好有个Google账号</li><li>使用Google的深度学习服务器<a href="https://colab.research.google.com/">Colab</a>,自带24G显存的GPU,如果要长时间使用9.99美元/月(65块/月),我们的数据集通过<a href="https://drive.google.com/">Google云端硬盘</a>上传,自带15G免费内存,可扩充100G/月(250日元/月,差不多15块吧,我们学习阶段应该用不上扩充)</li></ul><span id="more"></span><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><ul><li>学习完全可以跟着这个<a href="https://github.com/Jack-Cherish/Deep-Learning">网站</a>学</li><li>我先跳过理论直接做了UNet框架的训练,具体步骤参照<a href="https://cuijiahua.com/blog/2020/03/dl-16.html">这个网站</a>手把手教学,有源码和<a href="https://drive.google.com/drive/folders/1uWliDqL0bLOnnyFuOjjm2VwzGlJKBMsa?usp=sharing">数据集</a></li><li>我们需要做的只有学会怎么用colab</li><li>进入colab首先配置GPU加速模式,不然训练的超级慢<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20201217224044.png" alt=""><br>进去后硬件加速器选GPU(训练模型用GPU,不充钱不稳定后文有推荐本地运行的方法)</li><li>记得选择这个显示模式,更直观<br><img src="https://cdn.jsdelivr.net/gh/Ao021/PicPub@master/20201217224344.png" alt=""></li><li>然后跟着使用入门连接你的Google云端硬盘</li><li>然后再文件-&gt;新建笔记本</li><li>再左侧栏最下面文件夹里就是你的目录了,可以新建文件或者文件夹,你也能看见你的云端硬盘的文件夹,可以直接通过复制路径调用资源</li><li>记得自己的代码最好建立在本地或云端硬盘里,colab容易丢失,谢邀写到这里发现我代码没了</li><li>写的.py文件通过第一栏的笔记本输入<code>!python 绝对路径(直接复制的路径)/相对路径</code>执行</li><li>本地运行点击右上角 连接-&gt;切换到本地运行时,使用jupyter本地运行</li><li><p>请在终端分别输入以下代码(前提你已经配置好了python环境)</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install jupyter_http_over_ws</span><br><span class="line">jupyter serverextension enable --py jupyter_http_over_ws</span><br></pre></td></tr></table></figure>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">  jupyter notebook --NotebookApp.allow_origin=&#x27;https://colab.research.google.com&#x27; \</span><br><span class="line">--port=8888 --no-browser</span><br></pre></td></tr></table></figure></li><li><p>在colab输入你 终端显示的<code>http://localhost:8888/?token=</code>xxxxx</p></li></ul>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;前置&quot;&gt;&lt;a href=&quot;#前置&quot; class=&quot;headerlink&quot; title=&quot;前置&quot;&gt;&lt;/a&gt;前置&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;翻墙工具&lt;/li&gt;
&lt;li&gt;github账号,看源码必备&lt;/li&gt;
&lt;li&gt;基于pytorch&lt;/li&gt;
&lt;li&gt;最好有个Google账号&lt;/li&gt;
&lt;li&gt;使用Google的深度学习服务器&lt;a href=&quot;https://colab.research.google.com/&quot;&gt;Colab&lt;/a&gt;,自带24G显存的GPU,如果要长时间使用9.99美元/月(65块/月),我们的数据集通过&lt;a href=&quot;https://drive.google.com/&quot;&gt;Google云端硬盘&lt;/a&gt;上传,自带15G免费内存,可扩充100G/月(250日元/月,差不多15块吧,我们学习阶段应该用不上扩充)&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://www.dante-game.com.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="学习" scheme="https://www.dante-game.com.cn/tags/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="记录" scheme="https://www.dante-game.com.cn/tags/%E8%AE%B0%E5%BD%95/"/>
    
    <category term="经验" scheme="https://www.dante-game.com.cn/tags/%E7%BB%8F%E9%AA%8C/"/>
    
    <category term="人工智能" scheme="https://www.dante-game.com.cn/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
</feed>
